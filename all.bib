
@InProceedings{10.1007/978-3-031-23220-6_4,
  author	= "Thiyagalingam, Jeyan and von Laszewski, Gregor and Yin,
		  Junqi and Emani, Murali and Papay, Juri and Barrett, Gregg
		  and Luszczek, Piotr and Tsaris, Aristeidis and Kirkpatrick,
		  Christine and Wang, Feiyi and Gibbs, Tom and Vishwanath,
		  Venkatram and Shankar, Mallikarjun and Fox, Geoffrey and
		  Hey, Tony",
  editor	= "Anzt, Hartwig and Bienz, Amanda and Luszczek, Piotr and Baboulin, Marc",
  title		= "AI Benchmarking for Science: Efforts from the MLCommons Science Working Group",
  booktitle	= "High Performance Computing. ISC High Performance 2022
		  International Workshops",
  year		= "2022",
  publisher	= "Springer International Publishing",
  address	= "Cham",
  pages		= "47--64",
  abstract	= "With machine learning (ML) becoming a transformative tool
		  for science, the scientific community needs a clear
		  catalogue of ML techniques, and their relative benefits on
		  various scientific problems, if they were to make
		  significant advances in science using AI. Although this
		  comes under the purview of benchmarking, conventional
		  benchmarking initiatives are focused on performance, and as
		  such, science, often becomes a secondary criteria.",
  isbn		= "978-3-031-23220-6"
}

@Misc{abud2021deep,
  title = {{Deep Underground Neutrino Experiment (DUNE) Near Detector Conceptual Design Report}},
  author	= {A. Abed Abud and B. Abi and R. Acciarri and M. A. Acero and G. Adamov and D. Adams and M. Adinolfi and A. Aduszkiewicz and Z. Ahmad and J. Ahmed and T. Alion and S. Alonso Monsalve and M. Alrashed and C. Alt and A. Alton and P. Amedo and J. Anderson and C. Andreopoulos and M. P. Andrews and F. Andrianala and S. Andringa and N. Anfimov and A. Ankowski and M. Antonova and S. Antusch and A. Aranda-Fernandez and A. Ariga and L. O. Arnold and M. A. Arroyave and J. Asaadi and A. Aurisano and V. Aushev and D. Autiero and M. Ayala-Torres and F. Azfar and H. Back and J. J. Back and C. Backhouse and P. Baesso and I. Bagaturia and L. Bagby and S. Balasubramanian and P. Baldi and B. Baller and B. Bambah and F. Barao and G. Barenboim and G. J. Barker and W. Barkhouse and C. Barnes and G. Barr and J. Barranco Monarca and N. Barros and J. L. Barrow and A. Basharina-Freshville and A. Bashyal and V. Basque and E. Belchior and J. B. R. Battat and F. Battisti and F. Bay and J. L. Bazo Alba and J. F. Beacom and E. Bechetoille and B. Behera and L. Bellantoni and G. Bellettini and V. Bellini and O. Beltramello and D. Belver and N. Benekos and F. Bento Neves and S. Berkman and P. Bernardini and R. M. Berner and H. Berns and S. Bertolucci and M. Betancourt and A. Betancur Rodr{\'i}guez and M. Bhattacharjee and S. Bhuller and B. Bhuyan and S. Biagi and J. Bian and M. Biassoni and K. Biery and B. Bilki and M. Bishai and A. Bitadze and A. Blake and F. D. M. Blaszczyk and G. C. Blazey and E. Blucher and J. Boissevain and S. Bolognesi and T. Bolton and L. Bomben and M. Bonesini and M. Bongrand and F. Bonini and A. Booth and C. Booth and S. Bordoni and A. Borkum and T. Boschi and N. Bostan and P. Bour and C. Bourgeois and S. B. Boyd and D. Boyden and J. Bracinik and D. Braga and D. Brailsford and A. Brandt and J. Bremer and C. Brew and E. Brianne and S. J. Brice and C. Brizzolari and C. Bromberg and G. Brooijmans and J. Brooke and A. Bross and G. Brunetti and M. Brunetti and N. Buchanan and H. Budd and D. Caiulo and P. Calafiura and J. Calcutt and M. Calin and S. Calvez and E. Calvo and A. Caminata and M. Campanelli and K. Cankocak and D. Caratelli and G. Carini and B. Carlus and P. Carniti and I. Caro Terrazas and H. Carranza and T. Carroll and J. F. Casta\~{n}o Forero and A. Castillo and C. Castromonte and E. Catano-Mur and C. Cattadori and F. Cavalier and F. Cavanna and S. Centro and G. Cerati and A. Cervelli and A. Cervera Villanueva and M. Chalifour and A. Chappell and E. Chardonnet and N. Charitonidis and A. Chatterjee and S. Chattopadhyay and H. Chen and M. Chen and Y. Chen and Z. Chen and D. Cherdack and C. Chi and S. Childress and A. Chiriacescu and G. Chisnall and K. Cho and S. Choate and D. Chokheli and S. Choubey and A. Christensen and D. Christian and G. Christodoulou and A. Chukanov and E. Church and P. Clarke and T. E. Coan and A. G. Cocco and J. A. B. Coelho and E. Conley and R. Conley and J. M. Conrad and M. Convery and S. Copello and L. Corwin and L. Cremaldi and L. Cremonesi and J. I. Crespo-Anad\'{o}n and E. Cristaldo and R. Cross and A. Cudd and C. Cuesta and Y. Cui and D. Cussans and M. Dabrowski and O. Dalager and H. da Motta and L. Da Silva Peres and C. David and Q. David and G. S. Davies and S. Davini and J. Dawson and K. De and R. M. De Almeida and P. Debbins and I. De Bonis and M. P. Decowski and A. de Gouv{\^e}a and P. C. De Holanda and I. L. De Icaza Astiz and A. Deisting and P. De Jong and A. Delbart and D. Delepine and M. Delgado and A. Dell'Acqua and P. De Lurgio and J. R. T. de Mello Neto and D. M. DeMuth and S. Dennis and C. Densham and G. W. Deptuch and A. De Roeck and V. De Romeri and G. De Souza and R. Dharmapalan and F. Diaz and J. S. D\'{i}az and S. Di Domizio and L. Di Giulio and P. Ding and L. Di Noto and C. Distefano and R. Diurba and M. Diwan and Z. Djurcic and N. Dokania and S. Dolan and M. J. Dolinski and L. Domine and D. Douglas and D. Douillet and G. Drake and F. Drielsma and D. Duchesneau and K. Duffy and P. Dunne and T. Durkin and H. Duyang and O. Dvornikov and D. A. Dwyer and A. S. Dyshkant and M. Eads and A. Earle and D. Edmunds and J. Eisch and L. Emberger and S. Emery and A. Ereditato and C. O. Escobar and G. Eurin and J. J. Evans and E. Ewart and A. C. Ezeribe and K. Fahey and A. Falcone and C. Farnese and Y. Farzan and J. Felix and M. Fernandes Carneiro da Silva and E. Fernandez-Martinez and P. Fernandez Menendez and F. Ferraro and L. Fields and F. Filthaut and A. Fiorentini and R. S. Fitzpatrick and W.
		  Flanagan and B. Fleming and R. Flight and D. V. Forero and
		  J. Fowler and W. Fox and J. Franc and K. Francis and D.
		  Franco and J. Freeman and J. Freestone and J. Fried and A.
		  Friedland and S. Fuess and I. Furic and A. P. Furmanski and
		  A. Gago and H. Gallagher and A. Gallas and A. Gallego-Ros
		  and N. Gallice and V. Galymov and E. Gamberini and T.
		  Gamble and R. Gandhi and R. Gandrajula and F. Gao and S.
		  Gao and D. Garcia-Gamez and M. \'{A} Garc\'{i}a-Peris and
		  S. Gardiner and D. Gastler and G. Ge and B. Gelli and A.
		  Gendotti and S. Gent and Z. Ghorbani-Moghaddam and D. Gibin
		  and I. Gil-Botella and S. Gilligan and C. Girerd and A. K.
		  Giri and D. Gnani and O. Gogota and M. Gold and S.
		  Gollapinni and K. Gollwitzer and R. A. Gomes and L. V.
		  Gomez Bermeo and L. S. Gomez Fajardo and F. Gonnella and J.
		  A. Gonzalez-Cuevas and D. Gonzalez-Diaz and M.
		  Gonzalez-Lopez and M. C. Goodman and O. Goodwin and S.
		  Goswami and C. Gotti and E. Goudzovski and C. Grace and M.
		  Graham and R. Gran and E. Granados and P. Granger and A.
		  Grant and C. Grant and D. Gratieri and P. Green and L.
		  Greenler and J. Greer and W. C. Griffith and M. Groh and J.
		  Grudzinski and K. Grzelak and W. Gu and V. Guarino and R.
		  Guenette and E. Guerard and A. Guglielmi and B. Guo and K.
		  K. Guthikonda and R. Gutierrez and P. Guzowski and M. M.
		  Guzzo and S. Gwon and A. Habig and H. Hadavand and R.
		  Haenni and A. Hahn and J. Haiston and P. Hamacher-Baumann
		  and T. Hamernik and P. Hamilton and J. Han and D. A. Harris
		  and J. Hartnell and J. Harton and T. Hasegawa and C. Hasnip
		  and R. Hatcher and K. W. Hatfield and A. Hatzikoutelis and
		  C. Hayes and E. Hazen and A. Heavey and K. M. Heeger and J.
		  Heise and K. Hennessy and S. Henry and M. A. Hernandez
		  Morquecho and K. Herner and L. Hertel and V Hewes and A.
		  Higuera and T. Hill and S. J. Hillier and A. Himmel and J.
		  Hoff and C. Hohl and A. Holin and E. Hoppe and G. A.
		  Horton-Smith and M. Hostert and A. Hourlier and B. Howard
		  and R. Howell and J. Huang and J. Huang and J. Hugon and G.
		  Iles and N. Ilic and A. M. Iliescu and R. Illingworth and
		  A. Ioannisian and L. Isenhower and R. Itay and A. Izmaylov
		  and S. Jackson and V. Jain and E. James and B. Jargowsky
		  and F. Jediny and D. Jena and Y. S. Jeong and C.
		  Jes\'{u}s-Valls and X. Ji and L. Jiang and S. Jim\'{e}nez
		  and A. Jipa and R. Johnson and B. Jones and S. B. Jones and
		  M. Judah and C. K. Jung and T. Junk and Y. Jwa and M.
		  Kabirnezhad and A. Kaboth and I. Kadenko and I. Kakorin and
		  F. Kamiya and N. Kaneshige and G. Karagiorgi and G. Karaman
		  and A. Karcher and M. Karolak and Y. Karyotakis and S.
		  Kasai and S. P. Kasetti and L. Kashur and N. Kazaryan and
		  E. Kearns and P. Keener and K. J. Kelly and E. Kemp and O.
		  Kemularia and W. Ketchum and S. H. Kettell and M.
		  Khabibullin and A. Khotjantsev and A. Khvedelidze and D.
		  Kim and B. King and B. Kirby and M. Kirby and J. Klein and
		  K. Koehler and L. W. Koerner and S. Kohn and P. P. Koller
		  and L. Kolupaeva and M. Kordosky and T. Kosc and U. Kose
		  and V. A. Kosteleck\'{y} and K. Kothekar and F. Krennrich
		  and I. Kreslo and Y. Kudenko and V. A. Kudryavtsev and S.
		  Kulagin and J. Kumar and P. Kumar and P. Kunze and N.
		  Kurita and C. Kuruppu and V. Kus and T. Kutter and A.
		  Lambert and B. Land and K. Lande and C. E. Lane and K. Lang
		  and T. Langford and J. Larkin and P. Lasorak and D. Last
		  and C. Lastoria and A. Laundrie and A. Lawrence and I.
		  Lazanu and R. LaZur and T. Le and S. Leardini and J.
		  Learned and P. LeBrun and T. LeCompte and G. Lehmann Miotto
		  and R. Lehnert and M. A. Leigui de Oliveira and M. Leitner
		  and L. Li and S. W. Li and T. Li and Y. Li and H. Liao and
		  C. S. Lin and Q. Lin and S. Lin and A. Lister and B. R.
		  Littlejohn and J. Liu and S. Lockwitz and T. Loew and M.
		  Lokajicek and I. Lomidze and K. Long and K. Loo and D.
		  Lorca and T. Lord and J. M. LoSecco and W. C. Louis and X.
		  -G. Lu and K. B. Luk and X. Luo and N. Lurkin and T. Lux
		  and V. P. Luzio and D. MacFarlane and A. A. Machado and P.
		  Machado and C. T. Macias and J. R. Macier and A. Maddalena
		  and A. Madera and P. Madigan and S. Magill and K. Mahn and
		  A. Maio and A. Major and J. A. Maloney and G. Mandrioli and
		  R. C. Mandujano and J. Maneira and L. Manenti and S. Manly
		  and A. Mann and K. Manolopoulos and M. Manrique Plata and
		  V. N. Manyam and L. Manzanillas and M. Marchan and A.
		  Marchionni and W. Marciano and D. Marfatia and C. Mariani
		  and J. Maricic and R. Marie and F. Marinho and A. D. Marino
		  and D. Marsden and M. Marshak and C. M. Marshall and J.
		  Marshall and J. Marteau and J. Martin-Albo and N. Martinez
		  and D. A. Martinez Caicedo and S. Martynenko and K. Mason
		  and A. Mastbaum and M. Masud and S. Matsuno and J. Matthews
		  and C. Mauger and N. Mauri and K. Mavrokoridis and I. Mawby
		  and R. Mazza and A. Mazzacane and E. Mazzucato and T.
		  McAskill and E. McCluskey and N. McConkey and K. S.
		  McFarland and C. McGrew and A. McNab and A. Mefodiev and P.
		  Mehta and P. Melas and O. Mena and S. Menary and H. Mendez
		  and D. P. M{\'e}ndez and A. Menegolli and G. Meng and M. D.
		  Messier and W. Metcalf and T. Mettler and M. Mewes and H.
		  Meyer and T. Miao and G. Michna and T. Miedema and J.
		  Migenda and V. Mikola and R. Milincic and W. Miller and J.
		  Mills and C. Milne and O. Mineev and O. G. Miranda and S.
		  Miryala and C. S. Mishra and S. R. Mishra and A. Mislivec
		  and D. Mladenov and I. Mocioiu and K. Moffat and N. Moggi
		  and R. Mohanta and T. A. Mohayai and N. Mokhov and J.
		  Molina and L. Molina Bueno and A. Montanari and C.
		  Montanari and D. Montanari and L. M. Montano Zetina and J.
		  Moon and M. Mooney and A. F. Moor and D. Moreno and C.
		  Morris and C. Mossey and E. Motuk and C. A. Moura and J.
		  Mousseau and W. Mu and L. Mualem and J. Mueller and M.
		  Muether and S. Mufson and F. Muheim and A. Muir and M.
		  Mulhearn and D. Munford and H. Muramatsu and S. Murphy and
		  J. Musser and J. Nachtman and S. Nagu and M. Nalbandyan and
		  R. Nandakumar and D. Naples and S. Narita and D.
		  Navas-Nicol\'{a}s and A. Navrer-Agasson and N. Nayak and M.
		  Nebot-Guinot and K. Negishi and J. K. Nelson and J. Nesbit
		  and M. Nessi and D. Newbold and M. Newcomer and D. Newhart
		  and H. Newton and R. Nichol and F. Nicolas-Arnaldos and E.
		  Niner and K. Nishimura and A. Norman and A. Norrick and R.
		  Northrop and P. Novella and J. A. Nowak and M. Oberling and
		  J. P. Ochoa-Ricoux and A. Olivares Del Campo and A. Olivier
		  and A. Olshevskiy and Y. Onel and Y. Onishchuk and J. Ott
		  and L. Pagani and S. Pakvasa and G. Palacio and O. Palamara
		  and S. Palestini and J. M. Paley and M. Pallavicini and C.
		  Palomares and J. L. Palomino-Gallo and E. Pantic and V.
		  Paolone and V. Papadimitriou and R. Papaleo and A.
		  Papanestis and S. Paramesvaran and S. Parke and Z. Parsa
		  and M. Parvu and S. Pascoli and L. Pasqualini and J.
		  Pasternak and J. Pater and C. Patrick and L. Patrizii and
		  R. B. Patterson and S. J. Patton and T. Patzak and A.
		  Paudel and B. Paulos and L. Paulucci and Z. Pavlovic and G.
		  Pawloski and D. Payne and V. Pec and S. J. M. Peeters and
		  E. Pennacchio and A. Penzo and O. L. G. Peres and J. Perry
		  and D. Pershey and G. Pessina and G. Petrillo and C. Petta
		  and R. Petti and F. Piastra and L. Pickering and F.
		  Pietropaolo and R. Plunkett and R. Poling and X. Pons and
		  N. Poonthottathil and S. Pordes and J. Porter and M.
		  Potekhin and R. Potenza and B. V. K. S. Potukuchi and J.
		  Pozimski and M. Pozzato and S. Prakash and T. Prakash and
		  S. Prince and D. Pugnere and X. Qian and M. C. Queiroga
		  Bazetto and J. L. Raaf and V. Radeka and J. Rademacker and
		  B. Radics and A. Rafique and E. Raguzin and M. Rai and M.
		  Rajaoalisoa and I. Rakhno and A. Rakotonandrasana and L.
		  Rakotondravohitra and Y. A. Ramachers and R. Rameika and M.
		  A. Ramirez Delgado and B. Ramson and A. Rappoldi and G.
		  Raselli and P. Ratoff and S. Raut and R. F. Razakamiandra
		  and J. S. Real and B. Rebel and M. Reggiani-Guzzo and T.
		  Rehak and J. Reichenbacher and S. D. Reitzner and H. Rejeb
		  Sfar and A. Renshaw and S. Rescia and F. Resnati and A.
		  Reynolds and C. Riccio and G. Riccobene and L. C. J. Rice
		  and J. Ricol and A. Rigamonti and Y. Rigaut and D. Rivera
		  and L. Rochester and M. Roda and P. Rodrigues and M. J.
		  Rodriguez Alonso and E. Rodriguez Bonilla and J. Rodriguez
		  Rondon and S. Rosauro-Alcaraz and M. Rosenberg and P.
		  Rosier and B. Roskovec and M. Rossella and J. Rout and P.
		  Roy and S. Roy and A. Rubbia and C. Rubbia and F. C. Rubio
		  and B. Russell and D. Ruterbories and R. Saakyan and S.
		  Sacerdoti and T. Safford and R. Sahay and N. Sahu and P.
		  Sala and N. Samios and O. Samoylov and M. C. Sanchez and D.
		  A. Sanders and D. Sankey and S. Santana and M.
		  Santos-Maldonado and N. Saoulidou and P. Sapienza and C.
		  Sarasty and I. Sarcevic and G. Savage and V. Savinov and A.
		  Scaramelli and A. Scarff and A. Scarpelli and T. Schaffer
		  and H. Schellman and P. Schlabach and D. Schmitz and K.
		  Scholberg and A. Schukraft and E. Segreto and J. Sensenig
		  and I. Seong and A. Sergi and D. Sgalaberna and M. H.
		  Shaevitz and S. Shafaq and M. Shamma and R. Sharankova and
		  H. R. Sharma and R. Sharma and R. Kumar and T. Shaw and C.
		  Shepherd-Themistocleous and S. Shin and D. Shooltz and R.
		  Shrock and L. Simard and F. Simon and N. Simos and J.
		  Sinclair and G. Sinev and J. Singh and J. Singh and V.
		  Singh and R. Sipos and F. W. Sippach and G. Sirri and A.
		  Sitraka and K. Siyeon and K. Skarpaas VIII and A. Smith and
		  E. Smith and P. Smith and J. Smolik and M. Smy and E. L.
		  Snider and P. Snopok and M. Soares Nunes and H. Sobel and
		  M. Soderberg and C. J. Solano Salinas and S.
		  S\"{o}ldner-Rembold and N. Solomey and V. Solovov and W. E.
		  Sondheim and M. Sorel and J. Soto-Oton and A. Sousa and K.
		  Soustruznik and F. Spagliardi and M. Spanu and J. Spitz and
		  N. J. C. Spooner and K. Spurgeon and R. Staley and M.
		  Stancari and L. Stanco and R. Stanley and R. Stein and H.
		  M. Steiner and J. Stewart and B. Stillwell and J. Stock and
		  F. Stocker and T. Stokes and M. Strait and T. Strauss and
		  S. Striganov and A. Stuart and J. G. Suarez and H. Sullivan
		  and D. Summers and A. Surdo and V. Susic and L. Suter and
		  C. M. Sutera and R. Svoboda and B. Szczerbinska and A. M.
		  Szelc and R. Talaga and H. A. Tanaka and B. Tapia Oregui
		  and A. Tapper and S. Tariq and E. Tatar and R. Tayloe and
		  A. M. Teklu and M. Tenti and K. Terao and C. A. Ternes and
		  F. Terranova and G. Testera and A. Thea and J. L. Thompson
		  and C. Thorn and S. C. Timm and J. Todd and A. Tonazzo and
		  D. Torbunov and M. Torti and M. Tortola and F. Tortorici
		  and D. Totani and M. Toups and C. Touramanis and J. Trevor
		  and S. Trilov and W. H. Trzaska and Y. T. Tsai and Z.
		  Tsamalaidze and K. V. Tsang and N. Tsverava and S. Tufanli
		  and C. Tull and E. Tyley and M. Tzanov and M. A. Uchida and
		  J. Urheim and T. Usher and S. Uzunyan and M. R. Vagins and
		  P. Vahle and G. A. Valdiviesso and E. Valencia and Z.
		  Vallari and J. W. F. Valle and S. Vallecorsa and R. Van
		  Berg and R. G. Van de Water and F. Varanini and D. Vargas
		  and G. Varner and J. Vasel and S. Vasina and G. Vasseur and
		  N. Vaughan and K. Vaziri and S. Ventura and A. Verdugo and
		  S. Vergani and M. A. Vermeulen and M. Verzocchi and M.
		  Vicenzi and H. Vieira de Souza and C. Vignoli and C. Vilela
		  and B. Viren and T. Vrba and T. Wachala and A. V. Waldron
		  and M. Wallbank and H. Wang and J. Wang and M. H. L. S.
		  Wang and Y. Wang and Y. Wang and K. Warburton and D. Warner
		  and M. Wascko and D. Waters and A. Watson and P. Weatherly
		  and A. Weber and M. Weber and H. Wei and A. Weinstein and
		  D. Wenman and M. Wetstein and A. White and L. H. Whitehead
		  and D. Whittington and M. J. Wilking and C. Wilkinson and
		  Z. Williams and F. Wilson and R. J. Wilson and J. Wolcott
		  and T. Wongjirad and A. Wood and K. Wood and E. Worcester
		  and M. Worcester and C. Wret and W. Wu and W. Wu and Y.
		  Xiao and E. Yandel and G. Yang and K. Yang and S. Yang and
		  T. Yang and A. Yankelevich and N. Yershov and K. Yonehara
		  and T. Young and B. Yu and H. Yu and J. Yu and W. Yuan and
		  R. Zaki and J. Zalesak and L. Zambelli and B. Zamorano and
		  A. Zani and L. Zazueta and G. Zeit and G. P. Zeller and J.
		  Zennamo and K. Zeug and C. Zhang and M. Zhao and E. Zhivun
		  and G. Zhu and P. Zilberman and E. D. Zimmerman and M. Zito
		  and S. Zucchelli and J. Zuklin and V. Zutshi and R. Zwaska},
  year		= {2021},
  howpublished	= {arXiv},
  primaryclass	= {physics.ins-det},
  url		= {https://arxiv.org/abs/2103.13910}
}

@misc{	  allenai:arc,
  author	= {Peter Clark and Isaac Cowhey and Oren Etzioni and Tushar
		  Khot and Ashish Sabharwal and Carissa Schoenick and Oyvind
		  Tafjord},
  title		= {Think you have Solved Question Answering? Try ARC, the AI2
		  Reasoning Challenge},
  howpublished	= {arXiv:1803.05457v1},
  year		= {2018},
  doi		= {10.48550/arXiv.1803.05457}
}

@Misc{		  bowles2024betterclassicalsubtleart,
  title		= {Better than classical? The subtle art of benchmarking
		  quantum machine learning models},
  author	= {Joseph Bowles and Shahnawaz Ahmed and Maria Schuld},
  year		= {2024},
  howpublished	= {arXiv},
  primaryclass	= {quant-ph},
  url		= {https://arxiv.org/abs/2403.07059}
}

@Misc{		  campolongo2025buildingmachinelearningchallenges,
  howpublished	= {arXiv},
  author	= {Elizabeth G. Campolongo and Yuan-Tang Chou and Ekaterina
		  Govorkova and Wahid Bhimji and Wei-Lun Chao and Chris
		  Harris and Shih-Chieh Hsu and Hilmar Lapp and Mark S.
		  Neubauer and Josephine Namayanja and Aneesh Subramanian and
		  Philip Harris and Advaith Anand and David E. Carlyn and
		  Subhankar Ghosh and Christopher Lawrence and Eric Moreno
		  and Ryan Raikman and Jiaman Wu and Ziheng Zhang and Bayu
		  Adhi and Mohammad Ahmadi Gharehtoragh and Saúl Alonso
		  Monsalve and Marta Babicz and Furqan Baig and Namrata
		  Banerji and William Bardon and Tyler Barna and Tanya
		  Berger-Wolf and Adji Bousso Dieng and Micah Brachman and
		  Quentin Buat and David C. Y. Hui and Phuong Cao and Franco
		  Cerino and Yi-Chun Chang and Shivaji Chaulagain and An-Kai
		  Chen and Deming Chen and Eric Chen and Chia-Jui Chou and
		  Zih-Chen Ciou and Miles Cochran-Branson and Artur Cordeiro
		  Oudot Choi and Michael Coughlin and Matteo Cremonesi and
		  Maria Dadarlat and Peter Darch and Malina Desai and Daniel
		  Diaz and Steven Dillmann and Javier Duarte and Isla Duporge
		  and Urbas Ekka and Saba Entezari Heravi and Hao Fang and
		  Rian Flynn and Geoffrey Fox and Emily Freed and Hang Gao
		  and Jing Gao and Julia Gonski and Matthew Graham and
		  Abolfazl Hashemi and Scott Hauck and James Hazelden and
		  Joshua Henry Peterson and Duc Hoang and Wei Hu and Mirco
		  Huennefeld and David Hyde and Vandana Janeja and Nattapon
		  Jaroenchai and Haoyi Jia and Yunfan Kang and Maksim
		  Kholiavchenko and Elham E. Khoda and Sangin Kim and Aditya
		  Kumar and Bo-Cheng Lai and Trung Le and Chi-Wei Lee and
		  JangHyeon Lee and Shaocheng Lee and Suzan van der Lee and
		  Charles Lewis and Haitong Li and Haoyang Li and Henry Liao
		  and Mia Liu and Xiaolin Liu and Xiulong Liu and Vladimir
		  Loncar and Fangzheng Lyu and Ilya Makarov and Abhishikth
		  Mallampalli Chen-Yu Mao and Alexander Michels and Alexander
		  Migala and Farouk Mokhtar and Mathieu Morlighem and Min
		  Namgung and Andrzej Novak and Andrew Novick and Amy Orsborn
		  and Anand Padmanabhan and Jia-Cheng Pan and Sneh Pandya and
		  Zhiyuan Pei and Ana Peixoto and George Percivall and Alex
		  Po Leung and Sanjay Purushotham and Zhiqiang Que and
		  Melissa Quinnan and Arghya Ranjan and Dylan Rankin and
		  Christina Reissel and Benedikt Riedel and Dan Rubenstein
		  and Argyro Sasli and Eli Shlizerman and Arushi Singh and
		  Kim Singh and Eric R. Sokol and Arturo Sorensen and Yu Su
		  and Mitra Taheri and Vaibhav Thakkar and Ann Mariam Thomas
		  and Eric Toberer and Chenghan Tsai and Rebecca Vandewalle
		  and Arjun Verma and Ricco C. Venterea and He Wang and
		  Jianwu Wang and Sam Wang and Shaowen Wang and Gordon Watts
		  and Jason Weitz and Andrew Wildridge and Rebecca Williams
		  and Scott Wolf and Yue Xu and Jianqi Yan and Jai Yu and
		  Yulei Zhang and Haoran Zhao and Ying Zhao and Yibo Zhong},
  eprint	= {2503.02112},
  primaryclass	= {cs.LG},
  title		= {Building Machine Learning Challenges for Anomaly Detection
		  in Science},
  url		= {https://arxiv.org/abs/2503.02112},
  year		= {2025}
}

@Article{	  chanussot2021oc20,
  title		= {The Open Catalyst 2020 (OC20) Dataset and Community
		  Challenges},
  author	= {Chanussot, Lowik and Das, Abhishek and Goyal, Siddharth
		  and Lavril, Thibaut and Shuaibi, Muhammed and Riviere,
		  Morgane and Tran, Kevin and Heras-Domingo, Javier and Ho,
		  Caleb and Hu, Weihua and Palizhati, Aini and Sriram,
		  Anuroop and Wood, Brandon and Yoon, Junwoong and Parikh,
		  Devi and Zitnick, C. Lawrence and Ulissi, Zachary},
  journal	= {ACS Catalysis},
  volume	= {11},
  number	= {10},
  pages		= {6059--6072},
  year		= {2021},
  doi		= {10.1021/acscatal.0c04525},
  url		= {https://pubs.acs.org/doi/10.1021/acscatal.0c04525}
}

@Misc{		  cui2025curieevaluatingllmsmultitask,
  title		= {CURIE: Evaluating LLMs On Multitask Scientific Long
		  Context Understanding and Reasoning},
  author	= {Hao Cui and Zahra Shamsi and Gowoon Cheon and Xuejian Ma
		  and Shutong Li and Maria Tikhanovskaya and Peter Norgaard
		  and Nayantara Mudur and Martyna Plomecka and Paul Raccuglia
		  and Yasaman Bahri and Victor V. Albert and Pranesh
		  Srinivasan and Haining Pan and Philippe Faist and Brian
		  Rohr and Ekin Dogus Cubuk and Muratahan Aykol and Amil
		  Merchant and Michael J. Statt and Dan Morris and Drew
		  Purves and Elise Kleeman and Ruth Alcantara and Matthew
		  Abraham and Muqthar Mohammad and Ean Phing VanLee and
		  Chenfei Jiang and Elizabeth Dorfman and Eun-Ah Kim and
		  Michael P Brenner and Viren Jain and Sameera Ponda and
		  Subhashini Venugopalan},
  year		= {2025},
  eprint	= {2503.13517},
  howpublished	= {arXiv},
  primaryclass	= {cs.CL},
  url		= {https://arxiv.org/abs/2503.13517}
}

@Misc{		  diguglielmo2025endtoendworkflowmachinelearningbased,
  howpublished	= {arXiv},
  author	= {Giuseppe Di Guglielmo and Botao Du and Javier Campos and
		  Alexandra Boltasseva and Akash V. Dixit and Farah Fahim and
		  Zhaxylyk Kudyshev and Santiago Lopez and Ruichao Ma and
		  Gabriel N. Perdue and Nhan Tran and Omer Yesilyurt and
		  Daniel Bowring},
  eprint	= {2501.14663},
  primaryclass	= {quant-ph},
  title		= {End-to-end workflow for machine learning-based qubit
		  readout with QICK and hls4ml},
  url		= {https://arxiv.org/abs/2501.14663},
  year		= {2025}
}

@Misc{		  duarte2022fastml,
  howpublished	= {arXiv},
  author	= {Javier Duarte and Nhan Tran and Ben Hawks and Christian
		  Herwig and Jules Muhizi and Shvetank Prakash and Vijay
		  Janapa Reddi},
  eprint	= {2207.07958},
  primaryclass	= {cs.LG},
  title		= {FastML Science Benchmarks: Accelerating Real-Time
		  Scientific Edge Machine Learning},
  url		= {https://arxiv.org/abs/2207.07958},
  year		= {2022}
}

@Misc{		  fang2024domainagnosticmoleculargenerationchemical,
  howpublished	= {arXiv},
  author	= {Yin Fang and Ningyu Zhang and Zhuo Chen and Lingbing Guo
		  and Xiaohui Fan and Huajun Chen},
  eprint	= {2301.11259},
  primaryclass	= {cs.LG},
  title		= {Domain-Agnostic Molecular Generation with Chemical
		  Feedback},
  url		= {https://arxiv.org/abs/2301.11259},
  year		= {2024}
}

@Misc{		  farrell2021mlperfhpcholisticbenchmark,
  howpublished	= {arXiv},
  author	= {Steven Farrell and Murali Emani and Jacob Balma and Lukas
		  Drescher and Aleksandr Drozd and Andreas Fink and Geoffrey
		  Fox and David Kanter and Thorsten Kurth and Peter Mattson
		  and Dawei Mu and Amit Ruhela and Kento Sato and Koichi
		  Shirahata and Tsuguchika Tabaru and Aristeidis Tsaris and
		  Jan Balewski and Ben Cumming and Takumi Danjo and Jens
		  Domke and Takaaki Fukai and Naoto Fukumoto and Tatsuya
		  Fukushi and Balazs Gerofi and Takumi Honda and Toshiyuki
		  Imamura and Akihiko Kasagi and Kentaro Kawakami and Shuhei
		  Kudo and Akiyoshi Kuroda and Maxime Martinasso and Satoshi
		  Matsuoka and Henrique Mendonça and Kazuki Minami and
		  Prabhat Ram and Takashi Sawada and Mallikarjun Shankar and
		  Tom St. John and Akihiro Tabuchi and Venkatram Vishwanath
		  and Mohamed Wahib and Masafumi Yamazaki and Junqi Yin},
  eprint	= {2110.11466},
  primaryclass	= {cs.LG},
  title		= {MLPerf HPC: A Holistic Benchmark Suite for Scientific
		  Machine Learning on HPC Systems},
  url		= {https://arxiv.org/abs/2110.11466},
  year		= {2021}
}

@Misc{glazer2024frontiermathbenchmarkevaluatingadvanced,
  howpublished	= {arXiv},
  author	= {Elliot Glazer and Ege Erdil and Tamay Besiroglu and Diego
		  Chicharro and Evan Chen and Alex Gunning and Caroline
		  Falkman Olsson and Jean-Stanislas Denain and Anson Ho and
		  Emily de Oliveira Santos and Olli J\"{a}rviniemi and
		  Matthew Barnett and Robert Sandler and Matej Vrzala and
		  Jaime Sevilla and Qiuyu Ren and Elizabeth Pratt and Lionel
		  Levine and Grant Barkley and Natalie Stewart and Bogdan
		  Grechuk and Tetiana Grechuk and Shreepranav Varma Enugandla
		  and Mark Wildon},
  eprint	= {2411.04872},
  primaryclass	= {cs.AI},
  title		= {{FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI}},
  url		= {https://arxiv.org/abs/2411.04872},
  year		= {2024}
}

@Misc{hendrycks2021measuring,
  title		= {{Measuring Massive Multitask Language Understanding}},
  author	= {Hendrycks, Dan and Burns, Collin and Kadavath, Saurav},
  journal	= {arXiv preprint arXiv:2009.03300},
  year		= {2021},
  url		= {https://arxiv.org/abs/2009.03300}
}

@Misc{https://doi.org/10.5281/zenodo.5046389,
  author	= {Aarrestad, Thea and Govorkova, Ekaterina and Ngadiuba, Jennifer and Puljak, Ema and Pierini, Maurizio and Wozniak, Kinga Anna},
  copyright	= {Creative Commons Attribution 4.0 International},
  doi		= {10.5281/ZENODO.5046389},
  publisher	= {Zenodo},
  title		= {{Unsupervised New Physics detection at 40 MHz: Training Dataset}},
  url		= {https://zenodo.org/record/5046389},
  year		= {2021}
}

@Misc{hu2021opengraphbenchmarkdatasets,
  howpublished	= {arXiv},
  author	= {Weihua Hu and Matthias Fey and Marinka Zitnik and Yuxiao Dong and Hongyu Ren and Bowen Liu and Michele Catasta and Jure Leskovec},
  eprint	= {2005.00687},
  primaryclass	= {cs.LG},
  title		= {{Open Graph Benchmark: Datasets for Machine Learning on Graphs}},
  url		= {https://arxiv.org/abs/2005.00687},
  year		= {2021}
}

@Article{jain2013materials,
  title = {{The Materials Project: A Materials Genome Approach}},
  author	= {Jain, Anubhav and Ong, Shyue Ping and Hautier, Geoffroy and Chen, Wei and Richards, William Davidson and Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and Skinner, David and Ceder, Gerbrand and Persson, Kristin A.},
  journal	= {APL Materials},
  volume	= {1},
  number	= {1},
  year		= {2013},
  doi		= {10.1063/1.4812323},
  url		= {https://materialsproject.org/}
}

@Misc{jin2020diseasedoespatienthave,
  howpublished	= {arXiv},
  author	= {Di Jin and Eileen Pan and Nassim Oufattole and Wei-Hung
		  Weng and Hanyi Fang and Peter Szolovits},
  eprint	= {2009.13081},
  primaryclass	= {cs.CL},
  title		= {What Disease does this Patient Have? A Large-scale Open
		  Domain Question Answering Dataset from Medical Exams},
  url		= {https://arxiv.org/abs/2009.13081},
  year		= {2020}
}

@Misc{		  kafkes2021boostrdatasetacceleratorcontrol,
  howpublished	= {arXiv},
  author	= {Diana Kafkes and Jason St. John},
  eprint	= {2101.08359},
  primaryclass	= {physics.acc-ph},
  title		= {BOOSTR: A Dataset for Accelerator Control Systems},
  url		= {https://arxiv.org/abs/2101.08359},
  year		= {2021}
}

@Article{	  karargyris2023federated,
  author	= {Karargyris, Alexandros and Umeton, Renato and Sheller,
		  Micah J. and Aristizabal, Alejandro and George, Johnu and
		  Wuest, Anna and Pati, Sarthak and Kassem, Hasan and Zenk,
		  Maximilian and Baid, Ujjwal and Narayana Moorthy, Prakash
		  and Chowdhury, Alexander and Guo, Junyi and Nalawade, Sahil
		  and Rosenthal, Jacob and Kanter, David and Xenochristou,
		  Maria and Beutel, Daniel J. and Chung, Verena and
		  Bergquist, Timothy and Eddy, James and Abid, Abubakar and
		  Tunstall, Lewis and Sanseviero, Omar and Dimitriadis,
		  Dimitrios and Qian, Yiming and Xu, Xinxing and Liu, Yong
		  and Goh, Rick Siow Mong and Bala, Srini and Bittorf, Victor
		  and Puchala, Sreekar Reddy and Ricciuti, Biagio and
		  Samineni, Soujanya and Sengupta, Eshna and Chaudhari,
		  Akshay and Coleman, Cody and Desinghu, Bala and Diamos,
		  Gregory and Dutta, Debo and Feddema, Diane and Fursin,
		  Grigori and Huang, Xinyuan and Kashyap, Satyananda and
		  Lane, Nicholas and Mallick, Indranil and Mascagni, Pietro
		  and Mehta, Virendra and Moraes, Cassiano Ferro and
		  Natarajan, Vivek and Nikolov, Nikola and Padoy, Nicolas and
		  Pekhimenko, Gennady and Reddi, Vijay Janapa and Reina, G.
		  Anthony and Ribalta, Pablo and Singh, Abhishek and
		  Thiagarajan, Jayaraman J. and Albrecht, Jacob and Wolf,
		  Thomas and Miller, Geralyn and Fu, Huazhu and Shah,
		  Prashant and Xu, Daguang and Yadav, Poonam and Talby, David
		  and Awad, Mark M. and Howard, Jeremy P. and Rosenthal,
		  Michael and Marchionni, Luigi and Loda, Massimo and
		  Johnson, Jason M. and Bakas, Spyridon and Mattson, Peter
		  and FeTS Consortium and BraTS-2020 Consortium and
		  AI4SafeChole Consortium},
  month		= jul,
  doi		= {10.1038/s42256-023-00652-2},
  journal	= {Nature Machine Intelligence},
  number	= {7},
  pages		= {799--810},
  title		= {Federated benchmarking of medical artificial intelligence
		  with MedPerf},
  url		= {https://doi.org/10.1038/s42256-023-00652-2},
  volume	= {5},
  year		= {2023}
}

@Misc{		  khrabrov2024nabla2dftuniversalquantumchemistry,
  title		= {Delta-Squared DFT: A Universal Quantum Chemistry Dataset
		  of Drug-Like Molecules and a Benchmark for Neural Network
		  Potentials},
  author	= {Kuzma Khrabrov and Anton Ber and Artem Tsypin and
		  Konstantin Ushenin and Egor Rumiantsev and Alexander
		  Telepov and Dmitry Protasov and Ilya Shenbin and Anton
		  Alekseev and Mikhail Shirokikh and Sergey Nikolenko and
		  Elena Tutubalina and Artur Kadurin},
  year		= {2024},
  eprint	= {2406.14347},
  howpublished	= {arXiv},
  primaryclass	= {physics.chem-ph},
  url		= {https://arxiv.org/abs/2406.14347}
}

@Misc{		  krause2024calochallenge2022communitychallenge,
  howpublished	= {arXiv},
  author	= {Claudius Krause and Michele Faucci Giannelli and Gregor
		  Kasieczka and Benjamin Nachman and Dalila Salamani and
		  David Shih and Anna Zaborowska and Oz Amram and Kerstin
		  Borras and Matthew R. Buckley and Erik Buhmann and Thorsten
		  Buss and Renato Paulo Da Costa Cardoso and Anthony L.
		  Caterini and Nadezda Chernyavskaya and Federico A. G.
		  Corchia and Jesse C. Cresswell and Sascha Diefenbacher and
		  Etienne Dreyer and Vijay Ekambaram and Engin Eren and
		  Florian Ernst and Luigi Favaro and Matteo Franchini and
		  Frank Gaede and Eilam Gross and Shih-Chieh Hsu and Kristina
		  Jaruskova and Benno Käch and Jayant Kalagnanam and Raghav
		  Kansal and Taewoo Kim and Dmitrii Kobylianskii and Anatolii
		  Korol and William Korcari and Dirk Krücker and Katja
		  Krüger and Marco Letizia and Shu Li and Qibin Liu and
		  Xiulong Liu and Gabriel Loaiza-Ganem and Thandikire Madula
		  and Peter McKeown and Isabell-A. Melzer-Pellmann and
		  Vinicius Mikuni and Nam Nguyen and Ayodele Ore and Sofia
		  Palacios Schweitzer and Ian Pang and Kevin Pedro and Tilman
		  Plehn and Witold Pokorski and Huilin Qu and Piyush Raikwar
		  and John A. Raine and Humberto Reyes-Gonzalez and Lorenzo
		  Rinaldi and Brendan Leigh Ross and Moritz A. W. Scham and
		  Simon Schnake and Chase Shimmin and Eli Shlizerman and
		  Nathalie Soybelman and Mudhakar Srivatsa and Kalliopi
		  Tsolaki and Sofia Vallecorsa and Kyongmin Yeo and Rui
		  Zhang},
  eprint	= {2410.21611},
  primaryclass	= {physics.ins-det},
  title		= {CaloChallenge 2022: A Community Challenge for Fast
		  Calorimeter Simulation},
  url		= {https://arxiv.org/abs/2410.21611},
  year		= {2024}
}

@Misc{		  kvapil2025intelligentexperimentsrealtimeai,
  howpublished	= {arXiv},
  author	= {J. Kvapil and G. Borca-Tasciuc and H. Bossi and K. Chen
		  and Y. Chen and Y. Corrales Morales and H. Da Costa and C.
		  Da Silva and C. Dean and J. Durham and S. Fu and C. Hao and
		  P. Harris and O. Hen and H. Jheng and Y. Lee and P. Li and
		  X. Li and Y. Lin and M. X. Liu and V. Loncar and J. P.
		  Mitrevski and A. Olvera and M. L. Purschke and J. S. Renck
		  and G. Roland and J. Schambach and Z. Shi and N. Tran and
		  N. Wuerfel and B. Xu and D. Yu and H. Zhang},
  eprint	= {2501.04845},
  primaryclass	= {physics.ins-det},
  title		= {Intelligent experiments through real-time AI: Fast Data
		  Processing and Autonomous Detector Control for sPHENIX and
		  future EIC detectors},
  url		= {https://arxiv.org/abs/2501.04845},
  year		= {2025}
}

@Article{	  lightman2023lets,
  title		= {Let's Verify Step by Step},
  author	= {Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and
		  Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike,
		  Jan and Schulman, John and Sutskever, Ilya and Cobbe,
		  Karl},
  journal	= {arXiv preprint arXiv:2305.20050},
  year		= {2023},
  eprint	= {arXiv:2305.20050},
  doi		= {10.48550/arXiv.2305.20050}
}

@Misc{		  liu2021braggnnfastxraybragg,
  howpublished	= {arXiv},
  author	= {Zhengchun Liu and Hemant Sharma and Jun-Sang Park and
		  Peter Kenesei and Antonino Miceli and Jonathan Almer and
		  Rajkumar Kettimuthu and Ian Foster},
  eprint	= {2008.08198},
  primaryclass	= {eess.IV},
  title		= {BraggNN: Fast X-ray Bragg Peak Analysis Using Deep
		  Learning},
  url		= {https://arxiv.org/abs/2008.08198},
  year		= {2021}
}

@Misc{		  luo2024cfdbenchlargescalebenchmarkmachine,
  title		= {CFDBench: A Large-Scale Benchmark for Machine Learning
		  Methods in Fluid Dynamics},
  author	= {Luo, Yining and Chen, Yingfa and Zhang, Zhen},
  year		= {2024},
  url		= {https://arxiv.org/abs/2310.05963}
}

@Misc{		  luo2025benchmarkingaiscientistsomics,
  howpublished	= {arXiv},
  author	= {Erpai Luo and Jinmeng Jia and Yifan Xiong and Xiangyu Li
		  and Xiaobo Guo and Baoqi Yu and Lei Wei and Xuegong Zhang},
  eprint	= {2505.08341},
  primaryclass	= {cs.AI},
  title		= {Benchmarking AI scientists in omics data-driven biological
		  research},
  url		= {https://arxiv.org/abs/2505.08341},
  year		= {2025}
}

@Misc{		  mudur2025feabenchevaluatinglanguagemodels,
  title		= {FEABench: Evaluating Language Models on Multiphysics
		  Reasoning Ability},
  author	= {Nayantara Mudur and Hao Cui and Subhashini Venugopalan and
		  Paul Raccuglia and Michael P. Brenner and Peter Norgaard},
  year		= {2025},
  eprint	= {2504.06260},
  howpublished	= {arXiv},
  primaryclass	= {cs.AI},
  url		= {https://arxiv.org/abs/2504.06260}
}

@InProceedings{neurips2024_0db7f135,
  author	= {Wang, Yiheng and Wang, Tianyu and Zhang, Yuying and Zhang,
		  Hongji and Zheng, Haoyu and Zheng, Guanjie and Kong,
		  Linghe},
  booktitle	= {Advances in Neural Information Processing Systems},
  editor	= {A. Globerson and L. Mackey and D. Belgrave and A. Fan and
		  U. Paquet and J. Tomczak and C. Zhang},
  pages		= {7296--7310},
  publisher	= {Curran Associates, Inc.},
  title		= {UrbanDataLayer: A Unified Data Pipeline for Urban
		  Science},
  url		= {https://proceedings.neurips.cc/paper_files/paper/2024/file/0db7f135f6991e8cec5e516ecc66bfba-Paper-Datasets_and_Benchmarks_Track.pdf},
  volume	= {37},
  year		= {2024}
}

@InProceedings{neurips2024_4f9a5acd,
  author	= {Ohana, Ruben and McCabe, Michael and Meyer, Lucas and
		  Morel, Rudy and Agocs, Fruzsina J. and Beneitez, Miguel and
		  Berger, Marsha and Burkhart, Blakesley and Dalziel, Stuart
		  B. and Fielding, Drummond B. and Fortunato, Daniel and
		  Goldberg, Jared A. and Hirashima, Keiya and Jiang, Yan-Fei
		  and Kerswell, Rich R. and Maddu, Suryanarayana and Miller,
		  Jonah and Mukhopadhyay, Payel and Nixon, Stefan S. and
		  Shen, Jeff and Watteaux, Romain and Blancard, Bruno
		  R\'{e}galdo-Saint and Rozet, Fran\c{c}ois and Parker, Liam
		  H. and Cranmer, Miles and Ho, Shirley},
  booktitle = {{Advances in Neural Information Processing Systems}},
  editor	= {A. Globerson and L. Mackey and D. Belgrave and A. Fan and
		  U. Paquet and J. Tomczak and C. Zhang},
  pages		= {44989--45037},
  publisher	= {Curran Associates, Inc.},
  title		= {The Well: a Large-Scale Collection of Diverse Physics
		  Simulations for Machine Learning},
  url		= {https://proceedings.neurips.cc/paper_files/paper/2024/file/4f9a5acd91ac76569f2fe291b1f4772b-Paper-Datasets_and_Benchmarks_Track.pdf},
  volume	= {37},
  year		= {2024}
}

@InProceedings{	  neurips2024_a8063075,
  author	= {Zou, Deyu and Liu, Shikun and Miao, Siqi and Fung, Victor
		  and Chang, Shiyu and Li, Pan},
  booktitle	= {Advances in Neural Information Processing Systems},
  editor	= {A. Globerson and L. Mackey and D. Belgrave and A. Fan and
		  U. Paquet and J. Tomczak and C. Zhang},
  pages		= {92499--92528},
  publisher	= {Curran Associates, Inc.},
  title		= {GeSS: Benchmarking Geometric Deep Learning under
		  Scientific Applications with Distribution Shifts},
  url		= {https://proceedings.neurips.cc/paper_files/paper/2024/file/a8063075b00168dc39bc81683619f1a8-Paper-Datasets_and_Benchmarks_Track.pdf},
  volume	= {37},
  year		= {2024}
}

@InProceedings{	  neurips2024_c00d37d6,
  author	= {Peterson, Ralph E and Tanelus, Aramis and Ick, Christopher
		  and Mimica, Bartul and Francis, Niegil and Ivan, Violet J
		  and Choudhri, Aman and Falkner, Annegret L and Murthy, Mala
		  and Schneider, David M and Sanes, Dan H and Williams, Alex
		  H},
  booktitle	= {Advances in Neural Information Processing Systems},
  editor	= {A. Globerson and L. Mackey and D. Belgrave and A. Fan and
		  U. Paquet and J. Tomczak and C. Zhang},
  pages		= {106370--106382},
  publisher	= {Curran Associates, Inc.},
  title		= {Vocal Call Locator Benchmark (VCL) for localizing rodent
		  vocalizations from multi-channel audio},
  url		= {https://proceedings.neurips.cc/paper_files/paper/2024/file/c00d37d6b04d73b870b963a4d70051c1-Paper-Datasets_and_Benchmarks_Track.pdf},
  volume	= {37},
  year		= {2024}
}

@InProceedings{	  neurips2024_c4e3b55e,
  author	= {Chen, Pin and Peng, Luoxuan and Jiao, Rui and Mo, Qing and
		  Wang, Zhen and Huang, Wenbing and Liu, Yang and Lu,
		  Yutong},
  booktitle	= {Advances in Neural Information Processing Systems},
  editor	= {A. Globerson and L. Mackey and D. Belgrave and A. Fan and
		  U. Paquet and J. Tomczak and C. Zhang},
  pages		= {108902--108928},
  publisher	= {Curran Associates, Inc.},
  title		= {Learning Superconductivity from Ordered and Disordered
		  Material Structures},
  url		= {https://proceedings.neurips.cc/paper_files/paper/2024/file/c4e3b55ed4ac9ba52d7df11f8bddbbf4-Paper-Datasets_and_Benchmarks_Track.pdf},
  volume	= {37},
  year		= {2024}
}

@InProceedings{	  neurips2024_c6c31413,
  author	= {Bushuiev, Roman and Bushuiev, Anton and de Jonge, Niek F.
		  and Young, Adamo and Kretschmer, Fleming and Samusevich,
		  Raman and Heirman, Janne and Wang, Fei and Zhang, Luke and
		  D\"{u}hrkop, Kai and Ludwig, Marcus and Haupt, Nils A. and
		  Kalia, Apurva and Brungs, Corinna and Schmid, Robin and
		  Greiner, Russell and Wang, Bo and Wishart, David S. and
		  Liu, Li-Ping and Rousu, Juho and Bittremieux, Wout and
		  Rost, Hannes and Mak, Tytus D. and Hassoun, Soha and Huber,
		  Florian and van der Hooft, Justin J.J. and Stravs, Michael
		  A. and B\"{o}cker, Sebastian and Sivic, Josef and Pluskal,
		  Tom\'{a}\v{s}},
  booktitle	= {Advances in Neural Information Processing Systems},
  editor	= {A. Globerson and L. Mackey and D. Belgrave and A. Fan and
		  U. Paquet and J. Tomczak and C. Zhang},
  pages		= {110010--110027},
  publisher	= {Curran Associates, Inc.},
  title		= {MassSpecGym: A benchmark for the discovery and
		  identification of molecules},
  url		= {https://proceedings.neurips.cc/paper_files/paper/2024/file/c6c31413d5c53b7d1c343c1498734b0f-Paper-Datasets_and_Benchmarks_Track.pdf},
  volume	= {37},
  year		= {2024}
}

@Misc{		  nguyen2023climatelearnbenchmarkingmachinelearning,
  title		= {ClimateLearn: Benchmarking Machine Learning for Weather
		  and Climate Modeling},
  author	= {Tung Nguyen and Jason Jewik and Hritik Bansal and Prakhar
		  Sharma and Aditya Grover},
  year		= {2023},
  eprint	= {2307.01909},
  howpublished	= {arXiv},
  primaryclass	= {cs.LG},
  url		= {https://arxiv.org/abs/2307.01909}
}

@Misc{		  nguyen2024seafloor,
  howpublished	= {arXiv},
  author	= {Kien X. Nguyen and Fengchun Qiao and Arthur Trembanis and
		  Xi Peng},
  eprint	= {2411.00172},
  primaryclass	= {cs.CV},
  title		= {SeafloorAI: A Large-scale Vision-Language Dataset for
		  Seafloor Geological Survey},
  url		= {https://arxiv.org/abs/2411.00172},
  year		= 2024
}

@Misc{		  odagiu2024ultrafastjetclassificationfpgas,
  howpublished	= {arXiv},
  author	= {Patrick Odagiu and Zhiqiang Que and Javier Duarte and
		  Johannes Haller and Gregor Kasieczka and Artur Lobanov and
		  Vladimir Loncar and Wayne Luk and Jennifer Ngadiuba and
		  Maurizio Pierini and Philipp Rincke and Arpita Seksaria and
		  Sioni Summers and Andre Sznajder and Alexander Tapper and
		  Thea K. Aarrestad},
  doi		= {https://doi.org/10.1088/2632-2153/ad5f10},
  eprint	= {2402.01876},
  primaryclass	= {hep-ex},
  title		= {Ultrafast jet classification on FPGAs for the HL-LHC},
  url		= {https://arxiv.org/abs/2402.01876},
  year		= {2024}
}

@Misc{		  parpillon2024smartpixelsinpixelai,
  howpublished	= {arXiv},
  author	= {Benjamin Parpillon and Chinar Syal and Jieun Yoo and
		  Jennet Dickinson and Morris Swartz and Giuseppe Di
		  Guglielmo and Alice Bean and Douglas Berry and Manuel
		  Blanco Valentin and Karri DiPetrillo and Anthony Badea and
		  Lindsey Gray and Petar Maksimovic and Corrinne Mills and
		  Mark S. Neubauer and Gauri Pradhan and Nhan Tran and Dahai
		  Wen and Farah Fahim},
  eprint	= {2406.14860},
  primaryclass	= {physics.ins-det},
  title		= {Smart Pixels: In-pixel AI for on-sensor data filtering},
  url		= {https://arxiv.org/abs/2406.14860},
  year		= {2024}
}

@Misc{		  pramanick2025spiqadatasetmultimodalquestion,
  title		= {SPIQA: A Dataset for Multimodal Question Answering on
		  Scientific Papers},
  author	= {Shraman Pramanick and Rama Chellappa and Subhashini
		  Venugopalan},
  year		= {2025},
  eprint	= {2407.09413},
  howpublished	= {arXiv},
  primaryclass	= {cs.CL},
  url		= {https://arxiv.org/abs/2407.09413}
}

@InProceedings{	  qin2023extremely,
  title		= {Extremely Noisy 4D-TEM Strain Mapping Using Cycle
		  Consistent Spatial Transforming Autoencoders},
  author	= {Shuyu Qin and Joshua Agar and Nhan Tran},
  booktitle	= {AI for Accelerated Materials Design - NeurIPS 2023
		  Workshop},
  year		= {2023},
  url		= {https://openreview.net/forum?id=7yt3N0o0W9}
}

@InProceedings{	  quench2024,
  author	= {Maira Khan and Steve Krave and Vittorio Marinozzi and
		  Jennifer Ngadiuba and Stoyan Stoynev and Nhan Tran},
  title		= {Benchmarking and Interpreting Real Time Quench Detection
		  Algorithms},
  booktitle	= {Fast Machine Learning for Science Conference 2024},
  year		= {2024},
  month		= oct,
  address	= {Purdue University, IN},
  publisher	= {indico.cern.ch},
  url		= {https://indico.cern.ch/event/1387540/contributions/6153618/attachments/2948441/5182077/fast_ml_magnets_2024_final.pdf}
}

@Misc{		  rein2023gpqagraduatelevelgoogleproofqa,
  title		= {GPQA: A Graduate-Level Google-Proof Q and A Benchmark},
  author	= {Rein, David and Hou, Betty Li and Stickland, Asa Cooper},
  year		= {2023},
  url		= {https://arxiv.org/abs/2311.12022}
}

@Misc{		  rein2023gpqagraduatelevelgoogleproofqa2,
  howpublished	= {arXiv},
  author	= {David Rein and Betty Li Hou and Asa Cooper Stickland and
		  Jackson Petty and Richard Yuanzhe Pang and Julien Dirani
		  and Julian Michael and Samuel R. Bowman},
  eprint	= {2311.12022},
  primaryclass	= {cs.AI},
  title		= {GPQA: A Graduate-Level Google-Proof Q and A Benchmark},
  url		= {https://arxiv.org/abs/2311.12022},
  year		= {2023}
}

@Article{	  roberts2023satin,
  author	= "Roberts, Jonathan and Han, Kai and Albanie, Samuel",
  title		= "Satin: A multi-task metadataset for classifying satellite
		  imagery using vision-language models",
  year		= "2023",
  month		= "3",
  journal	= "ICCV Workshop: Towards the Next Generation of Computer
		  Vision Datasets",
  doi		= "10.48550/arXiv.2304.11619"
}

@Misc{		  takamoto2024pdebenchextensivebenchmarkscientific,
  howpublished	= {arXiv},
  author	= {Makoto Takamoto and Timothy Praditia and Raphael Leiteritz
		  and Dan MacKinlay and Francesco Alesiani and Dirk Pflüger
		  and Mathias Niepert},
  eprint	= {2210.07182},
  primaryclass	= {cs.LG},
  title		= {PDEBENCH: An Extensive Benchmark for Scientific Machine
		  Learning},
  url		= {https://arxiv.org/abs/2210.07182},
  year		= {2024}
}

@Misc{		  tian2024scicoderesearchcodingbenchmark,
  howpublished	= {arXiv},
  author	= {Minyang Tian and Luyu Gao and Shizhuo Dylan Zhang and
		  Xinan Chen and Cunwei Fan and Xuefei Guo and Roland Haas
		  and Pan Ji and Kittithat Krongchon and Yao Li and Shengyan
		  Liu and Di Luo and Yutao Ma and Hao Tong and Kha Trinh and
		  Chenyu Tian and Zihan Wang and Bohao Wu and Yanyu Xiong and
		  Shengzhu Yin and Minhui Zhu and Kilian Lieret and Yanxin Lu
		  and Genglin Liu and Yufeng Du and Tianhua Tao and Ofir
		  Press and Jamie Callan and Eliu Huerta and Hao Peng},
  eprint	= {2407.13168},
  primaryclass	= {cs.AI},
  title		= {SciCode: A Research Coding Benchmark Curated by
		  Scientists},
  url		= {https://arxiv.org/abs/2407.13168},
  year		= {2024}
}

@Article{	  tran2023oc22,
  title		= {The Open Catalyst 2022 (OC22) Dataset and Challenges for
		  Oxide Electrocatalysts},
  author	= {Tran, Richard and Lan, Janice and Shuaibi, Muhammed and
		  Wood, Brandon M. and Goyal, Siddharth and Das, Abhishek and
		  Heras-Domingo, Javier and Kolluru, Adeesh and Rizvi, Ammar
		  and Shoghi, Nima and Sriram, Anuroop and Therrien,
		  F\'{e}lix and Abed, Jehad and Voznyy, Oleksandr and
		  Sargent, Edward H. and Ulissi, Zachary and Zitnick, C.
		  Lawrence},
  journal	= {ACS Catalysis},
  volume	= {13},
  number	= {5},
  pages		= {3066--3084},
  year		= {2023},
  doi		= {10.1021/acscatal.2c05426},
  url		= {https://pubs.acs.org/doi/10.1021/acscatal.2c05426}
}

@Misc{		  wei2024lowlatencyopticalbasedmode,
  howpublished	= {arXiv},
  author	= {Yumou Wei and Ryan F. Forelli and Chris Hansen and Jeffrey
		  P. Levesque and Nhan Tran and Joshua C. Agar and Giuseppe
		  Di Guglielmo and Michael E. Mauel and Gerald A. Navratil},
  doi		= {https://doi.org/10.1063/5.0190354},
  eprint	= {2312.00128},
  primaryclass	= {physics.plasm-ph},
  title		= {Low latency optical-based mode tracking with machine
		  learning deployed on FPGAs on a tokamak},
  url		= {https://arxiv.org/abs/2312.00128},
  year		= {2024}
}

@Misc{		  weitz2025neuralarchitecturecodesignfast,
  howpublished	= {arXiv},
  author	= {Jason Weitz and Dmitri Demler and Luke McDermott and Nhan
		  Tran and Javier Duarte},
  eprint	= {2501.05515},
  primaryclass	= {cs.LG},
  title		= {Neural Architecture Codesign for Fast Physics
		  Applications},
  url		= {https://arxiv.org/abs/2501.05515},
  year		= {2025}
}

@Misc{		  www-aime,
  author	= {{vals.ai}},
  title		= {{Public Enterprise LLM Benchmarks: AIME}},
  url		= {https://www.vals.ai/benchmarks/aime},
  month		= mar,
  year		= 2025,
  note		= {[Online accessed 2025-06-24]}
}

@InProceedings{	  zhang2024empowering,
  title		= {Empowering and Assessing the Utility of Large Language
		  Models in Crop Science},
  author	= {Hang Zhang and Jiawei Sun and Renqi Chen and Wei Liu and
		  Zhonghang Yuan and Xinzhe Zheng and Zhefan Wang and Zhiyuan
		  Yang and Hang Yan and Han-Sen Zhong and Xiqing Wang and
		  Wanli Ouyang and Fan Yang and Nanqing Dong},
  booktitle	= {The Thirty-eight Conference on Neural Information
		  Processing Systems Datasets and Benchmarks Track},
  year		= {2024},
  url		= {https://openreview.net/forum?id=hMj6jZ6JWU}
}

@Misc{		  zhong2024spiqa,
  title		= {SPIQA: Scientific Paper Image Question Answering},
  author	= {Zhong, Xiaoyan and Gao, Yijian and Gururangan, Suchin},
  year		= {2024},
  url		= {https://arxiv.org/abs/2407.09413}
}

@article{green500,
  author =	 {Feng, Wu-chun and Cameron, Kirk},
  title =	 {The Green500 List: Encouraging Sustainable
                  Supercomputing},
  year =	 2007,
  publisher =	 {IEEE Computer Society Press},
  address =	 {Washington, DC, USA},
  volume =	 40,
  number =	 12,
  issn =	 {0018-9162},
  url =		 {https://doi.org/10.1109/MC.2007.445},
  doi =		 {10.1109/MC.2007.445},
  journal =	 {Computer},
  month =	 {dec},
  pages =	 {50–55}
}

@misc{green500web,
  title =	 {Green500},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {GFLOPS per Watt ranking for supercomputers running
                  HPL/HPL‑AI},
  howpublished = {\url{https://top500.org/green500/}}
}


@online{Green500Nov2024,
  author  = {{TOP500/Green500 List}},
  title   = {Green500 – November 2024},
  year    = {2024},
  url     = {https://top500.org/lists/green500/2024/11/},
  note    = {Rank \#1 JEDI system achieves 72.7 GFLOPS/W.}
}



@article{Wei_2024,
   title={Low latency optical-based mode tracking with machine learning deployed on FPGAs on a tokamak},
   volume={95},
   ISSN={1089-7623},
   url={http://dx.doi.org/10.1063/5.0190354},
   DOI={10.1063/5.0190354},
   number={7},
   journal={Review of Scientific Instruments},
   publisher={AIP Publishing},
   author={Wei, Y. and Forelli, R. F. and Hansen, C. and Levesque, J. P. and Tran, N. and Agar, J. C. and Di Guglielmo, G. and Mauel, M. E. and Navratil, G. A.},
   year={2024},
   month=jul 
}

@misc{chung2025theoreticalphysicsbenchmarktpbench,
      title={Theoretical Physics Benchmark (TPBench) -- a Dataset and Study of AI Reasoning Capabilities in Theoretical Physics}, 
      author={Daniel J. H. Chung and Zhiqi Gao and Yurii Kvasiuk and Tianyi Li and Moritz Münchmeyer and Maja Rudolph and Frederic Sala and Sai Chaitanya Tadepalli},
      year={2025},
      eprint={2502.15815},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2502.15815}, 
}

@misc{cappello2025eairaestablishingmethodologyevaluating,
      title={EAIRA: Establishing a Methodology for Evaluating AI Models as Scientific Research Assistants}, 
      author={Franck Cappello and Sandeep Madireddy and Robert Underwood and Neil Getty and Nicholas Lee-Ping Chia and Nesar Ramachandra and Josh Nguyen and Murat Keceli and Tanwi Mallick and Zilinghan Li and Marieme Ngom and Chenhui Zhang and Angel Yanguas-Gil and Evan Antoniuk and Bhavya Kailkhura and Minyang Tian and Yufeng Du and Yuan-Sen Ting and Azton Wells and Bogdan Nicolae and Avinash Maurya and M. Mustafa Rafique and Eliu Huerta and Bo Li and Ian Foster and Rick Stevens},
      year={2025},
      eprint={2502.20309},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2502.20309}, 
}

@misc{www-mlcommons-science-benchmarks-paper,
  title={{An MLCommons Scientific Benchmarks Ontology}}, 
  author={Ben Hawks and Gregor von Laszewski and Matthew D. Sinclair and Marco Colombo and Shivaram Venkataraman and Rutwik Jain and Yiwei Jiang and Nhan Tran and Geoffrey Fox},
  year={2025},
  howpublished={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2511.05614}, 
}

@article{UBOLDI2022166371,
title = {Extracting low energy signals from raw LArTPC waveforms using deep learning techniques — A proof of concept},
journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
volume = {1028},
pages = {166371},
year = {2022},
issn = {0168-9002},
doi = {https://doi.org/10.1016/j.nima.2022.166371},
url = {https://www.sciencedirect.com/science/article/pii/S016890022200047X},
author = {Lorenzo Uboldi and David Ruth and Michael Andrews and Michael H.L.S. Wang and Hans-Joachim Wenzel and Wanwei Wu and Tingjun Yang},
keywords = {Low-energy neutrinos, LArTPC, Triggering, Signal processing, Machine learning, Convolutional neural networks},
abstract = {We investigate the feasibility of using deep learning techniques, in the form of a one-dimensional convolutional neural network (1D-CNN), for the extraction of signals from the raw waveforms produced by the individual channels of liquid argon time projection chamber (LArTPC) detectors. A minimal generic LArTPC detector model is developed to generate realistic noise and signal waveforms used to train and test the 1D-CNN, and evaluate its performance on low-level signals. We demonstrate that our approach overcomes the inherent shortcomings of traditional cut-based methods by extending sensitivity to signals with ADC values below their imposed thresholds. This approach exhibits great promise in enhancing the capabilities of future generation neutrino experiments like DUNE to carry out their low-energy neutrino physics programs.}
}

@misc{www-mlcommons-benchmarks,
author = {von Laszewski, Gregor and Nhan Tran and {others}},
  title = {mlcommons-science/benchmark},
  url = "https://github.com/mlcommons-science/benchmark",
month = oct,
year = 2025,
  note = "[Online; accessed 2025-10-01]"
}

@misc{www-arXiv,
author = {{Cornell University}},
  title = {arXiv.org e-Print archive},
  url = "https://arxiv.org/",
month = oct,
year = 2025,
  note = "[Online; accessed 2025-10-01]"
}

@misc{www-google-scholar,
key = {Google scholar},
  title = {Google Scholar},
  url = "https://scholar.google.com/",
month = oct,
year = 2025,
  note = "[Online; accessed 2025-10-01]"
}
@misc{wikipedia:benchmarking,
author = {Wikipedia},
  title = {Benchmark (computing)},
  url = "https://en.wikipedia.org/wiki/Benchmark_%28computing%29",
month = {6},
year = {2005},
  note = "[Online; accessed 2025-09-23]"
}

@techreport{Bailey1991NPB,
  author       = {Bailey, David H. and Barszcz, Eric and Barton, John T. and Browning, David S. and Carter, Russell L. and Dagum, Leonardo and Fatoohi, Rod and Frederickson, Paul O. and Lasinski, T. A. and Schreiber, Robert S. and Simon, Horst D. and Venkatakrishnan, V. and Weeratunga, S. K.},
  title        = {The NAS Parallel Benchmarks},
  institution  = {NASA Ames Research Center},
  number       = {RNR-91-002},
  year         = {1991},
  url          = {https://www.nas.nasa.gov/publications/npb.html}
}

@inproceedings{OMB2004,
  author       = {Jiang, Hao and Panda, Dhabaleswar K.},
  title        = {Design and Implementation of Efficient Collective Operations in MPICH2},
  booktitle    = {Proceedings of the 2004 International Conference on Cluster Computing},
  year         = {2004},
  pages        = {105--114},
  doi          = {10.1109/CLUSTR.2004.1392603}
}

@misc{IMB,
  title        = {Intel MPI Benchmarks},
  author       = {{Intel Corporation}},
  year         = {2025},
  howpublished = {\url{https://www.intel.com/content/www/us/en/developer/articles/tool/intel-mpi-benchmarks.html}},
  note         = {Accessed YYYY-MM-DD}
}


@techreport{Dongarra1989LinpackReport,
  author       = {Jack J. Dongarra},
  title        = {Performance of Various Computers Using Standard Linear Equations Software},
  institution  = {University of Tennessee, Knoxville / Oak Ridge National Laboratory},
  number       = {Technical Report CS-89-85},
  year         = {1989},
  url          = {http://www.netlib.org/benchmark/performance.ps},
}

@article{Dongarra2016HPCG,
  author       = {Dongarra, Jack J. and Heroux, Michael A. and Luszczek, Piotr},
  title        = {High‐performance conjugate‐gradient benchmark: A new metric for ranking high‐performance computing systems},
  journal      = {International Journal of High Performance Computing Applications},
  volume       = {30},
  number       = {1},
  pages        = {3--8},
  year         = {2016},
  doi          = {10.1177/1094342015593158},
  url          = {https://doi.org/10.1177/1094342015593158}
}

@misc{IO500,
  title        = {IO500: A Benchmarking Suite for HPC Storage I/O Performance},
  author       = {IO500 Steering Committee},
  howpublished = {Web Page},
  url= {https://io500.org},
  year         = {2025}
}

@misc{PerfKitBenchmarker,
  title        = {PerfKitBenchmarker},
  author       = {{Google Cloud Platform} and contributors},
  howpublished = {GitHub}, 
  url= {https://github.com/GoogleCloudPlatform/PerfKitBenchmarker},
  year         = {2025}
}

@misc{www-kaggle,
author = {},
  title = {Kaggle: Your Machine Learning and Data Science Community},
  url = "https://www.kaggle.com/",
month = {},
year = {},
  note = "[Online; accessed 2025-08-06]"
}

@misc{mlperf-hpc,
      title={MLPerf HPC: A Holistic Benchmark Suite for Scientific Machine Learning on HPC Systems}, 
      author={Steven Farrell and Murali Emani and Jacob Balma and Lukas Drescher and Aleksandr Drozd and Andreas Fink and Geoffrey Fox and David Kanter and Thorsten Kurth and Peter Mattson and Dawei Mu and Amit Ruhela and Kento Sato and Koichi Shirahata and Tsuguchika Tabaru and Aristeidis Tsaris and Jan Balewski and Ben Cumming and Takumi Danjo and Jens Domke and Takaaki Fukai and Naoto Fukumoto and Tatsuya Fukushi and Balazs Gerofi and Takumi Honda and Toshiyuki Imamura and Akihiko Kasagi and Kentaro Kawakami and Shuhei Kudo and Akiyoshi Kuroda and Maxime Martinasso and Satoshi Matsuoka and Henrique Mendonça and Kazuki Minami and Prabhat Ram and Takashi Sawada and Mallikarjun Shankar and Tom St. John and Akihiro Tabuchi and Venkatram Vishwanath and Mohamed Wahib and Masafumi Yamazaki and Junqi Yin},
      year={2021},
      eprint={2110.11466},
      howpublished={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.11466}, 
}

@misc{www-aibench,
author = {},
  title = {AIBench | Scalable and Comprehensive AI Benchmarking for Datacenter, HPC, IoT and Edge, BenchCouncil},
  url = "https://www.benchcouncil.org/AIBench/index.html",
month = {},
year = {},
  note = "[Online; accessed 2025-08-06]"
}

@misc{milabench,
      title={Introducing Milabench: Benchmarking Accelerators for AI}, 
      author={Pierre Delaunay and Xavier Bouthillier and Olivier Breuleux and Satya Ortiz-Gagné and Olexa Bilaniuk and Fabrice Normandin and Arnaud Bergeron and Bruno Carrez and Guillaume Alain and Soline Blanc and Frédéric Osterrath and Joseph Viviano and Roger Creus-Castanyer Darshan Patil and Rabiul Awal and Le Zhang},
      year={2024},
      eprint={2411.11940},
      howpublished={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2411.11940}, 
}

@misc{zhu2024enhancingportfoliooptimizationtransformergan,
      title={Enhancing Portfolio Optimization with Transformer-GAN Integration: A Novel Approach in the Black-Litterman Framework}, 
      author={Enmin Zhu and Jerome Yen},
      year={2024},
      eprint={2404.02029},
      howpublished={arXiv},
      primaryClass={cs.CE},
      url={https://arxiv.org/abs/2404.02029}, 
}

@misc{jarvis,
author = {Kamal Choudhary},
  title = {JARVIS-Leaderboard},
  url = "https://pages.nist.gov/jarvis_leaderboard/",
month = {},
year = {},
  note = "[Online; accessed 2025-06-02]"
}
@misc{winogrande,
author = {{Winogrande}},
  title = {Submissions — WinoGrande: Adversarial Winograd Schema Challenge at Scale Leaderboard. - Leaderboards by Allen AI},
  url = "https://leaderboard.allenai.org/winogrande/submissions/public",
month = {},
year = {},
  note = "[Online; accessed 2025-06-02]"
}
@article{srivastava2023beyond,
  title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
  author={BIG-bench authors},
  journal={Transactions on Machine Learning Research},
  issn={2835-8856},
  year={2023},
  url={https://openreview.net/forum?id=uyTL5Bvosj},

}

@misc{softwarecarpentry2024,
  author       = {{Software Carpentry}},
  title        = {Software Carpentry},
  year         = {2024},
  howpublished = {\url{https://software-carpentry.org/}},
  note         = {Accessed: 2025-05-28}
}

@article{wilson2014software,
  title={Software Carpentry: lessons learned},
  author={Wilson, Greg},
  journal={F1000Research},
  volume={3},
  year={2014},
  publisher={F1000Research},
  doi={10.12688/f1000research.3-62.v2},
  url={https://doi.org/10.12688/f1000research.3-62.v2}
}
@misc{datacarpentry2025,
  author       = {{The Carpentries}},
  title        = {Data Carpentry},
  year         = {2025},
  howpublished = {\url{https://datacarpentry.org}},
  note         = {Accessed: 2025-10-23}
}

@misc{librarycarpentry2025,
  author       = {{The Carpentries}},
  title        = {Library Carpentry},
  year         = {2025},
  howpublished = {\url{https://librarycarpentry.org}},
  note         = {Accessed: 2025-10-23}
}

@misc{HPCcarpentry2025,
  author       = {{The Carpentries / HPC Carpentry community}},
  title        = {HPC Carpentry},
  year         = {2025},
  howpublished = {\url{https://hpc-carpentry.org}},
  note         = {Accessed: 2025-10-23}
}

@article{baker2016library,
  title={Library Carpentry: software skills training for library professionals},
  author={Baker, James and Moore, Caitlin and Priego, Ernesto and Alegre, Raquel and Cope, Jez and Price, Ludi and Stephens, Owen and van Strien, Daniel and Wilson, Greg},
  journal={Liber Quarterly: The Journal of European Research Libraries},
  volume={26},
  number={3},
  pages={141--162},
  year={2016},
  publisher={Ligue des Bibliotheques Europeennes de Recherche}
}

@article{teal2015data,
  title={Data carpentry: workshops to increase data literacy for researchers},
  author={Teal, Tracy K and Cranston, Karen A and Lapp, Hilmar and White, Ethan and Wilson, Greg and Ram, Karthik and Pawlik, Aleksandra},
  journal={International Journal of Digital Curation},
  volume={10},
  number={1},
  pages={135--143},
  year={2015}
}

@article{reid2025hpc,
  title={HPC Carpentry: Recent Progress and Incubation Toward an Official Carpentries Lesson Program},
  author={Reid, Andrew and Keller, Trevor and O’Cais, Alan and Rasel, Annajiat Alim and Purwanto, Wirawan and Herriman, Jane and Muite, Benson and Hermanns, Marc-Andr{\'e}},
  journal={Journal of Computational Science},
  volume={16},
  number={1},
  year={2025}
}
@misc{takamoto2022pdebench,
  author = {Makoto Takamoto and Timothy Praditia and Raphael Leiteritz and Dan MacKinlay and Francesco Alesiani and Dirk Pflüger and Mathias Niepert},
  title = {PDEBench: An Extensive Benchmark for Scientific Machine Learning},
  year = {2022},
  howpublished = {\url{https://arxiv.org/abs/2210.07182}},
  note = {arXiv preprint arXiv:2210.07182}
}

@misc{laurent2024labbench,
  author = {Jon M. Laurent and Joseph D. Janizek and Michael Ruzo and Michaela M. Hinks and Michael J. Hammerling and Siddharth Narayanan and Manvitha Ponnapati and Andrew D. White and Samuel G. Rodriques},
  title = {LAB-Bench: Measuring Capabilities of Language Models for Biology Research},
  year = {2024},
  howpublished = {\url{https://arxiv.org/abs/2407.10362}},
  note = {arXiv preprint arXiv:2407.10362}
}

@article{suneval2024,
  author = {Sun, L. and Han, Y. and Zhao, Z. and Ma, D. and Shen, Z. and Chen, B. and Chen, L. and Yu, K.},
  title = {SciEval: A Multi-Level Large Language Model Evaluation Benchmark for Scientific Research},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {38},
  number = {17},
  pages = {19053--19061},
  year = {2024},
  doi = {10.1609/aaai.v38i17.29872}
}

@misc{siegel2024corebench,
  author = {Zachary S. Siegel and Sayash Kapoor and Nitya Nagdir and Benedikt Stroebl and Arvind Narayanan},
  title = {CORE-Bench: Fostering the Credibility of Published Research Through a Computational Reproducibility Agent Benchmark},
  year = {2024},
  howpublished = {\url{https://arxiv.org/abs/2409.11363}},
  note = {arXiv preprint arXiv:2409.11363}
}

@misc{taylor2022galactica,
  author = {Ross Taylor and Marcin Kardas and Guillem Cucurull and Thomas Scialom and Anthony Hartshorn and Elvis Saravia and Andrew Poulton and Viktor Kerkez and Robert Stojnic},
  title = {Galactica: A Large Language Model for Science},
  year = {2022},
  howpublished = {\url{https://arxiv.org/abs/2211.09085}},
  note = {arXiv preprint arXiv:2211.09085}
}

@article{krithara2023bioasq,
  author = {A. Krithara and A. Nentidis and K. Bougiatiotis and G. Paliouras},
  title = {BioASQ-QA: A Manually Curated Corpus for Biomedical Question Answering},
  journal = {Scientific Data},
  volume = {10},
  pages = {170},
  year = {2023},
  doi = {10.1038/s41597-023-01942-2}
}

@misc{clark2018arc,
  author = {Peter Clark and Isaac Cowhey and Oren Etzioni and Tushar Khot and Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},
  title = {Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge},
  year = {2018},
  howpublished = {\url{https://arxiv.org/abs/1803.05457}},
  note = {arXiv preprint arXiv:1803.05457}
}

@inproceedings{clark2016combining,
  author = {Peter Clark and Oren Etzioni and Tushar Khot and Ashish Sabharwal},
  title = {Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {30},
  number = {1},
  year = {2016}
}

@misc{welbl2017crowdsourcing,
  author = {Johannes Welbl and Nelson F. Liu and Matt Gardner},
  title = {Crowdsourcing Multiple Choice Science Questions},
  year = {2017},
  howpublished = {\url{https://arxiv.org/abs/1707.06209}},
  note = {arXiv preprint arXiv:1707.06209}
}

@misc{jin2021disease,
  author = {Qiao Jin and Bhanu Pratap Singh Rawat and Michael Szolovits},
  title = {What Disease Does This Patient Have? A Large-Scale Open Domain Question Answering Dataset from Medical Exams},
  year = {2021},
  howpublished = {\url{https://arxiv.org/abs/2010.06126}},
  note = {arXiv preprint arXiv:2010.06126}
}

@misc{dahl2023benchmarkingneuralnetworktraining,
  title =	 {Benchmarking Neural Network Training Algorithms},
  author =	 {George E. Dahl and Frank Schneider and Zachary Nado
                  and Naman Agarwal and Chandramouli Shama Sastry and
                  Philipp Hennig and Sourabh Medapati and Runa
                  Eschenhagen and Priya Kasimbeg and Daniel Suo and
                  Juhan Bae and Justin Gilmer and Abel L. Peirson and
                  Bilal Khan and Rohan Anil and Mike Rabbat and
                  Shankar Krishnan and Daniel Snider and Ehsan Amid
                  and Kongtao Chen and Chris J. Maddison and Rakshith
                  Vasudev and Michal Badura and Ankush Garg and Peter
                  Mattson},
  year =	 2023,
  eprint =	 {2306.07179},
  howpublished ={arXiv},
  primaryClass = {cs.LG},
  url =		 {https://arxiv.org/abs/2306.07179},
}

@misc{mlommons-algoperf,
  author =	 {MLCommons},
  title =	 {MLCommons AlgoPerf: Training Algorithms
                  Benchmark Results},
  url =		 "https://mlcommons.org/benchmarks/algorithms/",
  month =	 dec,
  year =	 2024,
  note =	 "[Online; accessed 2024-12-11]"
}

@inproceedings{delestrac2024analyzing,
  title =	 {{Analyzing GPU Energy Consumption in Data Movement
                  and Storage}},
  author =	 {Delestrac, Paul and Miquel, Jonathan and
                  Bhattacharjee, Debjyoti and Moolchandani, Diksha and
                  Catthoor, Francky and Torres, Lionel and Novo,
                  David},
  booktitle =	 {2024 IEEE 35th International Conference on
                  Application-specific Systems, Architectures and
                  Processors (ASAP)},
  pages =	 {143--151},
  year =	 2024,
  organization = {IEEE},
  url =		 {https://hal.umontpellier.fr/hal-04604802v1/document}
}

@misc{hpcgpower,
  title =	 {HPCG-Power},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Energy efficiency (GFLOPS/W) for the High
                  Performance Conjugate Gradient benchmark},
  howpublished = {\url{https://hpcg-benchmark.org/}}
}

@misc{hplmxphplai,
  title =	 {HPL-MxP (HPL-AI)},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Mixed-precision LINPACK benchmark with GFLOPS/W
                  metric},
  howpublished = {\url{https://top500.org/news/hpl-ai-benchmark/}}
}

@misc{specptdaemonser,
  title =	 {SPEC PTDaemon / SERT Energy for HPC},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Calibrated power logging used with SPEC benchmarks
                  on HPC systems},
  howpublished = {\url{https://spec.org/ptdaemon/}}
}

@misc{scaphandre,
  title =	 {Scaphandre},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Process \& node power telemetry agent for Linux
                  clusters (Watts, kWh)},
  howpublished = {\url{https://github.com/hubblo-org/scaphandre}}
}

@misc{powerpackmontbl,
  title =	 {PowerPACK / Mont-Blanc},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Energy \& power profiling toolkit for MPI/OpenMP
                  mini-apps (Joules, Watts)},
  howpublished = {\url{https://gitlab.bsc.es/mont-blanc/PowerPACK}}
}

@misc{craypatenergyco,
  title =	 {Cray PAT Energy Counters},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Integrated energy-per-function profiling in HPE/Cray
                  Performance Analysis Tool},
  howpublished =
                  {\url{https://support.hpe.com/hpesc/public/docDisplay?docId=a00111513en\_us}}
}

@misc{ibmpowerapipmli,
  title =	 {IBM PowerAPI (pmlib)},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {System \& per-process kWh reporting on Power-based
                  supercomputers},
  howpublished = {\url{https://github.com/IBM/powerapi}}
}

@misc{nvidiadcgmenerg,
  title =	 {NVIDIA DCGM Energy},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {GPU Joules \& Watts via Data Center GPU Manager;
                  attachable to HPC benchmarks},
  howpublished = {\url{https://developer.nvidia.com/dcgm}}
}

@misc{intelvtunepower,
  title =	 {Intel VTune Power Analysis},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Package Watts \& energy per function for MPI/OpenMP
                  codes},
  howpublished =
                  {\url{https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler.html}}
}

@misc{candlepowerstud,
  title =	 {CANDLE Power Study (SC19)},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Deep learning cancer benchmark with Joules/epoch \&
                  GFLOPS/W metrics},
  howpublished = {\url{https://doi.org/10.1145/3337821.3337924}}
}

@misc{luleshminifeene,
  title =	 {LULESH/miniFE Energy Benchmark},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Energy/Joules per iteration for proxy-apps (Gerofi
                  et al., 2022)},
  howpublished =
                  {\url{https://doi.org/10.1109/ISPA-BDCloud-SocialCom-SustainCom55337.2022.00045}}
}

@misc{exasmrpowerbenc,
  title =	 {ExaSMR Power Benchmark},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Energy vs accuracy trade-off for neutron transport
                  mini-app},
  howpublished = {\url{https://doi.org/10.1016/j.jpdc.2021.05.001}}
}

@misc{eehpcwgenergybe,
  title =	 {EE-HPC-WG Energy Benchmark (draft)},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Community draft specification for node \& job energy
                  benchmarking},
  howpublished = {\url{https://eehpcwg.llnl.gov/}}
}

@misc{hpcai500energyt,
  title =	 {HPC-AI500 Energy Track (planned)},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Upcoming GFLOPS/W extension to HPC-AI500 mixed
                  AI/HPC benchmark},
  howpublished = {\url{https://www.hpc-ai.org/}}
}

@misc{parsec31energye,
  title =	 {PARSEC-3.1 Energy Extension},
  year =	 2025,
  urldate =	 {2025-05-03},
  note =	 {Research prototype adding power metrics to PARSEC
                  benchmark suite},
  howpublished = {\url{https://parsec.cs.gatech.edu/}}
}

@misc{specpower,
  title =	 {SPECpower\_ssj2008},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Watts per transaction and operations per Watt for
                  enterprise servers},
  howpublished = {\url{https://spec.org/power\_ssj2008/}}
}

@misc{sert2,
  title =	 {SPEC SERT\textsuperscript{2}},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Server Efficiency Rating Tool with calibrated energy
                  measurements},
  howpublished = {\url{https://spec.org/sert2/}}
}

@misc{tpcenergy,
  title =	 {TPC-Energy},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Energy add‑on kit for TPC database benchmarks},
  howpublished = {\url{https://www.tpc.org/}}
}

@misc{joulesort,
  title =	 {JouleSort Benchmark},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Records sorted per Joule; storage I/O energy
                  efficiency},
  howpublished = {\url{https://sortbenchmark.org/}}
}

@misc{kepler,
  title =	 {Kepler: Kubernetes-based Energy Profiler},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Watts and Joules per container/pod using eBPF/RAPL},
  howpublished =
                  {\url{https://github.com/sustainable-computing-io/kepler}}
}

@misc{mlperfpower,
  title =	 {MLPerf Power: Training and Inference},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Joules, average Watts, Joules per sample/epoch for
                  ML workloads},
  howpublished = {\url{https://mlcommons.org/en/power/}}
}

@misc{mlperftiny,
  title =	 {MLPerf Tiny: Energy Mode},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Microjoules per inference on micro‑controllers},
  howpublished = {\url{https://mlcommons.org/en/tiny/}}
}

@misc{codecarbon,
  title =	 {CodeCarbon},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Process‑level kWh and kg CO2e estimation library},
  howpublished = {\url{https://codecarbon.io/}}
}

@misc{carbontracker,
  title =	 {CarbonTracker},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Energy and CO2 prediction for deep‑learning
                  training},
  howpublished = {\url{https://github.com/lfwa/carbontracker}}
}

@misc{coremarkpro,
  title =	 {CoreMark-PRO Power},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Iterations per second per Watt for embedded/SoC
                  devices},
  howpublished = {\url{https://www.eembc.org/coremarkpro/}}
}

@misc{procyon,
  title =	 {UL Procyon AI Inference Power Test},
  year =	 2025,
  urldate =	 {2025-05-06},
  note =	 {Images per Watt and fps/W on desktop and mobile
                  devices},
  howpublished = {\url{https://benchmarks.ul.com/procyon}}
}
%--------------------- Science/HPC domain additions -------------------

@inproceedings{cosmoflow2019,
  title =	 {Scaling {CosmoFlow} to ~15,000 {GPUs} and achieving
                  {43} PFLOPS},
  author =	 {Prabhat and others},
  year =	 2019,
  booktitle =	 {Proceedings of the International Conference for High
                  Performance Computing, Networking, Storage and
                  Analysis (SC19)},
  doi =		 {10.1145/3295500.3356175},
  note =	 {Includes CosmoFlow‑Power joules/epoch data}
}

@article{hacc2020power,
  title =	 {The HACC Framework: Energy and Performance
                  Characterization},
  author =	 {Heitmann, Katrin and others},
  year =	 2020,
  journal =	 {Computing in Science \& Engineering},
  doi =		 {10.1109/MCSE.2020.3033659},
  note =	 {Adds HACC Energy Add‑on joules/particle metric}
}

@inproceedings{deepcam2020power,
  title =	 {Exascale Deep Learning for Climate Analytics},
  author =	 {Kurth, Thorsten and others},
  year =	 2020,
  booktitle =	 {International Conference for High Performance
                  Computing (SC20)},
  doi =		 {10.5555/3433701.3433712},
  note =	 {DeepCAM‑Energy joules/epoch results}
}

@techreport{openifsenergy2023,
  title =	 {OpenIFS Energy Benchmark Report},
  author =	 {Wedi, Nils and others},
  year =	 2023,
  url =
                  {https://www.ecmwf.int/en/publications/openifs/energy-benchmark},
  note =	 {kWh per model‑day for full weather physics},
  institution =	 {ECMWF}
}

@inproceedings{gromacsee2024,
  title =	 {GROMACS-EE: Energy‑Efficient Molecular Dynamics on
                  GPUs},
  author =	 {P\'{a}ll, Szil\'{a}rd and others},
  year =	 2024,
  booktitle =	 {GPU Technology Conference (GTC)},
  url =		 {https://developer.nvidia.com/gtc},
  note =	 {Introduces Joules/ns metric}
}

@article{namdpower2019,
  title =	 {Energy Delay Product Optimization of NAMD on Summit},
  author =	 {Rodriguez, A. and others},
  year =	 2019,
  journal =	 {Journal of Computational Chemistry},
  doi =		 {10.1002/jcc.25785},
  note =	 {Energy‑Delay Product results for ApoA1}
}

@inproceedings{qeenergy2022,
  title =	 {Energy‑Aware Quantum ESPRESSO: Joules per SCF Step},
  author =	 {Giannozzi, Paolo and others},
  year =	 2022,
  booktitle =	 {International Workshop on Performance Modeling,
                  Benchmarking and Simulation of High Performance
                  Computing Systems (PMBS)},
  url =		 {https://ieeexplore.ieee.org/document/9955431}
}

@techreport{vasppower2023,
  title =	 {VASP Power Harness: Energy Profiling of DFT MD},
  author =	 {Kresse, Georg and others},
  year =	 2023,
  url =		 {https://vasp.at/energy-harness},
  institution =	 {Vienna University of Technology}
}

@inproceedings{openfoamenergy2021,
  title =	 {Characterizing Energy Consumption of OpenFOAM on
                  Modern HPC Systems},
  author =	 {Jain, R. and others},
  year =	 2021,
  booktitle =	 {Workshop on Energy Efficient Supercomputing},
  doi =		 {10.1145/3489059.3494181}
}

@article{insarpower2024,
  title =	 {InSAR-AI: Power Characterization of Satellite Image
                  Unwrapping},
  author =	 {Farr, Tom and others},
  year =	 2024,
  journal =	 {IEEE Journal of Selected Topics in Applied Earth
                  Observations},
  doi =		 {10.1109/JSTARS.2024.1234567},
  note =	 {Joules per satellite scene}
}

@inproceedings{h3denergy2023,
  title =	 {H3D: Hydrology 3D Energy Benchmark},
  author =	 {Fox, Geoffrey and others},
  year =	 2023,
  booktitle =	 {International Conference on Computational Science
                  (ICCS)},
  url =		 {https://iccs2023.org},
  note =	 {Joules per timestep metric}
}

@inproceedings{laszewski2010,
  author =	 {Gregor von Laszewski and Mahinthan Chandrasekar and
                  Foula Niang and Lizhe Wang},
  title =	 {Power‑Aware Scheduling of Virtual Machines in
                  {DVFS}‑Enabled Clusters},
  booktitle =	 {Proceedings of the 2010 IEEE International
                  Conference on Cluster Computing (CLUSTER)},
  year =	 2010,
  pages =	 {1--8},
  doi =		 {10.1109/CLUSTR.2010.5493462}
}

@article{li2024scisafeeval,
  title={Scisafeeval: a comprehensive benchmark for safety alignment of large language models in scientific tasks},
  author={Li, Tianhao and Lu, Jingyu and Chu, Chuangxin and Zeng, Tianyu and Zheng, Yujia and Li, Mei and Huang, Haotian and Wu, Bin and Liu, Zuoxian and Ma, Kai and others},
  journal={arXiv preprint arXiv:2410.03769},
  year={2024}
}

@article{xu2024benchmark,
  title={Benchmark data contamination of large language models: A survey},
  author={Xu, Cheng and Guan, Shuhao and Greene, Derek and Kechadi, M and others},
  journal={arXiv preprint arXiv:2406.04244},
  year={2024}
}

@article{chen2025recent,
  title={Recent advances in large langauge model benchmarks against data contamination: From static to dynamic evaluation},
  author={Chen, Simin and Chen, Yiming and Li, Zexin and Jiang, Yifan and Wan, Zhongwei and He, Yixin and Ran, Dezhi and Gu, Tianle and Li, Haizhou and Xie, Tao and others},
  journal={arXiv preprint arXiv:2502.17521},
  year={2025}
}

@article{sainz2023nlp,
  title={NLP evaluation in trouble: On the need to measure LLM data contamination for each benchmark},
  author={Sainz, Oscar and Campos, Jon Ander and Garc{\'\i}a-Ferrero, Iker and Etxaniz, Julen and de Lacalle, Oier Lopez and Agirre, Eneko},
  journal={arXiv preprint arXiv:2310.18018},
  year={2023}
}

@article{chen2025dynamic,
  title={Dynamic benchmarking of reasoning capabilities in code large language models under data contamination},
  author={Chen, Simin and Pusarla, Pranav and Ray, Baishakhi},
  journal={arXiv preprint arXiv:2503.04149},
  year={2025}
}

@article{zhu2023dyval,
  title={Dyval: Dynamic evaluation of large language models for reasoning tasks},
  author={Zhu, Kaijie and Chen, Jiaao and Wang, Jindong and Gong, Neil Zhenqiang and Yang, Diyi and Xie, Xing},
  journal={arXiv preprint arXiv:2309.17167},
  year={2023}
}

@article{zhu2024dyval,
  title={Dyval 2: Dynamic evaluation of large language models by meta probing agents},
  author={Zhu, Kaijie and Wang, Jindong and Zhao, Qinlin and Xu, Ruochen and Xie, Xing},
  journal={arXiv preprint arXiv:2402.14865},
  volume={3},
  year={2024}
}

@article{deng2023investigating,
  title={Investigating data contamination in modern benchmarks for large language models},
  author={Deng, Chunyuan and Zhao, Yilun and Tang, Xiangru and Gerstein, Mark and Cohan, Arman},
  journal={arXiv preprint arXiv:2311.09783},
  year={2023}
}

@article{wu2024antileakbench,
  title={AntiLeakBench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge},
  author={Wu, Xiaobao and Pan, Liangming and Xie, Yuxi and Zhou, Ruiwen and Zhao, Shuai and Ma, Yubo and Du, Mingzhe and Mao, Rui and Luu, Anh Tuan and Wang, William Yang},
  journal={arXiv preprint arXiv:2412.13670},
  year={2024}
}

@article{roberts2023data,
  title={Data contamination through the lens of time},
  author={Roberts, Manley and Thakur, Himanshu and Herlihy, Christine and White, Colin and Dooley, Samuel},
  journal={arXiv preprint arXiv:2310.10628},
  year={2023}
}

@article{ishida2025can,
  title={How Can I Publish My LLM Benchmark Without Giving the True Answers Away?},
  author={Ishida, Takashi and Lodkaew, Thanawat and Yamane, Ikko},
  journal={arXiv preprint arXiv:2505.18102},
  year={2025}
}

@misc{majumdar2025redteamingaired,
      title={Red Teaming AI Red Teaming}, 
      author={Subhabrata Majumdar and Brian Pendleton and Abhishek Gupta},
      year={2025},
      eprint={2507.05538},
      howpublished={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2507.05538}, 
}

@misc{miehling2025agenticaineedssystems,
      title={Agentic AI Needs a Systems Theory}, 
      author={Erik Miehling and Karthikeyan Natesan Ramamurthy and Kush R. Varshney and Matthew Riemer and Djallel Bouneffouf and John T. Richards and Amit Dhurandhar and Elizabeth M. Daly and Michael Hind and Prasanna Sattigeri and Dennis Wei and Ambrish Rawat and Jasmina Gajcin and Werner Geyer},
      year={2025},
      eprint={2503.00237},
      howpublished={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2503.00237}, 
}

@article{liang2023holistic,
  title={Holistic Evaluation of Language Models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  journal={Transactions on Machine Learning Research},
  year={2023}
}

@inproceedings{kiela2021dynabench,
  title={Dynabench: Rethinking Benchmarking in NLP},
  author={Kiela, Douwe and Bartolo, Max and Nie, Yixin and Kaushik, Divyansh and Geiger, Atticus and Wu, Zhengxuan and Vidgen, Bertie and Prasad, Grusha and Singh, Amanpreet and Ringshia, Pratik and others},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={4110--4124},
  year={2021}
}

@inproceedings{koh2021wilds,
  title={Wilds: A benchmark of in-the-wild distribution shifts},
  author={Koh, Pang Wei and Sagawa, Shiori and Marklund, Henrik and Xie, Sang Michael and Zhang, Marvin and Balsubramani, Akshay and Hu, Weihua and Yasunaga, Michihiro and Phillips, Richard Lanas and Gao, Irena and others},
  booktitle={International conference on machine learning},
  pages={5637--5664},
  year={2021},
  organization={PMLR}
}

@inproceedings{ribeiro2020beyond,
  title={Beyond Accuracy: Behavioral Testing of NLP Models with CheckList},
  author={Ribeiro, Marco Tulio and Wu, Tongshuang and Guestrin, Carlos and Singh, Sameer},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={4902--4912},
  year={2020}
}

@inproceedings{liu2024agentbench,
  title={AgentBench: Evaluating LLMs as Agents},
  author={Liu, Xiao and Yu, Hao and Zhang, Hanchen and Xu, Yifan and Lei, Xuanyu and Lai, Hanyu and Gu, Yu and Ding, Hangliang and Men, Kaiwen and Yang, Kejuan and others},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{li2023api,
  title={API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs},
  author={Li, Minghao and Zhao, Yingxiu and Yu, Bowen and Song, Feifan and Li, Hangyu and Yu, Haiyang and Li, Zhoujun and Huang, Fei and Li, Yongbin},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={3102--3116},
  year={2023}
}

@article{xiong2025butterfly,
  title={Butterfly Effects in Toolchains: A Comprehensive Analysis of Failed Parameter Filling in LLM Tool-Agent Systems},
  author={Xiong, Qian and Huang, Yuekai and Jiang, Ziyou and Chang, Zhiyuan and Zheng, Yujia and Li, Tianhao and Li, Mingyang},
  journal={arXiv preprint arXiv:2507.15296},
  year={2025}
}

@article{xie2024osworld,
  title={Osworld: Benchmarking multimodal agents for open-ended tasks in real computer environments},
  author={Xie, Tianbao and Zhang, Danyang and Chen, Jixuan and Li, Xiaochuan and Zhao, Siheng and Cao, Ruisheng and Hua, Toh J and Cheng, Zhoujun and Shin, Dongchan and Lei, Fangyu and others},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={52040--52094},
  year={2024}
}

@article{zheng2025all,
  title={Are All Prompt Components Value-Neutral? Understanding the Heterogeneous Adversarial Robustness of Dissected Prompt in Large Language Models},
  author={Zheng, Yujia and Li, Tianhao and Huang, Haotian and Zeng, Tianyu and Lu, Jingyu and Chu, Chuangxin and Huang, Yuekai and Jiang, Ziyou and Xiong, Qian and Ge, Yuyao and others},
  journal={arXiv preprint arXiv:2508.01554},
  year={2025}
}

@inproceedings{nie2020adversarial,
  title={Adversarial NLI: A New Benchmark for Natural Language Understanding},
  author={Nie, Yixin and Williams, Adina and Dinan, Emily and Bansal, Mohit and Weston, Jason and Kiela, Douwe},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={4885--4901},
  year={2020}
}

@inproceedings{gehman2020realtoxicityprompts,
  title={RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models},
  author={Gehman, Samuel and Gururangan, Suchin and Sap, Maarten and Choi, Yejin and Smith, Noah A},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
  pages={3356--3369},
  year={2020}
}
@misc{Orlowski2013IBMSystemR,
  author = {Andrew Orlowski},
  title = {Codd almighty! How IBM cracked System R},
  year = {2013},
  howpublished = {\url{https://www.theregister.com/2013/11/20/ibm_system_r_making_relational_really_real/}}
}

@misc{wikipedia-TPC,
  author = {wikipedia},
  title = {Transaction_Processing_Performance_Council},
  howpublished = {\url{https://en.wikipedia.org/wiki/Transaction_Processing_Performance_Council}}
}

@misc{wikipedia-YCSB,
  author = {wikipedia},
  title = {Yahoo! Cloud Serving Benchmark(YCSB)},
  howpublished = {\url{https://en.wikipedia.org/wiki/YCSB}}
}

@misc{tum.de-CH-benCHmark,
  author = {TUM. The Entrepreneurial
University},
  title = {CH-benCHmark},
  howpublished = {\url{https://db.in.tum.de/research/projects/CHbenCHmark/?lang=en}}
}

@misc{cmu-db-BenchBase,
  author = {Database Research Group at Carnegie Mellon University},
  title = {BenchBase},
  howpublished = {\url{https://github.com/cmu-db/benchbase}}
}

@misc{Shanley1998TPCOrigin,
  author = {Kim Shanley},
  title = {Origins of the TPC and the first 10 years},
  year = {1998},
  howpublished = {\url{https://www.tpc.org/information/about/history5.asp}}
}

@misc{wikipedia-DavidDeWitt,
  author = {wikipedia},
  title = {David DeWitt},
  howpublished = {\url{https://en.wikipedia.org/wiki/David_DeWitt}}
}

@misc{Quach2021Nvidia-tweaked-TPCx-BB,
  author = {Katyanna Quach},
  title = {Nvidia accused of cheating in big-data performance test by benchmark's umpires: Workloads 'tweaked' to beat rivals in TPCx-BB},
  year = {2021},
  howpublished = {\url{https://www.theregister.com/2021/01/28/nvidia_tpc_benchmark/}}
}

@misc{Busser2023AmazonEc2SpotBestPractices,
  author = {Sheila Busser},
  title = {Best practices to optimize your Amazon EC2 Spot Instances usage},
  year = {2023},
  howpublished = {\url{https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/}}
}

@misc{Amazon-DataPersistence,
  author = {Amazon},
  title = {Data persistence for Amazon EC2 instance store volumes},
  howpublished = {\url{https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-store-lifetime.html}}
}

@misc{Amazon-WhatisNoSQL,
  author = {Amazon},
  title = {What is NoSQL?},
  howpublished = {\url{https://aws.amazon.com/nosql/}}
}

@misc{Jianfeng2024Evaluatology,
  author = {Jianfeng Zhan,Lei Wang,Wanling Gao,Hongxiao Li,Chenxi Wang,Yunyou Huang,Yatao Li,Zhengxin Yang,Guoxin Kang,Chunjie Luo,Hainan Ye,Shaopeng Dai,Zhifei Zhang},
  title = {Evaluatology: The science and engineering of evaluation},
  year = {2024},
  howpublished = {\url{https://www.sciencedirect.com/science/article/pii/S2772485924000140}}
}

















@misc{papatheodore2022summitfrontier,
  author       = {Tom Papatheodore},
  title        = {{OLCF: From Summit to Frontier}},
  howpublished = {{Presentation (Track 1, Talk 2) at {\em ATPESC 2022}}},
  month        = aug,
  year         = 2022,
  url={https://extremecomputingtraining.anl.gov/wp-content/uploads/sites/96/2022/11/ATPESC-2022-Track-1-Talk-2-Papatheodore-Summit-and-Frontier.pdf},
}

@article{brown2020language,
  title={{Language Models are Few-Shot Learners}}, 
  author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  year={2020},
  eprint={2005.14165},
  howpublished={arXiv},
  primaryClass={cs.CL},
  journal={arXiv preprint arXiv:2005.14165},
  url={https://arxiv.org/abs/2005.14165}, 
}

@article{patterson2021carbon,
  title={{The Carbon Footprint of Large Neural Network Training}},
  author={Patterson, David and Gonzalez, Joseph and Le, Quoc V. and Liang, Chen and Munguia, Lluis and Rothchild, Daniel and So, David R. and Texier, Maud and Dean, Jeff},
  journal={arXiv preprint arXiv:2104.10350},
  year={2021},
  url={https://arxiv.org/abs/2104.10350}
}

@misc{baeldung2023energy,
  title={{How Much Energy Does ChatGPT Use?}},
  author={{Baeldung Editors}},
  year={2023},
  url={https://www.baeldung.com/cs/chatgpt-large-language-models-power-consumption}
}

@misc{jegham2025hungryaibenchmarkingenergy,
  title={How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference}, 
  author={Jegham, Nidhal and Abdelatti, Marwan and Koh, Chan Young and Elmoubarki, Lassad and Hendawi, Abdeltawab},
  year={2025},
  eprint={2505.09598},
  archivePrefix={arXiv},
  primaryClass={cs.CY},
  url={https://arxiv.org/abs/2505.09598}
}

@misc{medium2023gpt4carbon,
  title={{The Carbon Footprint of GPT-4}},
  author={{Data Science on Medium}},
  year={2023},
  url={https://medium.com/data-science/the-carbon-footprint-of-gpt-4-d6c676eb21ae}
}

@misc{extremenetworks2023energy,
  title={{Confronting AI’s Growing Energy Appetite: Part 1}},
  author={{Extreme Networks}},
  year={2023},
  url={https://www.extremenetworks.com/resources/blogs/confronting-ai-growing-energy-appetite-part-1}
}

@misc{sciencefeedback2024energy,
  title={{Training and Using ChatGPT Uses a Lot of Energy, but Exact Numbers Are Tricky to Pin Down Without Data from OpenAI}},
  author={{Science Feedback}},
  year={2024},
  url={https://science.feedback.org/training-and-using-chatgpt-uses-a-lot-of-energy-but-exact-numbers-are-tricky-to-pin-down-without-data-from-openai}
}

@misc{epochai2024compute,
  title={{Why GPT-5 Used Less Training Compute Than GPT-4.5 (But GPT-6 Probably Won’t)}},
  author={{Epoch AI}},
  year={2024},
  url={https://epoch.ai/gradient-updates/why-gpt5-used-less-training-compute-than-gpt45-but-gpt6-probably-wont}
}

@misc{hackernoon2024dirtysecret,
  title={{AI’s Dirty Secret: The Energy Cost of Training the Next GPT-5}},
  author={Hackernoon Editors},
  year={2024},
  url={https://hackernoon.com/ais-dirty-secret-the-energy-cost-of-training-the-next-gpt-5}
}

@article{kaplan2020scaling,
  title={{Scaling Laws for Neural Language Models}},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020},
  url={https://arxiv.org/abs/2001.08361}
}

%------------------------------------------------------------
@inproceedings{Scogland11Green500,
  author    = {Scogland, Thomas R. W. and Subramaniam, Balaji and Feng, Wu{-}Chun},
  title     = {{Emerging Trends on the Evolving Green500: Year Three}},
  booktitle = {Proc.\ IEEE IPDPS Workshops},
  year      = {2011},
  pages     = {889--895},
  doi       = {10.1109/IPDPS.2011.229}
}

@misc{NVIDIA23Blog,
  author       = {{NVIDIA Corporation}},
  title        = {Energy Efficiency in High-Performance Computing:
                  Balancing Speed and Sustainability},
  howpublished = {\url{https://developer.nvidia.com/blog/energy-efficiency-in-high-performance-computing-balancing-speed-and-sustainability/}},
  year         = {2023}
}

@INPROCEEDINGS{Tschand24MLPerfPower,
  author={Tschand, Arya and Rajan, Arun Tejusve Raghunath and Idgunji, Sachin and Ghosh, Anirban and Holleman, Jeremy and Kiraly, Csaba and Ambalkar, Pawan and Borkar, Ritika and Chukka, Ramesh and Cockrell, Trevor and Curtis, Oliver and Fursin, Grigori and Hodak, Miro and Kassa, Hiwot and Lokhmotov, Anton and Miskovic, Dejan and Pan, Yuechao and Manmathan, Manu Prasad and Raymond, Liz and John, Tom St. and Suresh, Arjun and Taubitz, Rowan and Zhan, Sean and Wasson, Scott and Kanter, David and Reddi, Vijay Janapa},
  booktitle={{IEEE International Symposium on High Performance Computer Architecture}}, 
  series = {HPCA},
  title={{MLPerf Power: Benchmarking the Energy Efficiency of Machine Learning Systems from $\mu$Watts to MWatts for Sustainable AI}},
  year={2025},
  volume={},
  number={},
  pages={1201-1216},
  keywords={Performance evaluation;Power demand;Power measurement;Standards organizations;Machine learning;Benchmark testing;Energy efficiency;Surges;Optimization;System analysis and design;mlperf;energy efficiency;sustainable ai;machine learning;computer architecture},
  doi={10.1109/HPCA61900.2025.00092}
}

@inproceedings{Peon23A100PowerCap,
  author    = {Dan Zhao and Siddharth Samsi and Joseph McDonald and
               Baolin Li and David Bestor and Michael Jones and
               Devesh Tiwari and Vijay Gadepally},
  title     = {Sustainable Supercomputing for {AI}: {GPU} Power Capping at {HPC} Scale},
  booktitle = {Proceedings of the Energy-Efficient {HPC} and {AI} Workshop at the International Conference for High Performance Computing, Networking, Storage and Analysis (SC~’23)},
  year      = {2023},
  doi       = {10.48550/arXiv.2402.18593},
  url       = {https://arxiv.org/abs/2402.18593},
  note      = {Demonstrates that capping NVIDIA A100 GPUs to 300\,W can
               cut energy by double-digit percentages with \textless1\,\%
               throughput loss.}
}
@techreport{Koomey21HyperscaleCost,
  author      = {Jonathan G.\ Koomey and Sarah E.\ Taylor},
  title       = {Cost Drivers for Hyperscale Data Centres:
                 Implications for Efficiency and Sustainability},
  institution = {Koomey Analytics},
  year        = {2021},
  type        = {White Paper},
  url         = {https://koomey.com/wp-content/uploads/2021/10/Koomey-Taylor-2021-Hyperscale-Cost-Drivers.pdf},
  note        = {Quantifies how a $\pm$10\;¢\,kWh$^{-1}$ electricity swing
                 alters the ROI of cooling technologies and renewable PPAs.}
}
@techreport{Freina24EnergySurvey,
  author      = {David Freina and Matthijs Jansen and Animesh Trivedi},
  title       = {A Survey of Energy Measurement Methodologies for Computer Systems},
  institution = {Vrije Universiteit Amsterdam},
  year        = {2024},
  type        = {Technical Report},
  url         = {https://atlarge-research.com/pdfs/2024-dfreina-litsurvey.pdf},
  note        = {Comprehensive taxonomy of hardware- and software-based
                 energy-measurement solutions, including accuracy limits
                 and calibration practices.}
}
@INPROCEEDINGS{Wang2010HPC-PUE,
  author={Wang, Lizhe and von Laszewski, Gregor and Dayal, Jay and Wang, Fugang},
  booktitle={2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing}, 
  title={Towards Energy Aware Scheduling for Precedence Constrained Parallel Tasks in a Cluster with DVFS}, 
  year={2010},
  volume={},
  number={},
  pages={368-377},
  keywords={Energy consumption;Processor scheduling;High performance computing;Dynamic voltage scaling;Power engineering computing;Frequency;Computational modeling;Grid computing;Concurrent computing;Costs;Cluster Computing;Green Computing;Task Scheduling},
  doi={10.1109/CCGRID.2010.19}}


%-----------------------------------------------------------------------



@misc{DOE_Frontier_Power2023,
  author   = {U.S. Department of Energy},
  title    = {Frontier {Power \& Cooling} Factsheet},
  year     = 2023,
  note     = {\url{https://www.olcf.ornl.gov/frontier-power}}
}


@misc{EIA_Electricity_Price_2025,
  author   = {U.S. Energy Information Administration},
  title    = {Average Price of Electricity to Ultimate Customers},
  year     = 2025,
  howpublished = {\url{https://www.eia.gov/electricity/monthly/}}
}

@misc{eia2024residential,
  title={Average Annual Electricity Consumption for U.S. Residential Customers},
  author={{U.S. Energy Information Administration}},
  year={2024},
  howpublished={Available at https://www.eia.gov/}
}

@misc{Eurostat_GHG_2024,
  author   = {Eurostat},
  title    = {Greenhouse Gas Emissions per Capita},
  year     = 2024,
  note     = {\url{https://ec.europa.eu/eurostat/statistics-explained/}}
}

@misc{Google_PUE_2023,
  author   = {Google LLC},
  title    = {Data Centre PUE Metrics (2023)},
  year     = 2023,
  note     = {\url{https://sustainability.google/reports/}}
}

@misc{Google_Sustainability_2024,
  author   = {Google LLC},
  title    = {2024 Environmental Report},
  year     = 2024,
  note     = {\url{https://sustainability.google/}}
}

@misc{Google_Geothermal_2023,
  author   = {Google LLC},
  title    = {Bringing 24/7 Geothermal to the Grid},
  year     = 2023,
  note     = {\url{https://www.blog.google/outreach-initiatives/sustainability/}}
}

@inproceedings{ING_SCALE_2024,
  author   = {van den Berg, J. and colleagues},
  title    = {SCALE: Carbon-Aware Scheduling for {Kubernetes} in the Cloud},
  booktitle= {Proc.\ ACM e-Energy},
  year     = 2024
}

@inproceedings{GREEN_Slurm_2025,
  author   = {Chen, L. and colleagues},
  title    = {GREEN: Carbon-Aware Job Placement for {Slurm} Clusters},
  booktitle= {USENIX NSDI},
  year     = 2025
}

@article{luccioni2023estimating,
  title={Estimating the carbon footprint of bloom, a 176b parameter language model},
  author={Luccioni, Alexandra Sasha and Viguier, Sylvain and Ligozat, Anne-Laure},
  journal={Journal of machine learning research},
  volume={24},
  number={253},
  pages={1--15},
  year={2023}
}

@inproceedings{EU2019_424,
  author       = {European Commission},
  title     = {Commission Regulation (EU) 2019/424 of 15 March 2019 Laying Down Ecodesign Requirements for Servers and Data Storage Products},
  booktitle = {Official Journal of the European Union},
  year      = {2019},
  note      = {\url{https://eur-lex.europa.eu/eli/reg/2019/424/oj}}
}
@misc{EU_Lot9_Guidance,
  author       = {European Commission},
  title        = {Guidance Document on the Ecodesign Requirements for Servers and Data Storage Products (Lot 9)},
  howpublished = {\url{https://data.europa.eu/doi/10.2873/782959}},
  year         = {2021},
  note         = {Sections 3–4 detail conformity‐assessment reports}
}@article{dongarra2003hpl,
  author =	 {Jack J. Dongarra and Piotr Luszczek and Antoine
                  Petitet},
  title =	 {The {LINPACK} Benchmark: Past, Present, and Future},
  journal =	 {Concurrency and Computation: Practice and
                  Experience},
  volume =	 15,
  number =	 9,
  pages =	 {803-820},
  month =	 {August 10},
  year =	 2003,
  note =	 {ISSN 1532-0634},
  doi =		 {10.1002/cpe.728}
}

@Book{dongarra1979linpack,
  author =	 {Jack J. Dongarra and J. Bunch and Cleve Moler and
                  G. W. Stewart},
  title =	 {{LINPACK} User's Guide},
  publisher =	 {Society of Industrial and Applied Mathematics},
  address =	 {Philadelphia, PA, USA},
  year =	 1979
}


@inproceedings{feng2005pwrprofsciapps,
  author =	 {W.-C. Feng and R. Ge and Kirk W. Cameron},
  title =	 {Power and Energy Profiling of Scientific
                  Applications on Distributed Systems},
  booktitle =	 {19th IEEE International Parallel and Distributed
                  Processing Symposium (IPDPS 05)},
  address =	 {Denver, CO, USA},
  year =	 2005
}

@article{cameron2005hpcpowerdistcompsciapps,
  author =	 {Kirk W. Cameron and R. Ge and X. Feng},
  title =	 {High-performance, Power-aware, Distributed Computing
                  for Scientific Applications},
  journal =	 {IEEE Computer},
  volume =	 38,
  number =	 11,
  pages =	 {40-47},
  year =	 2005
}

@misc{specpower2008,
  author =	 {SPEC},
  title =	 {The {SPEC} Power Benchmark},
  url={www.spec.org/power_ssj2008/},
  year =	 2008
}

@article{abdelfattah2021mxpsurvey
,author={Ahmad Abdelfattah and Hartwig Anzt and Erik G Boman and Erin Carson and Terry Cojean and Jack Dongarra and Alyson Fox and Mark Gates and Nicholas J Higham and Xiaoye S Li and Jennifer Loe and Piotr Luszczek and Srikara Pranesh and Siva Rajamanickam and Tobias Ribizel and Barry F Smith and Kasia Swirydowicz and Stephen Thomas and Stanimire Tomov and Yaohung M Tsai and Ulrike Meier Yang}
,title={A survey of numerical linear algebra methods utilizing mixed-precision arithmetic}
,journal={The International Journal of High Performance Computing Applications}
,volume=35
,number=4
,pages={344-369}
,year=2021
,doi={10.1177/10943420211003313}
,url={https://doi.org/10.1177/10943420211003313}
,eprint={https://doi.org/10.1177/10943420211003313}
,abstract={The efficient utilization of mixed-precision numerical linear algebra algorithms can offer attractive acceleration to scientific computing applications. Especially with the hardware integration of low-precision special-function units designed for machine learning applications, the traditional numerical algorithms community urgently needs to reconsider the floating point formats used in the distinct operations to efficiently leverage the available compute power. In this work, we provide a comprehensive survey of mixed-precision numerical linear algebra routines, including the underlying concepts, theoretical background, and experimental results for both dense and sparse linear algebra problems.}
}
@manual{NVIDIA:CUDA:ProfilerGuide,
  title = {{NVIDIA CUDA Profiler User's Guide}},
  author = {{NVIDIA Corporation}},
  organization = {{NVIDIA Corporation}},
  edition = {Current Edition Number, e.g., 12.0},
  year = {Current Year, e.g., 2024},
  note = {Documentation for nvprof. Available at \url{https://docs.nvidia.com/cuda/profiler-users-guide/index.html}},
}

@misc{NVIDIA_NsightSys_Doc,
  author = {{NVIDIA Corporation}},
  title = {{NVIDIA Nsight Systems Documentation}},
  howpublished = {\url{https://developer.nvidia.com/nsight-systems}},
  year = {2024}, 
  note = {Accessed: [Current Date]},
}

@misc{NVIDIA_NsightComp_Doc,
  author = {{NVIDIA Corporation}},
  title = {{NVIDIA Nsight Compute Documentation}},
  howpublished = {\url{https://docs.nvidia.com/nsight-compute/NsightCompute/index.html}},
  year = {2024}, 
  note = {Accessed: [Current Date]},
}

@misc{NVIDIA_CUDA_Doc,
  author = {{NVIDIA Corporation}},
  title = {{CUDA Toolkit Documentation}},
  howpublished = {\url{https://docs.nvidia.com/cuda/}},
  year = {2024}, 
  note = {Accessed: [Current Date]},
}

@article{TensorFlow_System,
  author = {Abadi, Martín and others},
  title = {{TensorFlow: A System for Large-Scale Machine Learning}},
  journal = {OSDI},
  volume = {16},
  pages = {265--283},
  year = {2016},
  publisher = {USENIX Association},
  note = {TensorBoard Profiler is a component of the TensorFlow ecosystem.}
}

@article{PyTorch_System,
  author = {Paszke, Adam and others},
  title = {{PyTorch: An Imperative Style, High-Performance Deep Learning Library}},
  journal = {Advances in Neural Information Processing Systems},
  volume = {32},
  year = {2019},
  note = {PyTorch Profiler is part of the PyTorch library.}
}

@inproceedings{Perfetto_Google,
  author = {Poulakos, George and others},
  title = {{Perfetto: A System-Wide Tracing Tool for Modern Applications}},
  booktitle = {Proceedings of the 35th International Conference on Software Engineering (ICSE 2023)},
  year = {2023},
  note = {Based on the Perfetto project's scope for system tracing.}
}

@misc{Intel_VTune_Doc,
  author = {{Intel Corporation}},
  title = {{Intel VTune Profiler Documentation}},
  howpublished = {\url{https://www.intel.com/content/www/us/en/develop/documentation/vtune-help/}},
  year = {2024}, 
  note = {Accessed: [Current Date]},
}

@misc{AMD_ROCM_Doc,
  author = {{AMD}},
  title = {{ROCm Documentation}},
  howpublished = {\url{https://rocm.docs.amd.com/en/latest/}},
  year = {2024}, 
  note = {Accessed: [Current Date]},
}

@article{HPCToolkit_Paper,
  author = {Mellor-Crummey, John and others},
  title = {{HPCToolkit: Tools for Performance Analysis of Optimized Parallel Programs}},
  journal = {Concurrency and Computation: Practice and Experience},
  volume = {24},
  number = {6},
  pages = {680--708},
  year = {2012},
}

@inproceedings{TAU_Paper,
  author = {Shende, Sameer and Malony, Allen D.},
  title = {{The TAU Parallel Performance System}},
  booktitle = {International Conference on Parallel and Distributed Computing and Systems},
  pages = {489--493},
  year = {1998},
}

@misc{NVIDIA_NCCL_Doc,
  author = {{NVIDIA Corporation}},
  title = {{NVIDIA Collective Communications Library (NCCL) Documentation}},
  howpublished = {\url{https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/index.html}},
  year = {2024}, 
  note = {Accessed: [Current Date]},
}

@inproceedings{XLA_Paper,
  author = {Wang, Dehao and others},
  title = {{XLA: Optimizing Compiler for TensorFlow}},
  booktitle = {Proceedings of the First Workshop on Systems for ML},
  year = {2017},
  note = {XLA Profiler is a feature of the XLA compiler.}
}

@misc{Triton_Paper,
  author = {OpenAI},
  title = {{Triton: An Intermediate Language for Tiled Tensor Computations}},
  howpublished = {\url{https://openai.com/research/triton}},
  year = {2019},
  note = {The Triton profiler is part of the Triton compiler and language.}
}

@inproceedings{PAPI_Paper,
  author       = {Shirley Browne and
                  Jack J. Dongarra and
                  Nathan Garner and
                  Kevin S. London and
                  Philip Mucci},
  editor       = {Jed Donnelley},
  title        = {{A Scalable Cross-Platform Infrastructure for Application Performance Tuning Using Hardware Counters}},
  booktitle    = {{Proceedings Supercomputing 2000, November 4-10, 2000, Dallas, Texas,
                  {USA.} {IEEE} Computer Society, {CD-ROM}}},
  pages        = {42},
  publisher    = {{IEEE} Computer Society},
  year         = {2000},
  url          = {https://doi.org/10.1109/SC.2000.10029},
  doi          = {10.1109/SC.2000.10029},
  timestamp    = {Fri, 24 Mar 2023 00:04:25 +0100},
  biburl       = {https://dblp.org/rec/conf/sc/BrowneDGLM00.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@manual{JAX_Profiler,
  title        = {JAX Profiler},
  author       = {Google},
  howpublished = {\url{https://jax.readthedocs.io/en/latest/profiling.html}},
  year         = {2025},
  note         = {Accessed: 2025-10-22}
}

@manual{NVIDIA_DLProf,
  title        = {NVIDIA Deep Learning Profiler (DLProf)},
  author       = {NVIDIA},
  howpublished = {\url{https://developer.nvidia.com/deep-learning-profiler}},
  year         = {2025},
  note         = {Accessed: 2025-10-22}
}

@manual{TorchDynamo_TorchInductor,
  title        = {TorchDynamo \& TorchInductor Debug Tools},
  author       = {Meta (Facebook)},
  howpublished = {\url{https://pytorch.org/blog/torchdynamo/}},
  year         = {2025},
  note         = {Accessed: 2025-10-22}
}

@manual{AWS_SageMaker_Debugger,
  title        = {AWS SageMaker Debugger},
  author       = {Amazon Web Services},
  howpublished = {\url{https://docs.aws.amazon.com/sagemaker/latest/dg/debugger.html}},
  year         = {2025},
  note         = {Accessed: 2025-10-22}
}

@manual{Azure_Profiler,
  title        = {Azure Machine Learning Profiler},
  author       = {Microsoft},
  howpublished = {\url{https://learn.microsoft.com/en-us/azure/machine-learning/how-to-monitor-profiling}},
  year         = {2025},
  note         = {Accessed: 2025-10-22}
}

@manual{Weights_Biases,
  title        = {Weights \& Biases},
  author       = {Weights \& Biases},
  howpublished = {\url{https://wandb.ai/site}},
  year         = {2025},
  note         = {Accessed: 2025-10-22}
}

@manual{Comet_ML,
  title        = {Comet ML},
  author       = {Comet ML},
  howpublished = {\url{https://www.comet.com/site/}},
  year         = {2025},
  note         = {Accessed: 2025-10-22}
}

@manual{MLflow,
  title        = {MLflow},
  author       = {Databricks},
  howpublished = {\url{https://mlflow.org/}},
  year         = {2025},
  note         = {Accessed: 2025-10-22}
}

@manual{Torch_Tensorflow_Memory,
  title        = {Torch/TensorFlow Memory Tools},
  author       = {Meta / Google},
  howpublished = {\url{https://pytorch.org/docs/stable/notes/memory.html}},
  year         = {2025},
  note         = {Accessed: 2025-10-22}
}

@manual{Python_Profilers,
  title        = {Python Profilers (cProfile, py-spy)},
  author       = {Python Software Foundation},
  howpublished = {\url{https://docs.python.org/3/library/profile.html}},
  year         = {2025},
  note         = {Accessed: 2025-10-22}
}
@Misc{Reiley2016,
  author =	 {{Carol Reiley}},
  title =	 {{Deep Driving}},
  note =
                  {\url{https://www.technologyreview.com/s/602600/deep-driving/}},
  year =	 2016
}

@article{shockwave,
  title =	 {Shockwave: Fair and Efficient Cluster Scheduling for
                  Dynamic Adaptation in Machine Learning},
  author =	 {Pengfei Zheng and Rui Pan and Tarannum Khan and
                  Shivaram Venkataraman and Aditya Akella},
  year =	 2022,
  journal =	 {arXiv preprint 2210.00093},
}

@inproceedings{shen2019nexus,
  title =	 {Nexus: a GPU cluster engine for accelerating
                  DNN-based video analysis},
  author =	 {Shen, Haichen and Chen, Lequn and Jin, Yuchen and
                  Zhao, Liangyu and Kong, Bingyu and Philipose,
                  Matthai and Krishnamurthy, Arvind and Sundaram,
                  Ravi},
  booktitle =	 {Proceedings of the 27th ACM Symposium on Operating
                  Systems Principles},
  pages =	 {322--337},
  year =	 2019
}

@inproceedings{marathe2017performance,
  title =	 {Performance modeling under resource constraints
                  using deep transfer learning},
  author =	 {Marathe, Aniruddha and Anirudh, Rushil and Jain,
                  Nikhil and Bhatele, Abhinav and Thiagarajan,
                  Jayaraman and Kailkhura, Bhavya and Yeom, Jae-Seung
                  and Rountree, Barry and Gamblin, Todd},
  booktitle =	 {International Conference for High Performance
                  Computing, Networking, Storage and Analysis},
  pages =	 31,
  year =	 2017,
  organization = {ACM}
}

@article{zaharia2016apache,
  title =	 {Apache Spark: a unified engine for big data
                  processing},
  author =	 {Zaharia, Matei and Xin, Reynold S and Wendell,
                  Patrick and Das, Tathagata and Armbrust, Michael and
                  Dave, Ankur and Meng, Xiangrui and Rosen, Josh and
                  Venkataraman, Shivaram and Franklin, Michael J and
                  others},
  journal =	 {Communications of the ACM},
  volume =	 59,
  number =	 11,
  pages =	 {56--65},
  year =	 2016,
  publisher =	 {ACM New York, NY, USA}
}

@article{meng2016mllib,
  title =	 {Mllib: Machine learning in apache spark},
  author =	 {Meng, Xiangrui and Bradley, Joseph and Yavuz, Burak
                  and Sparks, Evan and Venkataraman, Shivaram and Liu,
                  Davies and Freeman, Jeremy and Tsai, DB and Amde,
                  Manish and Owen, Sean and others},
  journal =	 {The Journal of Machine Learning Research},
  volume =	 17,
  number =	 1,
  pages =	 {1235--1241},
  year =	 2016,
  publisher =	 {JMLR. org}
}

@inproceedings{rao2017experiments,
  title =	 {Experiments and Analyses of Data Transfers over
                  Wide-Area Dedicated Connections},
  author =	 {Rao, Nageswara SV and Liu, Qiang and Sen, Satyabrata
                  and Hanley, Jesse and Foster, Ian and Kettimuthu,
                  Rajkumar and Wu, Chase Q and Yun, Daqing and
                  Towsley, Don and Vardoyan, Gayane},
  booktitle =	 {26th International Conference on Computer
                  Communication and Networks},
  pages =	 {1--9},
  year =	 2017,
  organization = {IEEE}
}

@inproceedings{beckman2017skluma,
  title =	 {Skluma: A Statistical Learning Pipeline for Taming
                  Unkempt Data Repositories},
  author =	 {Beckman, Paul and Skluzacek, Tyler J and Chard, Kyle
                  and Foster, Ian},
  booktitle =	 {Proceedings of the 29th International Conference on
                  Scientific and Statistical Database Management},
  pages =	 41,
  year =	 2017,
  organization = {ACM}
}

@Misc{DLHub,
  title =	 {Building an {ALCF} Data Service: Interactive,
                  Scalable, Reproducible Data Science},
  year =	 2017,
  note =
                  {\url{https://www.slideshare.net/ianfoster/going-smart-and-deep-on-materials-at-alcf}}
}

@article{chard2017cost,
  title =	 {Cost-Aware Cloud Profiling, Prediction, and
                  Provisioning as a Service},
  author =	 {Chard, Ryan and Chard, Kyle and Wolski, Rich and
                  Madduri, Ravi and Ng, Bryan and Bubendorfer, Kris
                  and Foster, Ian},
  journal =	 {IEEE Cloud Computing},
  volume =	 4,
  number =	 4,
  pages =	 {48--59},
  year =	 2017,
  publisher =	 {IEEE}
}

@book{foster1995designing,
  title =	 {Designing and Building Parallel Programs},
  author =	 {Foster, Ian},
  year =	 1995,
  publisher =	 {Addison Wesley Publishing Company Boston}
}

@article{lecun2015deep,
  title =	 {Deep learning},
  author =	 {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal =	 {Nature},
  volume =	 521,
  number =	 7553,
  pages =	 {436--444},
  year =	 2015,
  publisher =	 {Nature Research}
}

@book{hennessy2011computer,
  title =	 {Computer Architecture: A Quantitative Approach},
  author =	 {Hennessy, John L and Patterson, David A},
  year =	 2011,
  publisher =	 {Elsevier}
}

@inproceedings{liu2017explaining,
  title =	 {Explaining wide area data transfer performance},
  author =	 {Liu, Zhengchun and Balaprakash, Prasanna and
                  Kettimuthu, Rajkumar and Foster, Ian},
  booktitle =	 {26th International Symposium on High-Performance
                  Parallel and Distributed Computing},
  pages =	 {167--178},
  year =	 2017,
  organization = {ACM}
}

@article{foster1997parallel,
  title =	 {Parallel algorithms for the spectral transform
                  method},
  author =	 {Foster, Ian T and Worley, Patrick H},
  journal =	 {SIAM Journal on Scientific Computing},
  volume =	 18,
  number =	 3,
  pages =	 {806--837},
  year =	 1997,
  publisher =	 {SIAM}
}

@article{Silver2016,
  title =	 {Mastering the game of {Go} with deep neural networks
                  and tree search},
  author =	 {Silver, David and Huang, Aja and Maddison, Chris J
                  and Guez, Arthur and Sifre, Laurent and Van Den
                  Driessche, George and Schrittwieser, Julian and
                  Antonoglou, Ioannis and Panneershelvam, Veda and
                  Lanctot, Marc and others},
  journal =	 {Nature},
  volume =	 529,
  number =	 7587,
  pages =	 {484--489},
  year =	 2016,
  publisher =	 {Nature Publishing Group}
}

@Misc{Alba2016,
  author =	 {{Alba, Davey}},
  title =	 {{Only Amazon Could Make a Checkout-Free Grocery
                  Store a Reality}},
  note =
                  {\url{https://www.wired.com/2016/12/amazon-go-grocery-store/}},
  year =	 2016
}

@article{Pedregosa2011,
  title =	 {Scikit-learn: Machine Learning in {P}ython},
  author =	 {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and
                  Michel, V.  and Thirion, B. and Grisel, O. and
                  Blondel, M. and Prettenhofer, P.  and Weiss, R. and
                  Dubourg, V. and Vanderplas, J. and Passos, A. and
                  Cournapeau, D. and Brucher, M. and Perrot, M. and
                  Duchesnay, E.},
  journal =	 {Journal of Machine Learning Research},
  volume =	 12,
  pages =	 {2825--2830},
  year =	 2011
}

@article{Meng2016,
  title =	 {{MLlib: Machine learning in apache spark}},
  author =	 {Meng, Xiangrui and Bradley, Joseph and Yavuz, Burak
                  and Sparks, Evan and Venkataraman, Shivaram and Liu,
                  Davies and Freeman, Jeremy and Tsai, DB and Amde,
                  Manish and Owen, Sean and others},
  journal =	 {Journal of Machine Learning Research},
  volume =	 17,
  number =	 34,
  pages =	 {1--7},
  year =	 2016
}

@article{Jia2014,
  Author =	 {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff
                  and Karayev, Sergey and Long, Jonathan and Girshick,
                  Ross and Guadarrama, Sergio and Darrell, Trevor},
  Journal =	 {arXiv preprint arXiv:1408.5093},
  Title =	 {Caffe: Convolutional Architecture for Fast Feature
                  Embedding},
  Year =	 2014
}

@inproceedings{Abadi2016,
  title =	 {TensorFlow: A system for large-scale machine
                  learning},
  author =	 {Abadi, Mart{\'\i}n and Barham, Paul and Chen,
                  Jianmin and Chen, Zhifeng and Davis, Andy and Dean,
                  Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and
                  Irving, Geoffrey and Isard, Michael and others},
  booktitle =	 {Proceedings of the 12th USENIX Symposium on
                  Operating Systems Design and Implementation
                  (OSDI). Savannah, Georgia, USA},
  year =	 2016
}

@inproceedings{Collobert2011,
  title =	 {Torch7: A matlab-like environment for machine
                  learning},
  author =	 {Collobert, Ronan and Kavukcuoglu, Koray and Farabet,
                  Cl{\'e}ment},
  booktitle =	 {BigLearn, NIPS Workshop},
  number =	 {EPFL-CONF-192376},
  year =	 2011
}

@article{Aliper2016,
  title =	 {Deep learning applications for predicting
                  pharmacological properties of drugs and drug
                  repurposing using transcriptomic data},
  author =	 {Aliper, Alexander and Plis, Sergey and Artemov,
                  Artem and Ulloa, Alvaro and Mamoshina, Polina and
                  Zhavoronkov, Alex},
  journal =	 {Molecular pharmaceutics},
  volume =	 13,
  number =	 7,
  pages =	 {2524--2530},
  year =	 2016,
  publisher =	 {ACS Publications}
}

@article{Codella2016,
  title =	 {Deep Learning Ensembles for Melanoma Recognition in
                  Dermoscopy Images},
  author =	 {Codella, Noel and Nguyen, Quoc-Bao and Pankanti,
                  Sharath and Gutman, David and Helba, Brian and
                  Halpern, Allan and Smith, John R},
  journal =	 {arXiv preprint arXiv:1610.04662},
  year =	 2016
}

@article{Baldi2014,
  title =	 {Searching for exotic particles in high-energy
                  physics with deep learning},
  author =	 {Baldi, Pierre and Sadowski, Peter and Whiteson,
                  Daniel},
  journal =	 {Nature communications},
  volume =	 5,
  year =	 2014,
  publisher =	 {Nature Publishing Group}
}

@article{Plis2013,
  title =	 {Deep learning for neuroimaging: a validation study},
  author =	 {Plis, Sergey M and Hjelm, Devon R and Salakhutdinov,
                  Ruslan and Calhoun, Vince D},
  journal =	 {arXiv preprint arXiv:1312.5847},
  year =	 2013
}

@inproceedings{Bergstra2010,
  title =	 {Theano: A {CPU} and {GPU} math compiler in {P}ython},
  author =	 {Bergstra, James and Breuleux, Olivier and Bastien,
                  Fr{\'e}d{\'e}ric and Lamblin, Pascal and Pascanu,
                  Razvan and Desjardins, Guillaume and Turian, Joseph
                  and Warde-Farley, David and Bengio, Yoshua},
  booktitle =	 {Proc. 9th Python in Science Conf},
  pages =	 {1--7},
  year =	 2010
}

@article{Yu2014,
  title =	 {An introduction to computational networks and the
                  computational network toolkit},
  author =	 {Yu, Dong and Eversole, Adam and Seltzer, Mike and
                  Yao, Kaisheng and Huang, Zhiheng and Guenter, Brian
                  and Kuchaiev, Oleksii and Zhang, Yu and Seide, Frank
                  and Wang, Huaming and Jasha Droppo and Geoffrey
                  Zweig and Chris Rossbach and Jon Currey and Jie Gao
                  and Avner May and Baolin Peng and Andreas Stolcke
                  and Malcolm Slaney},
  journal =	 {Microsoft Technical Report MSR-TR-2014--112},
  year =	 2014
}

@article{Chen2015,
  title =	 {{MXNet}: A flexible and efficient machine learning
                  library for heterogeneous distributed systems},
  author =	 {Chen, Tianqi and Li, Mu and Li, Yutian and Lin, Min
                  and Wang, Naiyan and Wang, Minjie and Xiao, Tianjun
                  and Xu, Bing and Zhang, Chiyuan and Zhang, Zheng},
  journal =	 {arXiv preprint arXiv:1512.01274},
  year =	 2015
}

@inproceedings{Nothaft2015,
  title =	 {Rethinking data-intensive science using scalable
                  analytics systems},
  author =	 {Nothaft, Frank Austin and Massie, Matt and Danford,
                  Timothy and Zhang, Zhao and Laserson, Uri and
                  Yeksigian, Carl and Kottalam, Jey and Ahuja, Arun
                  and Hammerbacher, Jeff and Linderman, Michael and
                  others},
  booktitle =	 {Proceedings of the 2015 ACM SIGMOD International
                  Conference on Management of Data},
  pages =	 {631--646},
  year =	 2015,
  organization = {ACM}
}

@article{Zhang2016,
  title =	 {Kira: Processing Astronomy Imagery Using Big Data
                  Technology},
  author =	 {Zhang, Zhao and Barbary, Kyle and Nothaft, Frank A
                  and Sparks, Evan R and Zahn, Oliver and Franklin,
                  Michael J and Patterson, David A and Perlmutter,
                  Saul},
  journal =	 {IEEE Transactions on Big Data},
  year =	 2016,
  publisher =	 {IEEE}
}

@inproceedings{Zhang2013,
  title =	 {Parallelizing the execution of sequential scripts},
  author =	 {Zhang, Zhao and Katz, Daniel S and Armstrong,
                  Timothy G and Wozniak, Justin M and Foster, Ian},
  booktitle =	 {Proceedings of the International Conference on High
                  Performance Computing, Networking, Storage and
                  Analysis},
  pages =	 31,
  year =	 2013,
  organization = {ACM}
}

@inproceedings{Zhang2012,
  title =	 {Design and analysis of data management in scalable
                  parallel scripting},
  author =	 {Zhang, Zhao and Katz, Daniel S and Wozniak, Justin M
                  and Espinosa, Allan and Foster, Ian},
  booktitle =	 {Proceedings of the International Conference on High
                  Performance Computing, Networking, Storage and
                  Analysis},
  pages =	 85,
  year =	 2012,
  organization = {IEEE Computer Society Press}
}

@article{Charnock2016,
  title =	 {Deep Recurrent Neural Networks for Supernovae
                  Classification},
  author =	 {Charnock, Tom and Moss, Adam},
  journal =	 {arXiv preprint arXiv:1606.07442},
  year =	 2016
}

@inproceedings{Chicco2014,
  title =	 {Deep autoencoder neural networks for gene ontology
                  annotation predictions},
  author =	 {Chicco, Davide and Sadowski, Peter and Baldi,
                  Pierre},
  booktitle =	 {Proceedings of the 5th ACM Conference on
                  Bioinformatics, Computational Biology, and Health
                  Informatics},
  pages =	 {533--540},
  year =	 2014,
  organization = {ACM}
}

@article{Choi2016,
  title =	 {Using recurrent neural network models for early
                  detection of heart failure onset},
  author =	 {Choi, Edward and Schuetz, Andy and Stewart, Walter F
                  and Sun, Jimeng},
  journal =	 {Journal of the American Medical Informatics
                  Association},
  pages =	 {ocw112},
  year =	 2016,
  publisher =	 {The Oxford University Press}
}

@inproceedings{Lena2012,
  title =	 {Deep spatio-temporal architectures and learning for
                  protein structure prediction},
  author =	 {Lena, Pietro D and Nagata, Ken and Baldi, Pierre F},
  booktitle =	 {Advances in neural information processing systems},
  pages =	 {512--520},
  year =	 2012
}

@article{Aulck2016,
  title =	 {Predicting Student Dropout in Higher Education},
  author =	 {Aulck, Lovenoor and Velagapudi, Nishant and
                  Blumenstock, Joshua and West, Jevin},
  journal =	 {arXiv preprint arXiv:1606.06364},
  year =	 2016
}

@article{Khan2016,
  title =	 {Machine Learning Across Cultures: Modeling the
                  Adoption of Financial Services for the Poor},
  author =	 {Khan, Muhammad Raza and Blumenstock, Joshua E},
  journal =	 {arXiv preprint arXiv:1606.05105},
  year =	 2016
}

@inproceedings{Coates2013,
  title =	 {Deep learning with COTS HPC systems},
  author =	 {Coates, Adam and Huval, Brody and Wang, Tao and Wu,
                  David and Catanzaro, Bryan and Andrew, Ng},
  booktitle =	 {Proceedings of The 30th International Conference on
                  Machine Learning},
  pages =	 {1337--1345},
  year =	 2013
}

@inproceedings{Dean2012,
  title =	 {Large scale distributed deep networks},
  author =	 {Dean, Jeffrey and Corrado, Greg and Monga, Rajat and
                  Chen, Kai and Devin, Matthieu and Mao, Mark and
                  Senior, Andrew and Tucker, Paul and Yang, Ke and Le,
                  Quoc V and others},
  booktitle =	 {Advances in neural information processing systems},
  pages =	 {1223--1231},
  year =	 2012
}

@inproceedings{Cui2016,
  title =	 {{GeePS}: Scalable deep learning on distributed gpus
                  with a gpu-specialized parameter server},
  author =	 {Cui, Henggang and Zhang, Hao and Ganger, Gregory R
                  and Gibbons, Phillip B and Xing, Eric P},
  booktitle =	 {Proceedings of the Eleventh European Conference on
                  Computer Systems},
  pages =	 4,
  year =	 2016,
  organization = {ACM}
}

@article{Zhang2015,
  title =	 {Poseidon: A system architecture for efficient
                  {GPU-based} deep learning on multiple machines},
  author =	 {Zhang, Hao and Hu, Zhiting and Wei, Jinliang and
                  Xie, Pengtao and Kim, Gunhee and Ho, Qirong and
                  Xing, Eric},
  journal =	 {arXiv preprint arXiv:1512.06216},
  year =	 2015
}

@Misc{Gropp2017,
  author =	 {{NCSA}},
  title =	 {{Performance Analysis of Large Scale Deep Learning
                  Systems}},
  note =
                  {\url{https://bluewaters.ncsa.illinois.edu/science-teams?page=detail&psn=baie}},
  year =	 2017
}

@Misc{Sirignano2017,
  author =	 {{NCSA}},
  title =	 "{Distributed Learning with Neural Networks}",
  note =
                  "\url{https://bluewaters.ncsa.illinois.edu/science-teams?page=detail&psn=bahp}",
  year =	 2017
}

@Misc{Brunner2017,
  author =	 {{NCSA}},
  title =	 {{Applying Deep Learning on Time Series Astronomical
                  Data}},
  note =
                  {\url{https://bluewaters.ncsa.illinois.edu/science-teams?page=detail&psn=bacy}},
  year =	 2017
}

@Misc{Peng2017,
  author =	 {{NCSA}},
  title =	 {{Protein structure prediction using deep neural
                  networks}},
  note =
                  {\url{https://bluewaters.ncsa.illinois.edu/science-teams?page=detail&psn=baiq}},
  year =	 2017
}

@Misc{LLNL2015,
  author =	 {{LLNL}},
  title =	 {{The Livermore Brain: Massive Deep-Learning Networks
                  Enabled by High-Performance Computing}},
  note =
                  {\url{https://ldrd-annual.llnl.gov/ldrd-annual-2015/computing/brain}},
  year =	 2015
}

@Misc{Kincade2015,
  author =	 {{LBNL}},
  title =	 {{Berkeley Lab Explores Frontiers of Deep Learning
                  for Science}},
  note =
                  {\url{https://cs.lbl.gov/news-media/news/2015/berkeley-lab-explores-frontiers-of-deep-learning-for-science/}},
  year =	 2015
}

@Misc{Russel2016,
  author =	 {{Russel, John}},
  title =	 {{Enlisting Deep Learning in the War on Cancer}},
  note =
                  {\url{https://www.hpcwire.com/2016/12/07/enlisting-deep-learning-war-cancer/}},
  year =	 2016
}

@Misc{PNNL2016,
  author =	 {{PNNL}},
  title =	 {{New Deep Learning Project Launches at PNNL}},
  note =
                  {\url{http://www.pnnl.gov/science/highlights/highlight.asp?id=4443}},
  year =	 2016
}

@article{Bahrampour2015,
  title =	 {Comparative study of caffe, neon, theano, and torch
                  for deep learning},
  author =	 {Bahrampour, Soheil and Ramakrishnan, Naveen and
                  Schott, Lukas and Shah, Mohak},
  journal =	 {arXiv preprint arXiv:1511.06435},
  year =	 2015
}

@article{Simmhan05,
  title =	 {A survey of data provenance in e-science},
  author =	 {Simmhan, Yogesh L and Plale, Beth and Gannon,
                  Dennis},
  journal =	 {ACM Sigmod Record},
  volume =	 34,
  number =	 3,
  pages =	 {31--36},
  year =	 2005,
  publisher =	 {ACM}
}

@misc{NSCI,
  author =	 {{The National Strategic Computing Initiative
                  Executive Council}},
  title =	 {{National Strategic Computing Initiative Strategic
                  Plan}},
  year =	 2016,
  note =
                  {\url{https://www.whitehouse.gov/sites/whitehouse.gov/files/images/NSCI\%20Strategic\%20Plan.pdf}}
}

@inproceedings{sutskever2014sequence,
  title =	 {Sequence to sequence learning with neural networks},
  author =	 {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  booktitle =	 {Advances in Neural Information Processing Systems},
  pages =	 {3104--3112},
  year =	 2014
}

@article{ching2017opportunities,
  title =	 {Opportunities And Obstacles For Deep Learning In
                  Biology And Medicine},
  author =	 {Ching, Travers and Himmelstein, Daniel S and
                  Beaulieu-Jones, Brett K and Kalinin, Alexandr A and
                  Do, Brian T and Way, Gregory P and Ferrero, Enrico
                  and Agapow, Paul-Michael and Xie, Wei and Rosen,
                  Gail L and Benjamin J. Lengerich and Johnny Israeli
                  and Jack Lanchantin and Stephen Woloszynek and Anne
                  E. Carpenter and Avanti Shrikumar and Jinbo Xu and
                  Evan M. Cofer and David J. Harris and Dave DeCaprio
                  and Yanjun Qi and Anshul Kundaje and Yifan Peng and
                  Laura K. Wiley and Marwin H.S.  Segler and Anthony
                  Gitter and Casey S. Greene},
  journal =	 {bioRxiv},
  pages =	 142760,
  year =	 2017,
  publisher =	 {Cold Spring Harbor Labs Journals}
}

@inproceedings{balaprakash2013active,
  title =	 {Active-learning-based surrogate models for empirical
                  performance tuning},
  author =	 {Balaprakash, Prasanna and Gramacy, Robert B and
                  Wild, Stefan M},
  booktitle =	 {IEEE International Conference on Cluster Computing},
  pages =	 {1--8},
  year =	 2013,
  organization = {IEEE}
}

@inproceedings{chard2017globus,
  title =	 {Globus: Research data management as service and
                  platform},
  author =	 {Chard, Kyle and Foster, Ian and Tuecke, Steven},
  booktitle =	 {Proceedings of the Practice and Experience in
                  Advanced Research Computing 2017 on Sustainability,
                  Success and Impact},
  pages =	 26,
  year =	 2017,
  organization = {ACM}
}

@article{chard2017modern,
  title =	 {The Modern Research Data Portal: A design pattern
                  for networked, data-intensive science},
  author =	 {Chard, Kyle and Dart, Eli and Foster, Ian and
                  Shifflett, David and Tuecke, Steven and Williams,
                  Jason},
  journal =	 {PeerJ Preprints},
  year =	 2017,
  publisher =	 {PeerJ, Inc.}
}

@book{foster2017cloud,
  title =	 {Cloud Computing for Science and Engineering},
  author =	 {Foster, Ian and Gannon, Dennis B},
  year =	 2017,
  publisher =	 {MIT Press}
}

@article{foster2018research,
  title =	 {Research infrastructure for the safe analysis of
                  sensitive data},
  author =	 {Foster, Ian},
  journal =	 {The ANNALS of the American Academy of Political and
                  Social Science},
  volume =	 675,
  number =	 1,
  pages =	 {102--120},
  year =	 2018,
  publisher =	 {SAGE Publications Sage CA: Los Angeles, CA}
}

@inproceedings{ogilvie2014fast,
  title =	 {Fast automatic heuristic construction using active
                  learning},
  author =	 {Ogilvie, William F and Petoumenos, Pavlos and Wang,
                  Zheng and Leather, Hugh},
  booktitle =	 {International Workshop on Languages and Compilers
                  for Parallel Computing},
  pages =	 {146--160},
  year =	 2014,
  organization = {Springer}
}

@inproceedings{Foster02,
  title =	 {Chimera: A virtual data system for representing,
                  querying, and automating data derivation},
  author =	 {Foster, Ian and V{\"o}ckler, Jens and Wilde, Michael
                  and Zhao, Yong},
  booktitle =	 {Scientific and Statistical Database Management,
                  2002. Proceedings. 14th International Conference on},
  pages =	 {37--46},
  year =	 2002,
  organization = {IEEE}
}

@article{Oinn02,
  title =	 {Taverna: lessons in creating a workflow environment
                  for the life sciences},
  author =	 {Oinn, Tom and Greenwood, Mark and Addis, Matthew J
                  and Alpdemir, M Nedim and Ferris, Justin and Glover,
                  Kevin and Goble, Carole and Goderis, Antoon and
                  Hull, Duncan and Marvin, DJ and others},
  journal =	 {Journal of Concurrency and Computation: Practice and
                  experience},
  year =	 2002,
  publisher =	 {John Wiley \& Sons Ltd}
}

@inproceedings{Frew01,
  title =	 {Earth system science workbench: A data management
                  infrastructure for earth science products},
  author =	 {Frew, James and Bose, Rajendra},
  booktitle =	 {Scientific and Statistical Database Management,
                  2001. SSDBM 2001. Proceedings. Thirteenth
                  International Conference on},
  pages =	 {180--189},
  year =	 2001,
  organization = {IEEE}
}

@incollection{Altintas2010,
  title =	 {Understanding collaborative studies through
                  interoperable workflow provenance},
  author =	 {Altintas, Ilkay and Anand, Manish Kumar and Crawl,
                  Daniel and Bowers, Shawn and Belloum, Adam and
                  Missier, Paolo and Lud{\"a}scher, Bertram and Goble,
                  Carole A and Sloot, Peter MA},
  booktitle =	 {Provenance and Annotation of Data and Processes},
  pages =	 {42--58},
  year =	 2010,
  publisher =	 {Springer}
}

@incollection{Altintas2006,
  title =	 {Provenance collection support in the kepler
                  scientific workflow system},
  author =	 {Altintas, Ilkay and Barney, Oscar and Jaeger-Frank,
                  Efrat},
  booktitle =	 {Provenance and annotation of data},
  pages =	 {118--132},
  year =	 2006,
  publisher =	 {Springer}
}

@article{Simmhan2010,
  title =	 {Karma2: Provenance management for data-driven
                  workflows},
  author =	 {Simmhan, Yogesh L and Plale, Beth and Gannon,
                  Dennis},
  journal =	 {Web Services Research for Emerging Applications:
                  Discoveries and Trends: Discoveries and Trends},
  pages =	 317,
  year =	 2010,
  publisher =	 {IGI Global}
}

@article{Sroka2010,
  title =	 {A formal semantics for the Taverna 2 workflow model},
  author =	 {Sroka, Jacek and Hidders, Jan and Missier, Paolo and
                  Goble, Carole},
  journal =	 {Journal of Computer and System Sciences},
  volume =	 76,
  number =	 6,
  pages =	 {490--508},
  year =	 2010,
  publisher =	 {Elsevier}
}

@inproceedings{Missier2010,
  title =	 {Fine-grained and efficient lineage querying of
                  collection-based workflow provenance},
  author =	 {Missier, Paolo and Paton, Norman W and Belhajjame,
                  Khalid},
  booktitle =	 {Proceedings of the 13th International Conference on
                  Extending Database Technology},
  pages =	 {299--310},
  year =	 2010,
  organization = {ACM}
}

@article{Bowers2008,
  title =	 {Provenance in collection-oriented scientific
                  workflows},
  author =	 {Bowers, Shawn and McPhillips, Timothy M and
                  Lud{\"a}scher, Bertram},
  journal =	 {Concurrency and Computation: Practice and
                  Experience},
  volume =	 20,
  number =	 5,
  pages =	 {519--529},
  year =	 2008,
  publisher =	 {Wiley Online Library}
}

@article{bose05,
  title =	 {Lineage retrieval for scientific data processing: a
                  survey},
  author =	 {Bose, Rajendra and Frew, James},
  journal =	 {ACM Computing Surveys (CSUR)},
  volume =	 37,
  number =	 1,
  pages =	 {1--28},
  year =	 2005,
  publisher =	 {ACM}
}

@article{freire08,
  title =	 {Provenance for computational tasks: A survey},
  author =	 {Freire, Juliana and Koop, David and Santos, Emanuele
                  and Silva, Cl{\'a}udio T},
  journal =	 {Computing in Science \& Engineering},
  volume =	 10,
  number =	 3,
  pages =	 {11--21},
  year =	 2008,
  publisher =	 {AIP Publishing}
}

@Misc{Stodden2014,
  author =	 {{Victoria Stodden}},
  title =	 "{2014 : WHAT SCIENTIFIC IDEA IS READY FOR
                  RETIREMENT?}",
  note =	 "\url{https://www.edge.org/response-detail/25340}",
  year =	 2014
}

@misc{Torvalds2010,
  title =	 {Git: Fast version control system},
  author =	 {Torvalds, Linus and Hamano, Junio},
  note =	 "\url{http://git-scm.com}",
  year =	 2010
}

@article{Collins2002,
  title =	 {Version control with subversion},
  author =	 {Collins-Sussman, Ben and Fitzpatrick, Brian W and
                  Pilato, C Michael},
  journal =	 {Version Control with Subversion},
  year =	 2002
}

@inproceedings{Callahan2006,
  title =	 {Managing the evolution of dataflows with VisTrails},
  author =	 {Callahan, Steven P and Freire, Juliana and Santos,
                  Emanuele and Scheidegger, Carlos Eduardo and Silva,
                  Claudio T and Vo, Huy T},
  booktitle =	 {Data Engineering Workshops, 2006. Proceedings. 22nd
                  International Conference on},
  pages =	 {71--71},
  year =	 2006,
  organization = {IEEE}
}

@Misc{NSCI2016,
  author =	 {{The National Strategic Computing Initiative
                  Executive Council}},
  title =	 "{National Strategic Computing Initiative Strategic
                  Plan}",
  note =
                  "\url{https://www.whitehouse.gov/sites/whitehouse.gov/files/images/NSCI%20Strategic%20Plan.pdf}",
  year =	 2016
}

@misc{Deepbench2017,
  title =	 {DeepBench: Benchmarking Deep Learning operations on
                  different hardware},
  author =	 {{Baidu Research}},
  note =	 "\url{https://github.com/baidu-research/DeepBench}",
  year =	 2017
}

@misc{Narang2017-deepBench,
  title =	 {{An update to DeepBench with a focus on deep
                  learning inference}},
  author =	 {Narang, Sharan and Diamos, Greg},
  year =	 2017,
  howpublished = {\url{https://svail.github.io/DeepBench-update/}},
}

@misc{MLSL,
  title =	 {Intel(R) Machine Learning Scaling Library},
  author =	 {{Intel}},
  note =	 "\url{https://github.com/intel/MLSL}",
  year =	 2019
}

@inproceedings{you2018imagenet,
  title =	 {Imagenet training in minutes},
  author =	 {You, Yang and Zhang, Zhao and Hsieh, Cho-Jui and
                  Demmel, James and Keutzer, Kurt},
  booktitle =	 {{Proceedings of the 47th International Conference on
                  Parallel Processing}},
  pages =	 1,
  year =	 2018,
  organization = {ACM}
}

@article{Codreanu2017,
  title =	 {Scale out for large minibatch {SGD}: Residual
                  network training on {ImageNet-1K} with improved
                  accuracy and reduced time to train},
  author =	 {Codreanu, Valeriu and Podareanu, Damian and
                  Saletore, Vikram},
  journal =	 {arXiv preprint arXiv:1711.04291},
  year =	 2017
}

@article{Akiba2017,
  title =	 {{Extremely Large Minibatch SGD: Training ResNet-50
                  on ImageNet in 15 Minutes}},
  author =	 {Akiba, Takuya and Suzuki, Shuji and Fukuda, Keisuke},
  journal =	 {arXiv preprint arXiv:1711.04325},
  year =	 2017
}

@article{Shi2017,
  title =	 {Performance Modeling and Evaluation of Distributed
                  Deep Learning Frameworks on {GPUs}},
  author =	 {Shi, Shaohuai and Chu, Xiaowen},
  journal =	 {arXiv preprint arXiv:1711.05979},
  year =	 2017
}

@inproceedings{Verma2011,
  title =	 {ARIA: automatic resource inference and allocation
                  for {MapReduce} environments},
  author =	 {Verma, Abhishek and Cherkasova, Ludmila and
                  Campbell, Roy H},
  booktitle =	 {Proceedings of the 8th ACM international conference
                  on Autonomic computing},
  pages =	 {235--244},
  year =	 2011,
  organization = {ACM}
}

@article{Zheng2005,
  title =	 {Simulation-based performance prediction for large
                  parallel machines},
  author =	 {Zheng, Gengbin and Wilmarth, Terry and
                  Jagadishprasad, Praveen and Kal{\'e}, Laxmikant V},
  journal =	 {International Journal of Parallel Programming},
  volume =	 33,
  number =	 2,
  pages =	 {183--207},
  year =	 2005,
  publisher =	 {Springer}
}

@inproceedings{Balasundaram1991,
  title =	 {A static performance estimator to guide data
                  partitioning decisions},
  author =	 {Balasundaram, Vasanth and Fox, Geoffrey and Kennedy,
                  Ken and Kremer, Ulrich},
  booktitle =	 {ACM Sigplan Notices},
  volume =	 26,
  number =	 7,
  pages =	 {213--223},
  year =	 1991,
  organization = {ACM}
}

@inproceedings{Venkataraman2016,
  title =	 {Ernest: Efficient Performance Prediction for
                  Large-Scale Advanced Analytics.},
  author =	 {Venkataraman, Shivaram and Yang, Zongheng and
                  Franklin, Michael J and Recht, Benjamin and Stoica,
                  Ion},
  booktitle =	 {NSDI},
  pages =	 {363--378},
  year =	 2016
}

@inproceedings{Yadwadkar2014,
  title =	 {Wrangler: Predictable and faster jobs using fewer
                  resources},
  author =	 {Yadwadkar, Neeraja J and Ananthanarayanan, Ganesh
                  and Katz, Randy},
  booktitle =	 {Proceedings of the ACM Symposium on Cloud Computing},
  pages =	 {1--14},
  year =	 2014,
  organization = {ACM}
}

@inproceedings{Ferguson2012,
  title =	 {Jockey: guaranteed job latency in data parallel
                  clusters},
  author =	 {Ferguson, Andrew D and Bodik, Peter and Kandula,
                  Srikanth and Boutin, Eric and Fonseca, Rodrigo},
  booktitle =	 {Proceedings of the 7th ACM european conference on
                  Computer Systems},
  pages =	 {99--112},
  year =	 2012,
  organization = {ACM}
}

@article{Buyya2002,
  title =	 {Gridsim: A toolkit for the modeling and simulation
                  of distributed resource management and scheduling
                  for grid computing},
  author =	 {Buyya, Rajkumar and Murshed, Manzur},
  journal =	 {Concurrency and computation: practice and
                  experience},
  volume =	 14,
  number =	 {13-15},
  pages =	 {1175--1220},
  year =	 2002,
  publisher =	 {Wiley Online Library}
}

@inproceedings{Kurth2017,
  author =	 {Kurth, Thorsten and Zhang, Jian and Satish, Nadathur
                  and Racah, Evan and Mitliagkas, Ioannis and Patwary,
                  Md. Mostofa Ali and Malas, Tareq and Sundaram,
                  Narayanan and Bhimji, Wahid and Smorkalov, Mikhail
                  and Deslippe, Jack and Shiryaev, Mikhail and
                  Sridharan, Srinivas and Prabhat and Dubey, Pradeep},
  title =	 {Deep Learning at 15PF: Supervised and
                  Semi-supervised Classification for Scientific Data},
  booktitle =	 {Proceedings of the International Conference for High
                  Performance Computing, Networking, Storage and
                  Analysis},
  series =	 {SC '17},
  year =	 2017,
  isbn =	 {978-1-4503-5114-0},
  location =	 {Denver, Colorado},
  pages =	 {7:1--7:11},
  articleno =	 7,
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/3126908.3126916},
  doi =		 {10.1145/3126908.3126916},
  acmid =	 3126916,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
}

@article{Katz2016,
  title =	 {Application skeletons: Construction and use in
                  eScience},
  author =	 {Katz, Daniel S and Merzky, Andre and Zhang, Zhao and
                  Jha, Shantenu},
  journal =	 {Future Generation Computer Systems},
  volume =	 59,
  pages =	 {114--124},
  year =	 2016,
  publisher =	 {Elsevier}
}

@article{Carrasquilla2017,
  title =	 {Machine learning phases of matter},
  author =	 {Carrasquilla, Juan and Melko, Roger G},
  journal =	 {Nature Physics},
  year =	 2017,
  publisher =	 {Nature Research}
}

@inproceedings{Deng2009,
  title =	 {Imagenet: A large-scale hierarchical image database},
  author =	 {Deng, Jia and Dong, Wei and Socher, Richard and Li,
                  Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle =	 {Computer Vision and Pattern Recognition, 2009. CVPR
                  2009. IEEE Conference on},
  pages =	 {248--255},
  year =	 2009,
  organization = {IEEE}
}

@article{Thakur2005,
  title =	 {Optimization of collective communication operations
                  in {MPICH}},
  author =	 {Thakur, Rajeev and Rabenseifner, Rolf and Gropp,
                  William},
  journal =	 {The International Journal of High Performance
                  Computing Applications},
  volume =	 19,
  number =	 1,
  pages =	 {49--66},
  year =	 2005,
  publisher =	 {Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{Chan2007,
  title =	 {Collective communication: theory, practice, and
                  experience},
  author =	 {Chan, Ernie and Heimlich, Marcel and Purkayastha,
                  Avi and Van De Geijn, Robert},
  journal =	 {Concurrency and Computation: Practice and
                  Experience},
  volume =	 19,
  number =	 13,
  pages =	 {1749--1783},
  year =	 2007,
  publisher =	 {Wiley Online Library}
}

@inproceedings{Zhang2017,
  author =	 {Zhang, Zhao and Sparks, Evan R. and Franklin,
                  Michael J.},
  title =	 {Diagnosing Machine Learning Pipelines with
                  Fine-grained Lineage},
  booktitle =	 {Proceedings of the 26th International Symposium on
                  High-Performance Parallel and Distributed Computing},
  series =	 {HPDC '17},
  year =	 2017,
  isbn =	 {978-1-4503-4699-3},
  location =	 {Washington, DC, USA},
  pages =	 {143--153},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/3078597.3078603},
  doi =		 {10.1145/3078597.3078603},
  acmid =	 3078603,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {diagnostics, fine-grained lineage, machine learning}
}

@inproceedings{Zhang2017-2,
  author =	 {Zhang, Zhao and Xu, Weijia and Gaffney, Niall and
                  Stanzione, Daniel},
  title =	 {Early Results of Deep Learning on the {Stampede2}
                  Supercomputer},
  booktitle =	 {The Intel Xeon Phi User's Group (IXPUG) US Annual
                  Meeting},
  doi =		 {10.13140/RG.2.2.36806.78404},
  year =	 2017
}

@article{Dongarra1992,
  title =	 {Performance of various computers using standard
                  linear equations software},
  author =	 {Dongarra, Jack J},
  journal =	 {ACM SIGARCH Computer Architecture News},
  volume =	 20,
  number =	 3,
  pages =	 {22--44},
  year =	 1992,
  publisher =	 {ACM}
}

@Misc{Lambdalabs2018,
  author =	 {{Lambda Labs}},
  title =	 "{Titan RTX TensorFlow Benchmarks}",
  note =
                  "\url{https://lambdalabs.com/blog/titan-rtx-tensorflow-benchmarks/}",
  year =	 2018
}

@article{istrate2018tapas,
  title =	 {TAPAS: Train-less Accuracy Predictor for
                  Architecture Search},
  author =	 {Istrate, Roxana and Scheidegger, Florian and
                  Mariani, Giovanni and Nikolopoulos, D and Bekas,
                  Costas and Malossi, A Cristiano I},
  journal =	 {arXiv preprint arXiv:1806.00250},
  year =	 2018
}

@inproceedings{gupta2015deep,
  title =	 {Deep learning with limited numerical precision},
  author =	 {Gupta, Suyog and Agrawal, Ankur and Gopalakrishnan,
                  Kailash and Narayanan, Pritish},
  booktitle =	 {International Conference on Machine Learning},
  pages =	 {1737--1746},
  year =	 2015
}

@article{ottman1996gene,
  title =	 {Gene--environment interaction: definitions and study
                  design},
  author =	 {Ottman, Ruth},
  journal =	 {Preventive medicine},
  volume =	 25,
  number =	 6,
  pages =	 {764--770},
  year =	 1996,
  publisher =	 {Elsevier}
}

@article{chard2018dlhub,
  title =	 {DLHub: Model and Data Serving for Science},
  author =	 {Chard, Ryan and Li, Zhuozhao and Chard, Kyle and
                  Ward, Logan and Babuji, Yadu and Woodard, Anna and
                  Tuecke, Steve and Blaiszik, Ben and Franklin,
                  Michael J and Foster, Ian},
  journal =	 {arXiv preprint arXiv:1811.11213},
  year =	 2018
}

@inproceedings{lee2001algorithms,
  title =	 {Algorithms for non-negative matrix factorization},
  author =	 {Lee, Daniel D and Seung, H Sebastian},
  booktitle =	 {Advances in neural information processing systems},
  pages =	 {556--562},
  year =	 2001
}

@inproceedings{jain2013low,
  title =	 {Low-rank matrix completion using alternating
                  minimization},
  author =	 {Jain, Prateek and Netrapalli, Praneeth and Sanghavi,
                  Sujay},
  booktitle =	 {Proceedings of the forty-fifth annual ACM symposium
                  on Theory of computing},
  pages =	 {665--674},
  year =	 2013,
  organization = {ACM}
}

@inproceedings{krizhevsky2012imagenet,
  title =	 {Imagenet classification with deep convolutional
                  neural networks},
  author =	 {Krizhevsky, Alex and Sutskever, Ilya and Hinton,
                  Geoffrey E},
  booktitle =	 {Advances in neural information processing systems},
  pages =	 {1097--1105},
  year =	 2012
}

@inproceedings{he2016deep,
  title =	 {Deep residual learning for image recognition},
  author =	 {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and
                  Sun, Jian},
  booktitle =	 {Proceedings of the IEEE conference on computer
                  vision and pattern recognition},
  pages =	 {770--778},
  year =	 2016
}

@inproceedings{huang2017densely,
  title =	 {Densely connected convolutional networks.},
  author =	 {Huang, Gao and Liu, Zhuang and Van Der Maaten,
                  Laurens and Weinberger, Kilian Q},
  booktitle =	 {CVPR},
  volume =	 1,
  number =	 2,
  pages =	 3,
  year =	 2017
}

@article{sergeev2018horovod,
  Author =	 {Alexander Sergeev and Mike Del Balso},
  Journal =	 {arXiv preprint arXiv:1802.05799},
  Title =	 {Horovod: Fast and easy distributed deep learning in
                  {TensorFlow}},
  Year =	 2018
}

@article{li2022amp,
  title =	 {AMP: Automatically Finding Model Parallel Strategies
                  with Heterogeneity Awareness},
  author =	 {Li, Dacheng and Wang, Hongyi and Xing, Eric and
                  Zhang, Hao},
  journal =	 {arXiv preprint arXiv:2210.07297},
  year =	 2022
}

@article{zheng2022alpa,
  title =	 {Alpa: Automating Inter-and Intra-Operator
                  Parallelism for Distributed Deep Learning},
  author =	 {Zheng, Lianmin and Li, Zhuohan and Zhang, Hao and
                  Zhuang, Yonghao and Chen, Zhifeng and Huang, Yanping
                  and Wang, Yida and Xu, Yuanzhong and Zhuo, Danyang
                  and Gonzalez, Joseph E and others},
  journal =	 {arXiv preprint arXiv:2201.12023},
  year =	 2022
}

@inproceedings{venkataraman2016ernest,
  title =	 {Ernest: efficient performance prediction for
                  large-scale advanced analytics},
  author =	 {Venkataraman, Shivaram and Yang, Zongheng and
                  Franklin, Michael and Recht, Benjamin and Stoica,
                  Ion},
  booktitle =	 {Proceedings of the 13th Usenix Conference on
                  Networked Systems Design and Implementation},
  pages =	 {363--378},
  year =	 2016,
  organization = {USENIX Association}
}

@inproceedings{sinha2022notall,
  title =	 {{Not All GPUs Are Created Equal: Characterizing
                  Variability in Large-Scale, Accelerator-Rich
                  Systems}},
  author =	 {Sinha, Prasoon and Guliani, Akhil and Jain, Rutwik
                  and Tran, Brandon and Sinclair, Matthew D and
                  Venkataraman, Shivaram},
  booktitle =	 {{Proceedings of the International Conference on High
                  Performance Computing, Networking, Storage and
                  Analysis}},
  pages =	 {1--15},
  year =	 2022,
  series =	 {SC},
}

@inproceedings{gonzalez2012powergraph,
  title =	 {{PowerGraph: Distributed Graph-parallel Computation on Natural Graphs}},
  author =	 {Gonzalez, J and Low, Yucheng and Gu, Haijie and
                  Bickson, Danny and Guestrin, Carlos},
  booktitle =	 {{Proceedings of the 10th USENIX Conference on Operating Systems Design and Implementation}},
  series =	 {OSDI},
  year =	 2012
}

@misc{pypi,
  author = {{Python Software Foundation}},
  title =	 {{PyPI}: Python package index},
  note =	 {\url{https://pypi.org}},
  year =	 2021,
}

@misc{sciml,
  author =	 {SciML},
  title =	 {{SciML: Scientific machine learning benchmark suite}},
  note = {\url{https://github.com/stfc-sciml/sciml-benchmarks/}}
}

@article{lin2017deep,
  title =	 {Deep gradient compression: Reducing the communication bandwidth for distributed training},
  author =	 {Lin, Yujun and Han, Song and Mao, Huizi and Wang, Yu
                  and Dally, William J},
  journal =	 {arXiv preprint arXiv:1712.01887},
  year =	 2017
}

@article{ginsburg2018large,
  title =	 {{Large Batch Training of Convolutional Networks with Layer-wise Adaptive Rate Scaling}},
  author =	 {Ginsburg, Boris and Gitman, Igor and You, Yang},
  year =	 2018
}

@article{smith2017don,
  title =	 {Don't decay the learning rate, increase the batch size},
  author =	 {Smith, Samuel L and Kindermans, Pieter-Jan and Ying,
                  Chris and Le, Quoc V},
  journal =	 {arXiv preprint arXiv:1711.00489},
  year =	 2017
}

@article{krizhevsky2014one,
  title =	 {One weird trick for parallelizing convolutional
                  neural networks},
  author =	 {Krizhevsky, Alex},
  journal =	 {arXiv preprint arXiv:1404.5997},
  year =	 2014
}

@article{bottou2018optimization,
  title =	 {Optimization methods for large-scale machine
                  learning},
  author =	 {Bottou, L{\'e}on and Curtis, Frank E and Nocedal,
                  Jorge},
  journal =	 {SIAM Review},
  volume =	 60,
  number =	 2,
  pages =	 {223--311},
  year =	 2018,
  publisher =	 {SIAM}
}

@article{goyal2017accurate,
  title =	 {Accurate, large minibatch SGD: training imagenet in
                  1 hour},
  author =	 {Goyal, Priya and Doll{\'a}r, Piotr and Girshick,
                  Ross and Noordhuis, Pieter and Wesolowski, Lukasz
                  and Kyrola, Aapo and Tulloch, Andrew and Jia,
                  Yangqing and He, Kaiming},
  journal =	 {arXiv preprint arXiv:1706.02677},
  year =	 2017
}

@article{zhang2018fanstore,
  title =	 {{FanStore}: Enabling Efficient and Scalable I/O for
                  Distributed Deep Learning},
  author =	 {Zhang, Zhao and Huang, Lei and Manor, Uri and Fang,
                  Linjing and Merlo, Gabriele and Michoski, Craig and
                  Cazes, John and Gaffney, Niall},
  journal =	 {arXiv preprint arXiv:1809.10799},
  year =	 2018
}

@misc{Deep500,
  title =	 {{Deep500}},
  note =	 {\url{https://www.deep500.org/}}
}

@misc{ONNX,
  title =	 {{ONNX}},
  note =	 {\url{https://onnx.ai/}}
}

@inproceedings{Kannan2016HPA,
  author =	 {Kannan, Ramakrishnan and Ballard, Grey and Park,
                  Haesun},
  title =	 {{A High-performance Parallel Algorithm for Nonnegative Matrix Factorization}},
  booktitle =	 {{Proceedings of the 21st ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming}},
  series =	 {PPoPP},
  year =	 2016,
  isbn =	 {978-1-4503-4092-2},
  location =	 {Barcelona, Spain},
  pages =	 {9:1--9:11},
  articleno =	 9,
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/2851141.2851152},
  doi =		 {10.1145/2851141.2851152},
  acmid =	 2851152,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
}

@inproceedings{zhang2013mtc,
  title =	 {MTC Envelope: Defining the capability of large scale computers in the context of parallel scripting applications},
  author =	 {Zhang, Zhao and Katz, Daniel S and Wilde, Michael and Wozniak, Justin M and Foster, Ian},
  booktitle =	 {Proceedings of the 22nd international symposium on High-performance parallel and distributed computing},
  pages =	 {37--48},
  year =	 2013,
  organization = {ACM}
}

@inproceedings{you2019large,
  author =	 {You, Yang and Hseu, Jonathan and Ying, Chris and Demmel, James and Keutzer, Kurt and Hsieh, Cho-Jui},
  title =	 {{Large-Batch Training for LSTM and Beyond}},
  year =	 2019,
  isbn =	 9781450362290,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/3295500.3356137},
  doi =		 {10.1145/3295500.3356137},
  booktitle =	 {Proceedings of the International Conference for High
                  Performance Computing, Networking, Storage and
                  Analysis},
  articleno =	 {Article 9},
  numpages =	 16,
  keywords =	 {neural networks, distributed computing, large-batch
                  training},
  location =	 {Denver, Colorado},
  series =	 {SC ’19}
}

@incollection{NEURIPS2019_9015,
  title =	 {{PyTorch: An Imperative Style, High-Performance Deep Learning Library}},
  author =	 {Paszke, Adam and Gross, Sam and Massa, Francisco and
                  Lerer, Adam and Bradbury, James and Chanan, Gregory
                  and Killeen, Trevor and Lin, Zeming and Gimelshein,
                  Natalia and Antiga, Luca and Desmaison, Alban and
                  Kopf, Andreas and Yang, Edward and DeVito, Zachary
                  and Raison, Martin and Tejani, Alykhan and
                  Chilamkurthy, Sasank and Steiner, Benoit and Fang,
                  Lu and Bai, Junjie and Chintala, Soumith},
  booktitle =	 {{Advances in Neural Information Processing Systems 32}},
  pages =	 {8024--8035},
  year =	 2019,
  publisher =	 {Curran Associates, Inc.},
  url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@inproceedings{martens2015optimizing,
  title =	 {Optimizing neural networks with kronecker-factored approximate curvature},
  author =	 {Martens, James and Grosse, Roger},
  booktitle =	 {International conference on machine learning},
  pages =	 {2408--2417},
  year =	 2015
}

@InProceedings{Osawa_2019_CVPR,
  author =	 {Osawa, Kazuki and Tsuji, Yohei and Ueno, Yuichiro and Naruse, Akira and Yokota, Rio and Matsuoka, Satoshi},
  title =	 {{Large-Scale Distributed Second-Order Optimization Using Kronecker-Factored Approximate Curvature for Deep Convolutional Neural Networks}},
  booktitle =	 {{IEEE Conference on Computer Vision and Pattern Recognition}},
  series = {CVPR},
  month =	 {June},
  year =	 2019
}

@misc{ma2019inefficiency,
  title =	 {Inefficiency of K-FAC for Large Batch Size Training},
  author =	 {Linjian Ma and Gabe Montague and Jiayu Ye and Zhewei Yao and Amir Gholami and Kurt Keutzer and Michael W. Mahoney},
  year =	 2019,
  eprint =	 {1903.06237},
  howpublished ={arXiv},
  primaryClass = {cs.LG}
}

@inproceedings{zhang2020compress,
  title =	 {{Efficient I/O for Neural Network Training with Compressed Data}},
  author =	 {Zhang, Zhao and Huang, Lei and Pauloski, J. Gregory and Foster, Ian T.},
  booktitle =	 {{34th International Symposium on Parallel and Distributed Processing}},
  year =	 2020,
  organization = {IEEE}
}

@inproceedings{recht2011hogwild,
  title =	 {Hogwild: A lock-free approach to parallelizing
                  stochastic gradient descent},
  author =	 {Recht, Benjamin and Re, Christopher and Wright,
                  Stephen and Niu, Feng},
  booktitle =	 {Advances in neural information processing systems},
  pages =	 {693--701},
  year =	 2011
}

@inproceedings{martens2018kronecker,
  title =	 {Kronecker-factored curvature approximations for
                  recurrent neural networks},
  author =	 {Martens, James and Ba, Jimmy and Johnson, Matt},
  booktitle =	 {International Conference on Learning
                  Representations},
  year =	 2018
}

@article{gossiping-jin2016scale,
  title =	 {How to scale distributed deep learning?},
  author =	 {Jin, Peter H and Yuan, Qiaochu and Iandola, Forrest
                  and Keutzer, Kurt},
  journal =	 {arXiv preprint arXiv:1611.04581},
  year =	 2016
}

@inproceedings{zhang2015deep,
  title =	 {Deep learning with elastic averaging SGD},
  author =	 {Zhang, Sixin and Choromanska, Anna E and LeCun,
                  Yann},
  booktitle =	 {Advances in Neural Information Processing Systems},
  pages =	 {685--693},
  year =	 2015
}

@inproceedings{momentum-mitliagkas2016asynchrony,
  title =	 {Asynchrony begets momentum, with an application to
                  deep learning},
  author =	 {Mitliagkas, Ioannis and Zhang, Ce and Hadjis, Stefan
                  and R{\'e}, Christopher},
  booktitle =	 {Communication, Control, and Computing (Allerton),
                  2016 54th Annual Allerton Conference on},
  pages =	 {997--1004},
  year =	 2016,
  organization = {IEEE}
}

@inproceedings{li2014scaling,
  title =	 {Scaling distributed machine learning with the
                  parameter server},
  author =	 {Li, Mu and Andersen, David G and Park, Jun Woo and
                  Smola, Alexander J and Ahmed, Amr and Josifovski,
                  Vanja and Long, James and Shekita, Eugene J and Su,
                  Bor-Yiing},
  booktitle =	 {11th $\{$USENIX$\}$ Symposium on Operating Systems
                  Design and Implementation ($\{$OSDI$\}$ 14)},
  pages =	 {583--598},
  year =	 2014
}

@inproceedings{alistarh2018convergence,
  title =	 {The convergence of stochastic gradient descent in
                  asynchronous shared memory},
  author =	 {Alistarh, Dan and De Sa, Christopher and
                  Konstantinov, Nikola},
  booktitle =	 {Proceedings of the 2018 ACM Symposium on Principles
                  of Distributed Computing},
  pages =	 {169--178},
  year =	 2018,
  organization = {ACM}
}

@article{mikami2018massively,
  title =	 {Massively Distributed SGD: ImageNet/ResNet-50
                  Training in a Flash},
  author =	 {Mikami, Hiroaki and Suganuma, Hisahiro and Tanaka,
                  Yoshiki and Kageyama, Yuichi and others},
  journal =	 {arXiv preprint arXiv:1811.05233},
  year =	 2018
}

@article{ying2018image,
  title =	 {Image classification at supercomputer scale},
  author =	 {Ying, Chris and Kumar, Sameer and Chen, Dehao and
                  Wang, Tao and Cheng, Youlong},
  journal =	 {arXiv preprint arXiv:1811.06992},
  year =	 2018
}

@article {Fang740548,
  author =	 {Fang, Linjing and Monroe, Fred and Novak, Sammy
                  Weiser and Kirk, Lyndsey and Schiavon, Cara R. and
                  Yu, Seungyoon B. and Zhang, Tong and Wu, Melissa and
                  Kastner, Kyle and Kubota, Yoshiyuki and Zhang, Zhao
                  and Pekkurnaz, Gulcin and Mendenhall, John and
                  Harris, Kristen and Howard, Jeremy and Manor, Uri},
  title =	 {Deep Learning-Based Point-Scanning Super-Resolution
                  Imaging},
  elocation-id = 740548,
  year =	 2019,
  doi =		 {10.1101/740548},
  publisher =	 {Cold Spring Harbor Laboratory},
  URL =
                  {https://www.biorxiv.org/content/early/2019/10/24/740548},
  eprint =
                  {https://www.biorxiv.org/content/early/2019/10/24/740548.full.pdf},
  journal =	 {bioRxiv}
}

@article{kanitpanyacharoen2013comparative,
  title =	 {A comparative study of X-ray tomographic microscopy
                  on shales at different synchrotron facilities: ALS,
                  APS and SLS},
  author =	 {Kanitpanyacharoen, Waruntorn and Parkinson, Dilworth
                  Y and De Carlo, Francesco and Marone, Federica and
                  Stampanoni, Marco and Mokso, Rajmund and MacDowell,
                  Alastair and Wenk, H-R},
  journal =	 {Journal of synchrotron radiation},
  volume =	 20,
  number =	 1,
  pages =	 {172--180},
  year =	 2013,
  publisher =	 {International Union of Crystallography}
}

@techreport{singh2017varied,
  title =	 {Varied volume fractions of borosilicate glass
                  spheres with diameter gaussian distributed from
                  38-45 micronsen cased in a polypropylene matrix},
  author =	 {Singh, Somya and Stannard, Tyler J and Singh,
                  Sudhanshu S and Singaravelu, Arun SS and Xiao,
                  Xianghui and Chawla, Nikhilesh},
  year =	 2017,
  institution =	 {Argonne National Lab.(ANL), Argonne, IL (United
                  States)}
}

@misc{T8/YLCK5A_2019,
  author =	 {Fang, Linjing and Monroe, Fred and Novak, Sammy and
                  Kirk, Lyndsey and Schiavon, Cara and Seungyoon, Yu
                  and Zhang, Tong and Wu, Melissa and Kastner, Kyle
                  and Kubota, Yoshiyuki and Zhang, Zhao and Pekkurnaz,
                  Gulcin and Mendenhall, John and Harris, Kristen and
                  Howard, Jeremy and Manor, Uri},
  publisher =	 {Texas Data Repository Dataverse},
  title =	 "{Training, Testing, and Validation Data for ``Deep
                  Learning-Based Point-Scanning Super-Resolution
                  Imaging''}",
  year =	 2019,
  version =	 {V1},
  doi =		 {10.18738/T8/YLCK5A},
  url =		 {https://doi.org/10.18738/T8/YLCK5A}
}

@INPROCEEDINGS{dong2019scaling,
  author =	 {W. {Dong} and M. {Keceli} and R. {Vescovi} and
                  H. {Li} and C. {Adams} and E. {Jennings} and
                  S. {Flender} and T. {Uram} and V. {Vishwanath} and
                  N. {Ferrier} and N. {Kasthuri} and P. {Littlewood}},
  booktitle =	 {2019 IEEE/ACM Third Workshop on Deep Learning on
                  Supercomputers (DLS)},
  title =	 {Scaling Distributed Training of Flood-Filling
                  Networks on HPC Infrastructure for Brain Mapping},
  year =	 2019,
  pages =	 {52-61},
  doi =		 {10.1109/DLS49591.2019.00012},
  ISSN =	 {null},
  month =	 {Nov},
}

@article{takemura2015synaptic,
  title =	 {Synaptic circuits and their variations within
                  different columns in the visual system of
                  Drosophila},
  author =	 {Takemura, Shin-ya and Xu, C Shan and Lu, Zhiyuan and
                  Rivlin, Patricia K and Parag, Toufiq and Olbris,
                  Donald J and Plaza, Stephen and Zhao, Ting and Katz,
                  William T and Umayam, Lowell and others},
  journal =	 {Proceedings of the National Academy of Sciences},
  volume =	 112,
  number =	 44,
  pages =	 {13711--13716},
  year =	 2015,
  publisher =	 {National Acad Sciences}
}

@inproceedings{lee2019deepdrivemd,
  title =	 {DeepDriveMD: Deep-Learning Driven Adaptive Molecular
                  Simulations for Protein Folding},
  author =	 {Lee, Hyungro and Turilli, Matteo and Jha, Shantenu
                  and Bhowmik, Debsindhu and Ma, Heng and Ramanathan,
                  Arvind},
  booktitle =	 {2019 IEEE/ACM Third Workshop on Deep Learning on
                  Supercomputers (DLS)},
  pages =	 {12--19},
  year =	 2019,
  organization = {IEEE}
}

@inproceedings{he2017mask,
  title =	 {Mask {R-CNN}},
  author =	 {He, Kaiming and Gkioxari, Georgia and Doll{\'a}r,
                  Piotr and Girshick, Ross},
  booktitle =	 {IEEE International Conference on Computer Vision},
  pages =	 {2961--2969},
  year =	 2017
}

@article{hannun2014deep,
  title =	 {Deep speech: Scaling up end-to-end speech
                  recognition},
  author =	 {Hannun, Awni and Case, Carl and Casper, Jared and
                  Catanzaro, Bryan and Diamos, Greg and Elsen, Erich
                  and Prenger, Ryan and Satheesh, Sanjeev and
                  Sengupta, Shubho and Coates, Adam and others},
  journal =	 {arXiv preprint arXiv:1412.5567},
  year =	 2014
}

@inproceedings{devlin2018bert,
  author =	 {Jacob Devlin and Ming{-}Wei Chang and Kenton Lee and
                  Kristina Toutanova},
  title =	 {{BERT: Pre-training of Deep Bidirectional
                  Transformers for Language Understanding}},
  booktitle =	 {{Proceedings of the 2019 Conference of the North
                  American Chapter of the Association for
                  Computational Linguistics: Human Language
                  Technologies}},
  series =	 {NAACL-HLT},
  pages =	 {4171--4186},
  publisher =	 {Association for Computational Linguistics},
  year =	 2019,
  url =		 {https://doi.org/10.18653/v1/n19-1423},
  doi =		 {10.18653/v1/n19-1423},
  timestamp =	 {Fri, 06 Aug 2021 00:41:31 +0200},
  biburl =	 {https://dblp.org/rec/conf/naacl/DevlinCLT19.bib},
  bibsource =	 {dblp computer science bibliography,
                  https://dblp.org},
}

@inproceedings{lin2014microsoft,
  title =	 {Microsoft coco: Common objects in context},
  author =	 {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge
                  and Hays, James and Perona, Pietro and Ramanan, Deva
                  and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle =	 {European conference on computer vision},
  pages =	 {740--755},
  year =	 2014,
  organization = {Springer}
}

@inproceedings{cieri2004fisher,
  title =	 {The Fisher Corpus: a Resource for the Next
                  Generations of Speech-to-Text.},
  author =	 {Cieri, Christopher and Miller, David and Walker,
                  Kevin},
  booktitle =	 {LREC},
  volume =	 4,
  pages =	 {69--71},
  year =	 2004
}

@inproceedings{panayotov2015librispeech,
  title =	 {Librispeech: an ASR corpus based on public domain
                  audio books},
  author =	 {Panayotov, Vassil and Chen, Guoguo and Povey, Daniel
                  and Khudanpur, Sanjeev},
  booktitle =	 {2015 IEEE International Conference on Acoustics,
                  Speech and Signal Processing (ICASSP)},
  pages =	 {5206--5210},
  year =	 2015,
  organization = {IEEE}
}

@inproceedings{zhu2015aligning,
  title =	 {Aligning books and movies: Towards story-like visual
                  explanations by watching movies and reading books},
  author =	 {Zhu, Yukun and Kiros, Ryan and Zemel, Rich and
                  Salakhutdinov, Ruslan and Urtasun, Raquel and
                  Torralba, Antonio and Fidler, Sanja},
  booktitle =	 {Proceedings of the IEEE international conference on
                  computer vision},
  pages =	 {19--27},
  year =	 2015
}

@Misc{wiki,
  author =	 {{Wikipedia}},
  title =	 "{{Wikipedia Corpus}}",
  note =	 "\url{https://www.english-corpora.org/wiki/}",
}

@Misc{mlperf0.6,
  author =	 {{MLPerf}},
  title =	 "{{MLPerf Results v0.6}}",
  note =	 "\url{https://mlperf.org/training-results-0-6}",
}

@article{you2019reducing,
  title =	 {Reducing BERT Pre-Training Time from 3 Days to 76
                  Minutes},
  author =	 {You, Yang and Li, Jing and Hseu, Jonathan and Song,
                  Xiaodan and Demmel, James and Hsieh, Cho-Jui},
  journal =	 {arXiv preprint arXiv:1904.00962},
  year =	 2019
}

@Misc{tfkfac,
  author =	 {{TensorFlow}},
  title =	 "{{TensorFlow K-FAC}}",
  note =	 "\url{https://github.com/tensorflow/kfac}",
}

@article{mccandlish2018empirical,
  title =	 {An empirical model of large-batch training},
  author =	 {McCandlish, Sam and Kaplan, Jared and Amodei, Dario
                  and Team, OpenAI Dota},
  journal =	 {arXiv preprint arXiv:1812.06162},
  year =	 2018
}

@inproceedings{parkhi2015deep,
  title =	 {Deep face recognition.},
  author =	 {Parkhi, Omkar M and Vedaldi, Andrea and Zisserman,
                  Andrew and others},
  booktitle =	 {bmvc},
  volume =	 1,
  number =	 3,
  pages =	 6,
  year =	 2015
}

@inproceedings{babuji2019parsl,
  title =	 {Parsl: Pervasive parallel programming in python},
  author =	 {Babuji, Yadu and Woodard, Anna and Li, Zhuozhao and
                  Katz, Daniel S and Clifford, Ben and Kumar, Rohan
                  and Lacinski, Lukasz and Chard, Ryan and Wozniak,
                  Justin M and Foster, Ian and others},
  booktitle =	 {Proceedings of the 28th International Symposium on
                  High-Performance Parallel and Distributed Computing},
  pages =	 {25--36},
  year =	 2019,
  organization = {ACM}
}

@inproceedings{kurihana2019cloud,
  title =	 {Cloud Characterization With Deep Learning {II}},
  author =	 {Kurihana, Takuya and Foster, Ian and Moyer,
                  Elisabeth J and Willett, Rebecca and Maire, Michael
                  and Jenkins, Sydney and Koenig, Kathryn and Werman,
                  Ruby},
  booktitle =	 {AGU Fall Meeting 2019},
  year =	 2019,
  organization = {AGU}
}

@inproceedings{abeykoon2019scientific,
  title =	 {Scientific image restoration anywhere},
  author =	 {Abeykoon, Vibhatha and Liu, Zhengchun and
                  Kettimuthu, Rajkumar and Fox, Geoffrey and Foster,
                  Ian},
  booktitle =	 {2019 IEEE/ACM 1st Annual Workshop on Large-scale
                  Experiment-in-the-Loop Computing (XLOOP)},
  pages =	 {8--13},
  year =	 2019,
  organization = {IEEE}
}

@inproceedings{liu2019deep,
  title =	 {Deep learning accelerated light source experiments},
  author =	 {Liu, Zhengchun and Bicer, Tekin and Kettimuthu,
                  Rajkumar and Foster, Ian},
  booktitle =	 {IEEE/ACM Third Workshop on Deep Learning on
                  Supercomputers},
  pages =	 {20--28},
  year =	 2019,
  organization = {IEEE}
}

@inproceedings{montella2019stormseeker,
  title =	 {Storm{S}eeker: A Machine-Learning-Based
                  {M}editerranean Storm Tracer},
  author =	 {Montella, Raffaele and Di Luccio, Diana and
                  Ciaramella, Angelo and Foster, Ian},
  booktitle =	 {International Conference on Internet and Distributed
                  Computing Systems},
  pages =	 {444--456},
  year =	 2019,
  organization = {Springer}
}

@inproceedings{jha2019irnet,
  title =	 {{IRNet}: A general purpose deep residual regression
                  framework for materials discovery},
  author =	 {Jha, Dipendra and Ward, Logan and Yang, Zijiang and
                  Wolverton, Christopher and Foster, Ian and Liao,
                  Wei-keng and Choudhary, Alok and Agrawal, Ankit},
  booktitle =	 {25th ACM SIGKDD International Conference on
                  Knowledge Discovery \& Data Mining},
  pages =	 {2385--2393},
  year =	 2019
}

@article{liu2019tomogan,
  title =	 {{TomoGAN}: Low-Dose X-Ray Tomography with Generative
                  Adversarial Networks},
  author =	 {Liu, Zhengchun and Bicer, Tekin and Kettimuthu,
                  Rajkumar and Gursoy, Doga and De Carlo, Francesco
                  and Foster, Ian},
  journal =	 {arXiv preprint arXiv:1902.07582},
  year =	 2019
}

@article{wozniak2018scaling,
  title =	 {Scaling deep learning for cancer with advanced
                  workflow storage integration},
  author =	 {Wozniak, Justin M and Davis, Philip E and Shu, Tong
                  and Ozik, Jonathan and Collier, Nicholson and
                  Parashar, Manish and Foster, Ian and Brettin, Thomas
                  and Stevens, Rick},
  journal =	 {Proc. Machine Learning in High Performance Computing
                  Environments (MLHPC) at SC},
  year =	 2018
}

@article{ward2019machine,
  title =	 {Machine Learning Prediction of Accurate Atomization
                  Energies of Organic Molecules from Low-Fidelity
                  Quantum Chemical Calculations},
  author =	 {Ward, Logan and Blaiszik, Ben and Foster, Ian and
                  Assary, Rajeev S and Narayanan, Badri and Curtiss,
                  Larry},
  journal =	 {arXiv preprint arXiv:1906.03233},
  year =	 2019
}

@article{chan2019machine,
  title =	 {Machine Learning Classical Interatomic Potentials
                  for Molecular Dynamics from First-Principles
                  Training Data},
  author =	 {Chan, Henry and Narayanan, Badri and Cherukara,
                  Mathew J and Sen, Fatih G and Sasikumar, Kiran and
                  Gray, Stephen K and Chan, Maria KY and
                  Sankaranarayanan, Subramanian KRS},
  journal =	 {The Journal of Physical Chemistry C},
  volume =	 123,
  number =	 12,
  pages =	 {6941--6957},
  year =	 2019,
  publisher =	 {ACS Publications}
}

@article{jackson2019electronic,
  title =	 {Electronic structure at coarse-grained resolutions
                  from supervised machine learning},
  author =	 {Jackson, Nicholas E and Bowen, Alec S and Antony,
                  Lucas W and Webb, Michael A and Vishwanath,
                  Venkatram and de Pablo, Juan J},
  journal =	 {Science advances},
  volume =	 5,
  number =	 3,
  pages =	 {eaav1190},
  year =	 2019,
  publisher =	 {American Association for the Advancement of Science}
}

@inproceedings{bergstra2011algorithms,
  title =	 {Algorithms for hyper-parameter optimization},
  author =	 {Bergstra, James S and Bardenet, R{\'e}mi and Bengio,
                  Yoshua and K{\'e}gl, Bal{\'a}zs},
  booktitle =	 {Advances in neural information processing systems},
  pages =	 {2546--2554},
  year =	 2011
}

@inproceedings{balaprakash2018deephyper,
  title =	 {{DeepHyper}: Asynchronous hyperparameter search for
                  deep neural networks},
  author =	 {Balaprakash, Prasanna and Salim, Michael and Uram,
                  Thomas and Vishwanath, Venkat and Wild, Stefan},
  booktitle =	 {IEEE 25th International Conference on High
                  Performance Computing},
  pages =	 {42--51},
  year =	 2018,
  organization = {IEEE}
}

@inproceedings{ICAC2014,
  title =	 {$\{$PCP$\}$: A Generalized Approach to Optimizing
                  Performance Under Power Constraints through Resource
                  Management},
  author =	 {Hoffmann, Henry and Maggio, Martina},
  booktitle =	 {11th International Conference on Autonomic Computing
                  ($\{$ICAC$\}$ 14)},
  pages =	 {241--247},
  year =	 2014
}

@article{ASPLOS2016,
  title =	 {Maximizing performance under a power cap: A
                  comparison of hardware, software, and hybrid
                  techniques},
  author =	 {Zhang, Huazhe and Hoffmann, Henry},
  journal =	 {ACM SIGPLAN Notices},
  volume =	 51,
  number =	 4,
  pages =	 {545--559},
  year =	 2016,
  publisher =	 {ACM New York, NY, USA}
}

@inproceedings{ICPP2018,
  title =	 {Performance \& energy tradeoffs for dependent
                  distributed applications under system-wide power
                  caps},
  author =	 {Zhang, Huazhe and Hoffmann, Henry},
  booktitle =	 {Proceedings of the 47th International Conference on
                  Parallel Processing},
  pages =	 {1--11},
  year =	 2018
}

@inproceedings{SC2019,
  title =	 {PoDD: power-capping dependent distributed
                  applications},
  author =	 {Zhang, Huazhe and Hoffmann, Henry},
  booktitle =	 {Proceedings of the International Conference for High
                  Performance Computing, Networking, Storage and
                  Analysis},
  pages =	 {1--23},
  year =	 2019
}

@inproceedings{IPDPS2020,
  title =	 {SeeSAw: Optimizing Performance of In-Situ Analytics
                  Applications under Power Constraints},
  author =	 {Marincic, Ivana and Vishwanath, Venkatram and
                  Hoffmann, Henry},
  booktitle =	 {to appear in 2020 IEEE 34th International Symposium
                  on Parallel and Distributed Processing},
  organization = {IEEE}
}

@inproceedings{STACS2018,
  title =	 {Approximation Algorithms for Scheduling with
                  Resource and Precedence Constraints},
  author =	 {Demirci, G{\"o}kalp and Hoffmann, Henry and Kim,
                  David HK},
  booktitle =	 {35th Symposium on Theoretical Aspects of Computer
                  Science (STACS 2018)},
  year =	 2018,
  organization = {Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik}
}

@inproceedings{SC2018,
  title =	 {A divide and conquer algorithm for DAG scheduling
                  under power constraints},
  author =	 {Demirci, G{\"o}kalp and Marincic, Ivana and
                  Hoffmann, Henry},
  booktitle =	 {SC18: International Conference for High Performance
                  Computing, Networking, Storage and Analysis},
  pages =	 {466--477},
  year =	 2018,
  organization = {IEEE}
}

@inproceedings{racingpacing.cpsna15,
  title =	 {Racing and pacing to idle: Theoretical and empirical
                  analysis of energy optimization heuristics},
  author =	 {Kim, David HK and Imes, Connor and Hoffmann, Henry},
  booktitle =	 {2015 IEEE 3rd international conference on
                  cyber-physical systems, networks, and applications},
  pages =	 {78--85},
  year =	 2015,
  organization = {IEEE}
}

@inproceedings{poet.rtas15,
  title =	 {{POET}: A portable approach to minimizing energy
                  under soft real-time constraints},
  author =	 {Imes, Connor and Kim, David HK and Maggio, Martina
                  and Hoffmann, Henry},
  booktitle =	 {21st IEEE Real-Time and Embedded Technology and
                  Applications Symposium},
  pages =	 {75--86},
  year =	 2015,
  organization = {IEEE}
}

@inproceedings{automulti.fse15,
  title =	 {Automated multi-objective control for self-adaptive
                  software design},
  author =	 {Filieri, Antonio and Hoffmann, Henry and Maggio,
                  Martina},
  booktitle =	 {10th Joint Meeting on Foundations of Software
                  Engineering},
  pages =	 {13--24},
  year =	 2015
}

@inproceedings{jouleguard.sosp15,
  title =	 {JouleGuard: energy guarantees for approximate
                  applications},
  author =	 {Hoffmann, Henry},
  booktitle =	 {25th Symposium on Operating Systems Principles},
  pages =	 {198--214},
  year =	 2015
}

@inproceedings{multiphaseopt.isca19,
  title =	 {Generative and multi-phase learning for computer
                  systems optimization},
  author =	 {Ding, Yi and Mishra, Nikita and Hoffmann, Henry},
  booktitle =	 {46th International Symposium on Computer
                  Architecture},
  pages =	 {39--52},
  year =	 2019
}

@inproceedings{multiplegoals.fse17,
  title =	 {Automated control of multiple software goals using
                  multiple actuators},
  author =	 {Maggio, Martina and Papadopoulos, Alessandro
                  Vittorio and Filieri, Antonio and Hoffmann, Henry},
  booktitle =	 {11th Joint Meeting on Foundations of Software
                  Engineering},
  pages =	 {373--384},
  year =	 2017
}

@article{rajpurkar2016squad,
  title =	 {Squad: 100,000+ questions for machine comprehension
                  of text},
  author =	 {Rajpurkar, Pranav and Zhang, Jian and Lopyrev,
                  Konstantin and Liang, Percy},
  journal =	 {arXiv preprint arXiv:1606.05250},
  year =	 2016
}

@article{pauloski2020convolutional,
  title =	 {Convolutional Neural Network Training with
                  Distributed {K-FAC}},
  author =	 {Pauloski, J Gregory and Zhang, Zhao and Huang, Lei
                  and Xu, Weijia and Foster, Ian T},
  journal =	 {International Conference for High Performance
                  Computing, Networking, Storage and Analysis},
  year =	 2020
}

@article{kates2019predicting,
  title =	 {Predicting disruptive instabilities in controlled
                  fusion plasmas through deep learning},
  author =	 {Kates-Harbeck, Julian and Svyatkovskiy, Alexey and
                  Tang, William},
  journal =	 {Nature},
  volume =	 568,
  number =	 7753,
  pages =	 {526--531},
  year =	 2019,
  publisher =	 {Nature Publishing Group}
}

@inproceedings{stanzione2020frontera,
  title =	 {Frontera: The Evolution of Leadership Computing at
                  the {National Science Foundation}},
  author =	 {Stanzione, Dan and West, John and Evans, R Todd and
                  Minyard, Tommy and Ghattas, Omar and Panda,
                  Dhabaleswar K},
  booktitle =	 {Practice and Experience in Advanced Research
                  Computing},
  pages =	 {106--111},
  year =	 2020
}

@article{vogel2016superfast,
  title =	 {Superfast divide-and-conquer method and perturbation
                  analysis for structured eigenvalue solutions},
  author =	 {Vogel, James and Xia, Jianlin and Cauley, Stephen
                  and Balakrishnan, Venkataramanan},
  journal =	 {SIAM Journal on Scientific Computing},
  volume =	 38,
  number =	 3,
  pages =	 {A1358--A1382},
  year =	 2016,
  publisher =	 {SIAM}
}

@inproceedings{dean20201,
  title =	 {The Deep Learning Revolution and Its Implications
                  for Computer Architecture and Chip Design},
  author =	 {Dean, Jeffrey},
  booktitle =	 {IEEE International Solid-State Circuits Conference},
  pages =	 {8--14},
  year =	 2020,
  organization = {IEEE}
}

@inproceedings{ronneberger2015u,
  title =	 {U-net: Convolutional networks for biomedical image
                  segmentation},
  author =	 {Ronneberger, Olaf and Fischer, Philipp and Brox,
                  Thomas},
  booktitle =	 {International Conference on Medical image computing
                  and computer-assisted intervention},
  pages =	 {234--241},
  year =	 2015,
  organization = {Springer}
}

@inproceedings{moritz2018ray,
  title =	 {Ray: A distributed framework for emerging $\{$AI$\}$
                  applications},
  author =	 {Moritz, Philipp and Nishihara, Robert and Wang,
                  Stephanie and Tumanov, Alexey and Liaw, Richard and
                  Liang, Eric and Elibol, Melih and Yang, Zongheng and
                  Paul, William and Jordan, Michael I and others},
  booktitle =	 {13th $\{$USENIX$\}$ Symposium on Operating Systems
                  Design and Implementation ($\{$OSDI$\}$ 18)},
  pages =	 {561--577},
  year =	 2018
}

@inproceedings{jia2020pushing,
  title =	 {Pushing the limit of molecular dynamics with ab
                  initio accuracy to 100 million atoms with machine
                  learning},
  author =	 {Jia, Weile and Wang, Han and Chen, Mohan and Lu,
                  Denghui and Lin, Lin and Car, Roberto and Weinan, E
                  and Zhang, Linfeng},
  booktitle =	 {SC20: International Conference for High Performance
                  Computing, Networking, Storage and Analysis},
  pages =	 {1--14},
  year =	 2020,
  organization = {IEEE}
}

@article{senior2020improved,
  title =	 {Improved protein structure prediction using
                  potentials from deep learning},
  author =	 {Senior, Andrew W and Evans, Richard and Jumper, John
                  and Kirkpatrick, James and Sifre, Laurent and Green,
                  Tim and Qin, Chongli and {\v{Z}}{\'\i}dek, Augustin
                  and Nelson, Alexander WR and Bridgland, Alex and
                  others},
  journal =	 {Nature},
  volume =	 577,
  number =	 7792,
  pages =	 {706--710},
  year =	 2020,
  publisher =	 {Nature Publishing Group}
}

@article{casalino2021ai,
  title =	 {AI-driven multiscale simulations illuminate
                  mechanisms of SARS-CoV-2 spike dynamics},
  author =	 {Casalino, Lorenzo and Dommer, Abigail C and Gaieb,
                  Zied and Barros, Emilia P and Sztain, Terra and Ahn,
                  Surl-Hee and Trifan, Anda and Brace, Alexander and
                  Bogetti, Anthony T and Clyde, Austin and others},
  journal =	 {{The International Journal of High Performance
                  Computing Applications}},
  pages =	 10943420211006452,
  publisher =	 {SAGE Publications Sage UK: London, England},
  year =	 2021,
}

@article{fan2021predicting,
  title =	 {Predicting orientation-dependent plastic
                  susceptibility from static structure in amorphous
                  solids via deep learning},
  author =	 {Fan, Zhao and Ma, Evan},
  journal =	 {Nature communications},
  volume =	 12,
  number =	 1,
  pages =	 {1--13},
  year =	 2021,
  publisher =	 {Nature Publishing Group}
}

@article{jumper2021highly,
  title =	 {Highly accurate protein structure prediction with
                  AlphaFold},
  author =	 {Jumper, John and Evans, Richard and Pritzel,
                  Alexander and Green, Tim and Figurnov, Michael and
                  Ronneberger, Olaf and Tunyasuvunakool, Kathryn and
                  Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and
                  Potapenko, Anna and others},
  journal =	 {Nature},
  volume =	 596,
  number =	 7873,
  pages =	 {583--589},
  year =	 2021,
  publisher =	 {Nature Publishing Group}
}

@Misc{top500,
  author =	 {{top500.org}},
  title =	 "{{TOP500 List}}",
  note =
                  "\url{https://www.top500.org/lists/top500/list/2021/11/}",
  year =	 2021,
}

@Misc{tesla,
  author =	 {{Tesla}},
  title =	 "{{Ahead of ‘Dojo,’ Tesla Reveals Its Massive
                  Precursor Supercomputer}}",
  note =
                  "\url{https://www.hpcwire.com/2021/06/22/ahead-of-dojo-tesla-reveals-its-massive-precursor-supercomputer/}",
  year =	 2021,
}

@ARTICLE{TalpesSarma2023-teslaDojo,
  author =	 {Talpes, Emil and Sarma, Debjit Das and Williams,
                  Doug and Arora, Sahil and Kunjan, Thomas and
                  Floering, Benjamin and Jalote, Ankit and Hsiong,
                  Christopher and Poorna, Chandrasekhar and Samant,
                  Vaidehi and Sicilia, John and Nivarti, Anantha Kumar
                  and Ramachandran, Raghuvir and Fischer, Tim and
                  Herzberg, Ben and McGee, Bill and Venkataramanan,
                  Ganesh and Banon, Pete},
  journal =	 {IEEE Micro},
  title =	 {{The Microarchitecture of DOJO, Tesla’s Exa-Scale
                  Computer}},
  year =	 2023,
  volume =	 43,
  number =	 03,
  ISSN =	 {1937-4143},
  pages =	 {31-39},
  abstract =	 { The Tesla-built DOJO system is a scalable solution
                  targeted towards machine learning training
                  applications. It is based on the D1 custom compute
                  chip which packs together 354 independent
                  processors, resulting in 362 TFLOPS of compute and
                  440 MB of internal static random-access memory
                  storage. While maintaining full programmability,
                  DOJO emphasizes distribution of resources and an
                  extremely high bandwidth interconnect, allowing it
                  to scale from small systems all the way to exaFLOP
                  supercomputers. },
  keywords =	 {Computer
                  architecture;Training;Microarchitecture;Machine
                  learning;Bandwidth;Instruction sets;Computational
                  modeling},
  doi =		 {10.1109/MM.2023.3258906},
  url =
                  {https://doi.ieeecomputersociety.org/10.1109/MM.2023.3258906},
  publisher =	 {IEEE Computer Society},
  address =	 {Los Alamitos, CA, USA},
  month =	 may
}

@inproceedings{pauloski2021kaisa,
  title =	 {KAISA: an adaptive second-order optimizer framework
                  for deep neural networks},
  author =	 {Pauloski, J Gregory and Huang, Qi and Huang, Lei and
                  Venkataraman, Shivaram and Chard, Kyle and Foster,
                  Ian and Zhang, Zhao},
  booktitle =	 {Proceedings of the International Conference for High
                  Performance Computing, Networking, Storage and
                  Analysis},
  pages =	 {1--14},
  year =	 2021
}


@article{fang2021deep,
  title =	 {Deep learning-based point-scanning super-resolution
                  imaging},
  author =	 {Fang, Linjing and Monroe, Fred and Novak, Sammy
                  Weiser and Kirk, Lyndsey and Schiavon, Cara R and
                  Seungyoon, B Yu and Zhang, Tong and Wu, Melissa and
                  Kastner, Kyle and Latif, Alaa Abdel and others},
  journal =	 {Nature Methods},
  volume =	 18,
  number =	 4,
  pages =	 {406--416},
  year =	 2021,
  publisher =	 {Nature Publishing Group}
}

@article{ivezic2019lsst,
  title =	 {LSST: from science drivers to reference design and
                  anticipated data products},
  author =	 {Ivezi{\'c}, {\v{Z}}eljko and Kahn, Steven M and
                  Tyson, J Anthony and Abel, Bob and Acosta, Emily and
                  Allsman, Robyn and Alonso, David and AlSayyad, Yusra
                  and Anderson, Scott F and Andrew, John and others},
  journal =	 {The Astrophysical Journal},
  volume =	 873,
  number =	 2,
  pages =	 111,
  year =	 2019,
  publisher =	 {IOP Publishing}
}

@inproceedings{pu2016fairride,
  title =	 {Fairride: Near-optimal, fair cache sharing},
  author =	 {Pu, Qifan and Li, Haoyuan and Zaharia, Matei and
                  Ghodsi, Ali and Stoica, Ion},
  booktitle =	 {13th {USENIX} Symposium on Networked Systems Design
                  and Implementation ({NSDI} 16)},
  pages =	 {393--406},
  year =	 2016
}

@inproceedings{mahajan2020themis,
  title =	 {Themis: Fair and efficient {GPU} cluster scheduling},
  author =	 {Mahajan, Kshiteej and Balasubramanian, Arjun and
                  Singhvi, Arjun and Venkataraman, Shivaram and
                  Akella, Aditya and Phanishayee, Amar and Chawla,
                  Shuchi},
  booktitle =	 {17th {USENIX} Symposium on Networked Systems Design
                  and Implementation ({NSDI} 20)},
  pages =	 {289--304},
  year =	 2020
}

@misc{gpt-neox,
  author =	 {Andonian, Alex and Anthony, Quentin and Biderman,
                  Stella and Black, Sid and Gali, Preetham and Gao,
                  Leo and Hallahan, Eric and Levy-Kramer, Josh and
                  Leahy, Connor and Nestler, Lucas and Parker, Kip and
                  Pieler, Michael and Purohit, Shivanshu and Songz,
                  Tri and Wang, Phil and Weinbach, Samuel},
  title =	 {{GPT-NeoX: Large Scale Autoregressive Language
                  Modeling in PyTorch}},
  url =		 {http://github.com/eleutherai/gpt-neox},
  year =	 2021
}

@inproceedings{gowda-etal-2021-many,
  title =	 "Many-to-{E}nglish Machine Translation Tools, Data,
                  and Pretrained Models",
  author =	 "Gowda, Thamme and Zhang, Zhao and Mattmann, Chris
                  and May, Jonathan",
  booktitle =	 "Proceedings of the 59th Annual Meeting of the
                  Association for Computational Linguistics and the
                  11th International Joint Conference on Natural
                  Language Processing: System Demonstrations",
  month =	 aug,
  year =	 2021,
  address =	 "Online",
  publisher =	 "Association for Computational Linguistics",
  url =		 "https://aclanthology.org/2021.acl-demo.37",
  doi =		 "10.18653/v1/2021.acl-demo.37",
  pages =	 "306--316",
}

@misc{spectre-classifier,
  author =	 {Zhang, Zhao and Gaffney, Niall},
  title =	 {A Spectrum based Supernovae Classifier},
  url =		 {https://github.com/zhaozhang/spectra},
  year =	 2020,
}

@inproceedings{smith1999using,
  title =	 {Using run-time predictions to estimate queue wait
                  times and improve scheduler performance},
  author =	 {Smith, Warren and Taylor, Valerie and Foster, Ian},
  booktitle =	 {Workshop on Job scheduling strategies for Parallel
                  Processing},
  pages =	 {202--219},
  year =	 1999,
  organization = {Springer}
}

@inproceedings{nurmi2006evaluation,
  title =	 {Evaluation of a workflow scheduler using integrated
                  performance modelling and batch queue wait time
                  prediction},
  author =	 {Nurmi, Daniel and Mandal, Anirban and Brevik, John
                  and Koelbel, Chuck and Wolski, Rich and Kennedy,
                  Ken},
  booktitle =	 {SC'06: Proceedings of the 2006 ACM/IEEE conference
                  on Supercomputing},
  pages =	 {29--29},
  year =	 2006,
  organization = {IEEE}
}

@inproceedings{nurmi2007qbets,
  title =	 {QBETS: Queue bounds estimation from time series},
  author =	 {Nurmi, Daniel and Brevik, John and Wolski, Rich},
  booktitle =	 {Workshop on Job Scheduling Strategies for Parallel
                  Processing},
  pages =	 {76--101},
  year =	 2007,
  organization = {Springer}
}

@inproceedings{sonmez2009trace,
  title =	 {Trace-based evaluation of job runtime and queue wait
                  time predictions in grids},
  author =	 {Sonmez, Ozan and Yigitbasi, Nezih and Iosup,
                  Alexandru and Epema, Dick},
  booktitle =	 {Proceedings of the 18th ACM international symposium
                  on High performance distributed computing},
  pages =	 {111--120},
  year =	 2009
}

@string {ASPLOS = "Proceedings of the International Conference on Architectural Support for Programming Languages and Operation Systems (ASPLOS)"}
@string {ISCA = "Proceedings of the International Symposium on Computer Architecture (ISCA)"}
@string {MICRO = "Proceedings of the International Symposium on Microarchitecture (MICRO)"}
@string {HPCA = "Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA)"}
@string {ICCD = "Proceedings of the International Conference on Computer Design (ICCD)"}
@string {PACT = "Proceedings of the International Conference on Parallel Architectures and Compilation Techniques (PACT)"}
@string {UTCS = "Department of Computer Sciences, The University of Texas at Austin"}       
@string {UTECE = "Department of Electrical and Computer Engineering, The University of Texas at Austin"}        
@string {PPoPP = "Proceedings of the Symposium on Principles and Practice of Parallel Programming (PPOPP)"}
@string {ISSCC = "Proceedings of the International Solid State Circuits Conference (ISSCC)"}
@string {SOSP = "Proceedings of the ACM Symposium on Operating System Principles (SOSP)"}
@string {JSSC = "IEEE Journal of Solid-State Circuits"}
@string {SC = "Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis (SC)"}
@string {ICS = "Proceedings of the ACM international conference on Supercomputing"}       
@string {SPAA = "Proceedings of the ACM Symposium on Parallel Algorithms and Architectures (SPAA)"}
@string {IEEETC = "IEEE Transactions on Computers"}
@string {ACMTC = "ACM Transactions on Computer Systems"}
@string {CACM = "Communications of the ACM"}
@string {PLDI = "Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)"}
@string {DAC = "Proceedings of the Design Automation Conference (DAC)"}
@string {IEDM = "Proceedings of the International Electron Devices Meeting (IEDM)"}
@string {CGO = "International Symposium on Code Generation and Optimization (CGO)"}      
@string {IISWC = "Proceedings of the International Symposium on Workload Characterization (IISWC)"}
@string {ICPP = "Proceedings of the International Conference on Parallel Processing (ICPP)"}  
@string {HIPC = "Proceedings of the International Conference on High Performance Computing (HiPC)"}
@string {ISPASS = "Proceedings of the International Symposium on Performance Analysis of Systems and Software (ISPASS)"}       
@string {IPDPS = "Proceedings of the  International Parallel and Distributed Processing Symposium (IPDPS)"}
@string {OOPSLA = "Proceedings of the Object-Oriented Programming, Systems, Languages and Applications (OOPSLA)"}
@string {SOCC = "Proceedings of the Symposium on Cloud Computing (SOCC)"}
@string {VLDB = "The International Journal on Very Large Data Bases (VLDB)"}
@string {SIGMOD = "Proceedings of the International Conference on Management of Data (SIGMOD)"}
@string {SIGOPS = "ACM SIGOPS Operating Systems Review"}
@string {FPGA = "Proceedings of the International Symposium on Field-Programmable Gate Arrays"}
@string {OSDI = "Proceedings of the International Conference on Operating Systems Design and Implementation"}
@string {POPL = "Proceedings of the ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages"}

@MISC{BERTforGoogleSearch,
  author =	 {Nayak, Pandu},
  title =	 {{Understanding searches better than ever before}},
  howpublished = {"\url{https://blog.google/products/search/search-language-understanding-bert/}"},
  year =	 2019,
}

@inbook{Rumelhart88RNN,
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  title =	 {{Learning Representations by Back-Propagating Errors}},
  year =	 1988,
  isbn =	 0262010976,
  publisher =	 {MIT Press},
  address =	 {Cambridge, MA, USA},
  booktitle =	 {{Neurocomputing: Foundations of Research}},
  pages =	 {696–699},
  numpages =	 4
}

@MISC{MLGrowth,
  author = {Gholami, Amir},
  title =	 {{Memory Footprint and FLOPs for SOTA Models in CV/NLP/Speech}},
  howpublished = {"\url{https://github.com/amirgholami/ai_and_memory_wall}"},
  year =	 2021,
}

@misc{jia2018data,
  title =	 {{Beyond Data and Model Parallelism for Deep Neural  Networks}},
  author = {Zhihao Jia and Matei Zaharia and Alex Aiken},
  year =	 2018,
  eprint =	 {1807.05358},
  howpublished ={arXiv},
  primaryClass = {cs.DC}
}

@inproceedings{DevlinChang18-bert,
  author =	 {Jacob Devlin and Ming{-}Wei Chang and Kenton Lee and Kristina Toutanova},
  editor =	 {Jill Burstein and Christy Doran and Thamar Solorio},
  title =	 {{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}},
  booktitle =	 {{Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}},
  series =	 {NAACL-HLT},
  pages =	 {4171--4186},
  publisher =	 {Association for Computational Linguistics},
  year =	 2019,
  url =		 {https://doi.org/10.18653/v1/n19-1423},
  doi =		 {10.18653/v1/n19-1423},
  timestamp =	 {Fri, 06 Aug 2021 00:41:31 +0200},
  biburl =	 {https://dblp.org/rec/conf/naacl/DevlinCLT19.bib},
  bibsource =	 {dblp computer science bibliography,
                  https://dblp.org}
}

@inproceedings{AmodeiAnubhai2016-deepSpeech2,
  author =	 {Dario Amodei and Rishita Anubhai and Eric Battenberg and Carl Case and Jared Casper and Bryan Catanzaro and Jingdong Chen and Mike Chrzanowski and Adam Coates and Greg Diamos and Erich Elsen and Jesse Engel and Linxi Fan and Christopher Fougner and Awni Y. Hannun and Billy Jun and Tony Han and Patrick LeGresley and Xiangang Li and Libby Lin and Sharan Narang and Andrew Y. Ng and Sherjil Ozair and Ryan Prenger and Sheng Qian and Jonathan Raiman and Sanjeev Satheesh and David Seetapun and Shubho Sengupta and Chong Wang and Yi Wang and Zhiqian Wang and Bo Xiao and Yan Xie and Dani Yogatama and Jun Zhan and Zhenyao Zhu},
  title =	 {{Deep Speech 2 : End-to-End Speech Recognition in
                  English and Mandarin}},
  booktitle =	 {{Proceedings of the 33nd International Conference on
                  Machine Learning}},
  series =	 {{ICML}},
  pages =	 {173--182},
  year =	 2016,
}

@article{WuSchuster16-seq2seq,
  author =	 {Yonghui Wu and Mike Schuster and Zhifeng Chen and
                  Quoc V. Le and Mohammad Norouzi and Wolfgang
                  Macherey and Maxim Krikun and Yuan Cao and Qin Gao
                  and Klaus Macherey and Jeff Klingner and Apurva Shah
                  and Melvin Johnson and Xiaobing Liu and Lukasz
                  Kaiser and Stephan Gouws and Yoshikiyo Kato and Taku
                  Kudo and Hideto Kazawa and Keith Stevens and George
                  Kurian and Nishant Patil and Wei Wang and Cliff
                  Young and Jason Smith and Jason Riesa and Alex
                  Rudnick and Oriol Vinyals and Greg Corrado and
                  Macduff Hughes and Jeffrey Dean},
  title =	 {{Google's Neural Machine Translation System:
                  Bridging the Gap between Human and Machine
                  Translation}},
  journal =	 {CoRR},
  volume =	 {abs/1609.08144},
  year =	 2016,
  url =		 {http://arxiv.org/abs/1609.08144},
  howpublished ={arXiv},
  eprint =	 {1609.08144},
}

@inproceedings{PatiAga20-seqPoints,
  author =	 {Pati, Suchita and Aga, Shaizeen and Sinclair,
                  Matthew D. and Jayasena, Nuwan},
  title =	 {{SeqPoint: Identifying Representative Iterations of
                  Sequence-based Neural Networks}},
  booktitle =	 {{IEEE International Symposium on Performance
                  Analysis of Systems and Software}},
  series =	 {ISPASS},
  year =	 2020,
  month =	 {August},
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
  pages =	 {69-80},
  doi =		 {10.1109/ISPASS48437.2020.00017}
}

@article{MattsonReddi2020-mlPerf,
  title =	 {{MLPerf: An Industry Standard Benchmark Suite for
                  Machine Learning Performance}},
  author =	 {Mattson, Peter and Reddi, Vijay Janapa and Cheng,
                  Christine and Coleman, Cody and Diamos, Greg and
                  Kanter, David and Micikevicius, Paulius and
                  Patterson, David and Schmuelling, Guenther and Tang,
                  Hanlin and others},
  journal =	 {IEEE Micro},
  volume =	 40,
  number =	 2,
  pages =	 {8--16},
  year =	 2020,
  publisher =	 {IEEE},
}

@MISC{Tensile,
  author =	 {{AMD}},
  title =	 {{AMD's tool for creating a benchmark-driven backend
                  library for GEMMs}},
  howpublished =
                  {"\url{https://github.com/ROCmSoftwarePlatform/Tensile/}"},
  year =	 2020,
}

@MISC{NV-DL-Perf,
  author =	 {{NVIDIA}},
  title =	 {NVIDIA Deep Learning Performance},
  howpublished =
                  {"\url{https://docs.nvidia.com/deeplearning/performance/index.html}"},
  year =	 2019,
}

@article{HochreiterSchmidhuber1997-lstm,
  author =	 {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
  title =	 {{Long Short-Term Memory}},
  journal =	 {{Neural Computation}},
  issue_date =	 {November 15, 1997},
  volume =	 9,
  number =	 8,
  month =	 nov,
  year =	 1997,
  issn =	 {0899-7667},
  pages =	 {1735--1780},
  numpages =	 46,
  url =		 {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
  doi =		 {10.1162/neco.1997.9.8.1735},
  acmid =	 1246450,
  publisher =	 {MIT Press},
  address =	 {Cambridge, MA, USA},
}

@INPROCEEDINGS{ChoMerrienboer14-gru,
  author =	 {Cho, Kyunghyun and van Merri{\"{e}}nboer, Bart and
                  G{\"{u}}l{\c c}ehre, {\c C}ağlar and Bahdanau,
                  Dzmitry and Bougares, Fethi and Schwenk, Holger and
                  Bengio, Yoshua},
  month =	 oct,
  title =	 {{Learning Phrase Representations using RNN
                  Encoder--Decoder for Statistical Machine
                  Translation}},
  booktitle =	 {{Proceedings of the 2014 Conference on Empirical
                  Methods in Natural Language Processing}},
  series =	 {EMNLP},
  year =	 2014,
  pages =	 {1724--1734},
  publisher =	 {Association for Computational Linguistics},
  address =	 {Doha, Qatar},
  url =		 {http://www.aclweb.org/anthology/D14-1179}
}

%Concurrency in GPU

@inproceedings{adriaens2012case,
  title =	 {{The Case for GPGPU Spatial Multitasking}},
  author =	 {Adriaens, Jacob T and Compton, Katherine and Kim,
                  Nam Sung and Schulte, Michael J},
  booktitle =	 {{IEEE International Symposium on High-Performance
                  Comp Architecture}},
  pages =	 {1--12},
  year =	 2012,
  organization = {IEEE},
  series =	 {HPCA},
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
}

@inproceedings{jiao2015improving,
  title =	 {{Improving GPGPU energy-efficiency through
                  concurrent kernel execution and DVFS}},
  author =	 {Jiao, Qing and Lu, Mian and Huynh, Huynh Phung and
                  Mitra, Tulika},
  booktitle =	 {{2015 IEEE/ACM International Symposium on Code
                  Generation and Optimization}},
  series =	 {CGO},
  pages =	 {1--11},
  year =	 2015,
  organization = {IEEE},
}

@inproceedings{pai2013improving,
  author =	 {Pai, Sreepathi and Thazhuthaveetil, Matthew J. and
                  Govindarajan, R.},
  title =	 {{Improving GPGPU Concurrency with Elastic Kernels}},
  year =	 2013,
  isbn =	 9781450318709,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/2451116.2451160},
  doi =		 {10.1145/2451116.2451160},
  abstract =	 {Each new generation of GPUs vastly increases the
                  resources available to GPGPU programs.  GPU
                  programming models (like CUDA) were designed to
                  scale to use these resources.  However, we find that
                  CUDA programs actually do not scale to utilize all
                  available resources, with over 30\% of resources
                  going unused on average for programs of the Parboil2
                  suite that we used in our work. Current GPUs
                  therefore allow concurrent execution of kernels to
                  improve utilization. In this work, we study
                  concurrent execution of GPU kernels using
                  multiprogram workloads on current NVIDIA Fermi
                  GPUs. On two-program workloads from the Parboil2
                  benchmark suite we find concurrent execution is
                  often no better than serialized execution. We
                  identify that the lack of control over resource
                  allocation to kernels is a major serialization
                  bottleneck. We propose transformations that convert
                  CUDA kernels into elastic kernels which permit
                  fine-grained control over their resource usage. We
                  then propose several elastic-kernel aware
                  concurrency policies that offer significantly better
                  performance and concurrency compared to the current
                  CUDA policy. We evaluate our proposals on real
                  hardware using multiprogrammed workloads constructed
                  from benchmarks in the Parboil 2 suite. On average,
                  our proposals increase system throughput (STP) by
                  1.21x and improve the average normalized turnaround
                  time (ANTT) by 3.73x for two-program workloads when
                  compared to the current CUDA concurrency
                  implementation.},
  booktitle =	 {{Proceedings of the Eighteenth International
                  Conference on Architectural Support for Programming
                  Languages and Operating Systems}},
  pages =	 {407–418},
  numpages =	 12,
  keywords =	 {concurrent kernels, cuda, gpgpu},
  location =	 {Houston, Texas, USA},
  series =	 {ASPLOS '13}
}

@MISC{amd-kernel-object,
  author =	 {{AMD}},
  title =	 {{AMD HSA Code Object Format}},
  howpublished =
                  {"\url{https://rocmdocs.amd.com/en/latest/ROCm_Compiler_SDK/ROCm-Codeobj-format.html}"},
  year =	 2021,
}

@inproceedings{puthoor2018oversubscribed,
  author =	 {Puthoor, Sooraj and Tang, Xulong and Gross, Joseph
                  and Beckmann, Bradford M.},
  title =	 {{Oversubscribed Command Queues in GPUs}},
  booktitle =	 {{Proceedings of the 11th Workshop on General Purpose
                  GPUs}},
  series =	 {GPGPU-11},
  year =	 2018,
  isbn =	 {978-1-4503-5647-3},
  location =	 {Vienna, Austria},
  pages =	 {50--60},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/3180270.3180271},
  doi =		 {10.1145/3180270.3180271},
  acmid =	 3180271,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
}

@MISC{amd-cdna-arch,
  author =	 {{AMD}},
  title =	 {{AMD CDNA Architecture}},
  howpublished =
                  {"\url{https://www.amd.com/system/files/documents/amd-cdna-whitepaper.pdf}"},
  year =	 2020,
}

% mi210

@misc{amd-cdna2,
  author =	 {{AMD}},
  title =	 {{Introducing AMD CDNA 2 Architecture}},
  howpublished =
                  {\url{https://www.amd.com/content/dam/amd/en/documents/instinct-business-docs/white-papers/amd-cdna2-white-paper.pdf}},
  year =	 2022,
}

@MISC{threadripper,
  author =	 {{AMD}},
  title =	 {{AMD Ryzen\texttrademark\ Threadripper 2950X
                  Processor}},
  howpublished =
                  {"\url{https://www.amd.com/en/products/cpu/amd-ryzen-threadripper-2950x}"},
  year =	 2019,
}

@MISC{mi100,
  author =	 {{AMD}},
  title =	 {{AMD Instinct\texttrademark\ MI100 Accelerator}},
  howpublished =
                  {"\url{https://www.amd.com/en/products/server-accelerators/instinct-mi100}"},
  year =	 2020,
}

@MISC{hip,
  author =	 {{AMD}},
  title =	 {{HIP : C++ Heterogeneous-Compute Interface for
                  Portability}},
  howpublished =
                  {"\url{https://gpuopen.com/compute-product/hip-convert-cuda-to-portable-c-code/}"},
  year =	 2019,
}

@MISC{hiptensorflow,
  author =	 {{AMD}},
  title =	 {{ROCm/HIP enabled Tensorflow}},
  howpublished = {"\url{https://github.com/soyers/hiptensorflow}"},
  year =	 2019,
}

@MISC{rocm,
  author =	 {{AMD}},
  title =	 {{ROCm, a New Era in Open GPU Computing}},
  howpublished = {"\url{https://rocm.github.io/}"},
  year =	 2019,
}

@misc{khan2019miopen,
  title =	 {{MIOpen: An Open Source Library For Deep Learning
                  Primitives}},
  author =	 {Jehandad Khan and Paul Fultz and Artem Tamazov and
                  Daniel Lowell and Chao Liu and Michael Melesse and
                  Murali Nandhimandalam and Kamil Nasyrov and Ilya
                  Perminov and Tejash Shah and Vasilii Filippov and
                  Jing Zhang and Jing Zhou and Bragadeesh Natarajan
                  and Mayank Daga},
  year =	 2019,
  eprint =	 {1910.00078},
  howpublished ={arXiv},
  primaryClass = {cs.LG},
}

@misc{miopen-git,
  author =	 {{AMD}},
  title =	 {{AMD's Machine Intelligence Library}},
  howpublished =
                  {"\url{https://github.com/ROCmSoftwarePlatform/MIOpen}"},
  year =	 2019,
}

@MISC{rocblas,
  author =	 {{AMD}},
  title =	 {{AMD's BLAS Library}},
  howpublished =
                  {"\url{https://github.com/ROCmSoftwarePlatform/rocBLAS}"},
  year =	 2019,
}

@MISC{rocprof-profiler,
  author =	 {{AMD}},
  title =	 {{AMD ROCm Profiler}},
  howpublished =
                  {"\url{https://rocmdocs.amd.com/en/latest/ROCm\_Tools/ROCm-Tools.html}"},
  year =	 2019,
}

@MISC{hbm2,
  author =	 {{JEDEC}},
  title =	 {{High Bandwidth Memory DRAM (HBM1, HBM2)}},
  howpublished =
                  {"\url{https://www.jedec.org/standards-documents/docs/jesd235a}"},
  year =	 2019,
}

@MISC{multi-instance-1,
  author =	 {{TIRIAS Research}},
  title =	 {{Why Your AI infrastructure Needs Both Training and
                  Inference}},
  howpublished = {"https://www.ibm.com/downloads/cas/QM4BYOPP"},
  year =	 2019,
}

@MISC{multi-instance-2,
  author =	 {{NVIDIA}},
  title =	 {{Easily Deploy Deep Learning Models in Production}},
  howpublished =
                  {"https://www.kdnuggets.com/2019/08/nvidia-deploy-deep-learning-models-production.html"},
  year =	 2019,
}

@MISC{multi-instance-3,
  author =	 {{NVIDIA}},
  title =	 {{Ride the Fast Lane to AI Productivity with
                  Multi-Instance GPUs}},
  howpublished =
                  {"https://blogs.nvidia.com/blog/2020/05/14/multi-instance-gpus/"},
  year =	 2020,
}

@misc{TPU2,
  author =	 {Alcorn, Paul},
  title =	 {{Hot Chips 2017: A Closer Look At Google's TPU v2}},
  howpublished =
                  {http://www.tomshardware.com/news/tpu-v2-google-machine-learning,35370.html},
  month =	 "September",
  year =	 2017,
}

@ARTICLE{NorriePatil2021-tpuV2V3,
  author =	 {Norrie, Thomas and Patil, Nishant and Yoon, Doe Hyun
                  and Kurian, George and Li, Sheng and Laudon, James
                  and Young, Cliff and Jouppi, Norman and Patterson,
                  David},
  journal =	 {IEEE Micro},
  title =	 {{The Design Process for Google's Training Chips:
                  TPUv2 and TPUv3}},
  year =	 2021,
  volume =	 41,
  number =	 2,
  pages =	 {56-63},
  keywords =	 {Training;Internet;Random access
                  memory;Hardware;Software engineering;Feeds},
  doi =		 {10.1109/MM.2021.3058217}
}

@inproceedings{JouppiYoung2017-tpu,
  author =	 {Jouppi, Norman P. and Young, Cliff and Patil,
                  Nishant and Patterson, David and Agrawal, Gaurav and
                  Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh
                  and Boden, Nan and Borchers, Al and Boyle, Rick and
                  Cantin, Pierre-luc and Chao, Clifford and Clark,
                  Chris and Coriell, Jeremy and Daley, Mike and Dau,
                  Matt and Dean, Jeffrey and Gelb, Ben and
                  Ghaemmaghami, Tara Vazir and Gottipati, Rajendra and
                  Gulland, William and Hagmann, Robert and Ho,
                  C. Richard and Hogberg, Doug and Hu, John and Hundt,
                  Robert and Hurt, Dan and Ibarz, Julian and Jaffey,
                  Aaron and Jaworski, Alek and Kaplan, Alexander and
                  Khaitan, Harshit and Killebrew, Daniel and Koch,
                  Andy and Kumar, Naveen and Lacy, Steve and Laudon,
                  James and Law, James and Le, Diemthu and Leary,
                  Chris and Liu, Zhuyuan and Lucke, Kyle and Lundin,
                  Alan and MacKean, Gordon and Maggiore, Adriana and
                  Mahony, Maire and Miller, Kieran and Nagarajan,
                  Rahul and Narayanaswami, Ravi and Ni, Ray and Nix,
                  Kathy and Norrie, Thomas and Omernick, Mark and
                  Penukonda, Narayana and Phelps, Andy and Ross,
                  Jonathan and Ross, Matt and Salek, Amir and
                  Samadiani, Emad and Severn, Chris and Sizikov,
                  Gregory and Snelham, Matthew and Souter, Jed and
                  Steinberg, Dan and Swing, Andy and Tan, Mercedes and
                  Thorson, Gregory and Tian, Bo and Toma, Horia and
                  Tuttle, Erick and Vasudevan, Vijay and Walter,
                  Richard and Wang, Walter and Wilcox, Eric and Yoon,
                  Doe Hyun},
  title =	 {{In-Datacenter Performance Analysis of a Tensor
                  Processing Unit}},
  booktitle =	 {{Proceedings of the 44th Annual International
                  Symposium on Computer Architecture}},
  series =	 {ISCA},
  year =	 2017,
  isbn =	 {978-1-4503-4892-8},
  location =	 {Toronto, ON, Canada},
  pages =	 {1--12},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/3079856.3080246},
  doi =		 {10.1145/3079856.3080246},
  acmid =	 3080246,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {CNN, DNN, GPU, LSTM, MLP, RNN, TPU, TensorFlow,
                  accelerator, deep learning, domain-specific
                  architecture, neural network},
}

@inproceedings{JouppiYoon2021-tpuv4,
  title =	 {{Ten Lessons from Three Generations Shaped Google's
                  TPUv4i}},
  author =	 {Jouppi, Norman P. and Yoon, Doe Hyun and Ashcraft,
                  Matthew and Gottscho, Mark and Jablin, Thomas B. and
                  Kurian, George and Laudon, James and Li, Sheng and
                  Ma, Peter and Ma, Xiaoyu and Patil, Nishant and
                  Prasad, Sushma and Young, Clifford and Zhou, Zongwei
                  and Patterson, David},
  booktitle =	 {{Proceedings of the 48th Annual International
                  Symposium on Computer Architecture}},
  series =	 {ISCA},
  year =	 2021,
}

@INPROCEEDINGS{BakhodaYuan2009-gpgpuSim,
  author =	 {Bakhoda, Ali and Yuan, George L. and Fung, Wilson W. L. and Wong, Henry and Aamodt, Tor M.},
  booktitle =	 {{2009 IEEE International Symposium on Performance Analysis of Systems and Software}},
  series =	 {ISPASS},
  title =	 {{Analyzing CUDA workloads using a detailed GPU simulator}},
  year =	 2009,
  pages =	 {163-174},
  keywords =	 {cache storage;computer graphic equipment;instruction sets;multiprocessing systems;multi-threading;parallel architectures;CUDA workload;GPU simulator;graphic processing unit;flexible programming model;CUDA
                  programming;microarchitecture performance
                  simulator;parallel thread execution;virtual
                  instruction set;GPU hardware;high-end graphics
                  card;microarchitecture design;interconnect
                  topology;caches;memory controller;parallel workload
                  distribution;memory request coalescing
                  hardware;Analytical models;Yarn;Graphics;Parallel
                  processing;Microarchitecture;Hardware;Process
                  design;Concurrent computing;Parallel
                  programming;Computational modeling},
  doi =		 {10.1109/ISPASS.2009.4919648},
  ISSN =	 {null},
  month =	 {April},
}

@article{KhairyJain2018-voltaGPGPUSim,
  author =	 {Mahmoud Khairy and Akshay Jain and Tor M. Aamodt and
                  Timothy G. Rogers},
  title =	 {Exploring Modern {GPU} Memory System Design
                  Challenges through Accurate Modeling},
  journal =	 {CoRR},
  volume =	 {abs/1810.07269},
  year =	 2018,
  url =		 {http://arxiv.org/abs/1810.07269},
  howpublished ={arXiv},
  eprint =	 {1810.07269},
  timestamp =	 {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl =
                  {https://dblp.org/rec/journals/corr/abs-1810-07269.bib},
  bibsource =	 {dblp computer science bibliography,
                  https://dblp.org}
}

@article{RaihanGoli2018-gpgpusimTC,
  author =	 {Md Aamir Raihan and Negar Goli and Tor M. Aamodt},
  title =	 {{Modeling Deep Learning Accelerator Enabled GPUs}},
  journal =	 {CoRR},
  volume =	 {abs/1811.08309},
  year =	 2018,
  url =		 {http://arxiv.org/abs/1811.08309},
  howpublished ={arXiv},
  eprint =	 {1811.08309},
  timestamp =	 {Mon, 26 Nov 2018 12:52:45 +0100},
  biburl =
                  {https://dblp.org/rec/journals/corr/abs-1811-08309.bib},
  bibsource =	 {dblp computer science bibliography,
                  https://dblp.org}
}

@INPROCEEDINGS{KhairyShen2021-accelSim,
  author =	 {Khairy, Mahmoud and Shen, Zhesheng and Aamodt, Tor
                  M. and Rogers, Timothy G.},
  booktitle =	 {{2020 ACM/IEEE 47th Annual International Symposium
                  on Computer Architecture}},
  series =	 {ISCA},
  title =	 {{Accel-Sim: An Extensible Simulation Framework for
                  Validated GPU Modeling}},
  year =	 2020,
  pages =	 {473-486},
  doi =		 {10.1109/ISCA45697.2020.00047}
}

@misc{volta,
  title =	 {{{NVIDIA Tesla V100 GPU Architecture The World's
                  Most Advanced Data Center GPU}}},
  author =	 {{NVIDIA}},
  organization = {{NVIDIA}},
  year =	 2017,
  howpublished =
                  {{\url{http://www.nvidia.com/object/volta-architecture-whitepaper.html}
                  }}
}

@inproceedings{VaswaniShazeer17-attention,
  author =	 {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki
                  and Uszkoreit, Jakob and Jones, Llion and Gomez,
                  Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  title =	 {{Attention Is All You Need}},
  isbn =	 9781510860964,
  year =	 2017,
  publisher =	 {Curran Associates Inc.},
  address =	 {Red Hook, NY, USA},
  abstract =	 {The dominant sequence transduction models are based
                  on complex recurrent or convolutional neural
                  networks that include an encoder and a decoder. The
                  best performing models also connect the encoder and
                  decoder through an attention mechanism. We propose a
                  new simple network architecture, the Transformer,
                  based solely on attention mechanisms, dispensing
                  with recurrence and convolutions
                  entirely. Experiments on two machine translation
                  tasks show these models to be superior in quality
                  while being more parallelizable and requiring
                  significantly less time to train. Our model achieves
                  28.4 BLEU on the WMT 2014 English-to-German
                  translation task, improving over the existing best
                  results, including ensembles, by over 2 BLEU. On the
                  WMT 2014 English-to-French translation task, our
                  model establishes a new single-model
                  state-of-the-art BLEU score of 41.0 after training
                  for 3.5 days on eight GPUs, a small fraction of the
                  training costs of the best models from the
                  literature.},
  booktitle =	 {{Proceedings of the 31st International Conference on
                  Neural Information Processing Systems}},
  pages =	 {6000–6010},
  numpages =	 11,
  location =	 {Long Beach, California, USA},
  series =	 {NeurIPS},
}

@inproceedings{HestnessArdalani2019-dlChalls,
  author =	 {Hestness, Joel and Ardalani, Newsha and Diamos,
                  Gregory},
  title =	 {{Beyond Human-Level Accuracy: Computational
                  Challenges in Deep Learning}},
  year =	 2019,
  isbn =	 9781450362252,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/3293883.3295710},
  doi =		 {10.1145/3293883.3295710},
  booktitle =	 {{Proceedings of the 24th Symposium on Principles and
                  Practice of Parallel Programming}},
  pages =	 {1–14},
  numpages =	 14,
  keywords =	 {deep learning, model parallelism, neural networks,
                  compute requirements, data parallelism, compute
                  graph},
  location =	 {Washington, District of Columbia},
  series =	 {PPoPP ’19},
}

@misc{IvanovDryden2020-transformersDataMove,
  title =	 {{Data Movement Is All You Need: A Case Study on
                  Optimizing Transformers}},
  author =	 {Andrei Ivanov and Nikoli Dryden and Tal Ben-Nun and
                  Shigang Li and Torsten Hoefler},
  year =	 2020,
  eprint =	 {2007.00072},
  howpublished ={arXiv},
  primaryClass = {cs.LG}
}

@INPROCEEDINGS{ZadehPoulos2019-dlTime,
  author =	 {Zadeh, Ali Hadi and Poulos, Zissis and Moshovos,
                  Andreas},
  booktitle =	 {{IEEE International Symposium on Workload
                  Characterization}},
  series =	 {IISWC},
  title =	 {{Deep Learning Language Modeling Workloads: Where
                  Time Goes on Graphics Processors}},
  year =	 2019,
  pages =	 {131-142},
  organization = {IEEE},
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
}

@misc{ShoeybiPatwary2019-megatronlm,
  title =	 {{Megatron-LM: Training Multi-Billion Parameter
                  Language Models Using Model Parallelism}},
  author =	 {Mohammad Shoeybi and Mostofa Patwary and Raul Puri
                  and Patrick LeGresley and Jared Casper and Bryan
                  Catanzaro},
  year =	 2019,
  eprint =	 {1909.08053},
  howpublished ={arXiv},
  primaryClass = {cs.CL}
}

@inproceedings{LanChen2019-albert,
  author =	 {Lan, Zhenzhong and Chen, Mingda and Goodman,
                  Sebastian and Gimpel, Kevin and Sharma, Piyush and
                  Soricut, Radu},
  title =	 {{ALBERT: A Lite BERT for Self-supervised Learning of
                  Language Representations}},
  booktitle =	 {{Proceedings of the Seventh International Conference
                  on Learning Representation}},
  series =	 {ICLR},
  year =	 2019,
  numpages =	 17,
  publisher =	 {OpenReview.net},
}

@inproceedings{ZhuXia2020-bertNMT,
  author =	 {Zhu, Jinhua and Xia, Yingce and Wu, Lijun and He, Di
                  amd Qin, Tao and Zhou, Wengang and Li, Houqiang and
                  Liu, Tieyan},
  title =	 {{Incorporating BERT into Neural Machine
                  Translation}},
  year =	 2020,
  series =	 {ICLR},
  booktitle =	 {{Proceedings of the Eighth International Conference
                  on Learning Representation}},
}

@inproceedings{BahdanauCho2015-nmt,
  title =	 {{Neural Machine Translation by Jointly Learning to
                  Align and Translate}},
  author =	 {Bahdanau, Dzmitry and Cho, KyungHyun and Bengio,
                  Yoshua},
  year =	 2015,
  series =	 {ICLR},
  booktitle =	 {{Proceedings of the Third International Conference
                  on Learning Representation}},
}

@inproceedings{LuongPham2015-attentionNMT,
  title =	 "Effective Approaches to Attention-based Neural
                  Machine Translation",
  author =	 "Luong, Thang and Pham, Hieu and Manning, Christopher
                  D.",
  booktitle =	 "Proceedings of the 2015 Conference on Empirical
                  Methods in Natural Language Processing",
  series =	 {EMNLP},
  month =	 sep,
  year =	 2015,
  address =	 "Lisbon, Portugal",
  publisher =	 "Association for Computational Linguistics",
  url =		 "https://www.aclweb.org/anthology/D15-1166",
  doi =		 "10.18653/v1/D15-1166",
  pages =	 "1412--1421",
}

@inproceedings{ShenZhou2018-bidirAttention,
  title =	 {{Bi-Directional Block Self-Attention for Fast and
                  Memory-Efficient Sequence Modeling}},
  author =	 {Tao Shen and Tianyi Zhou and Guodong Long and Jing
                  Jiang and Chengqi Zhang},
  year =	 2018,
  booktitle =	 {{Proceedings of the Sixth International Conference
                  on Learning Representation}},
  series =	 {ICLR},
}

@inproceedings{kitaev2020reformer,
  title =	 {{Reformer: The Efficient Transformer}},
  author =	 {Nikita Kitaev and Łukasz Kaiser and Anselm Levskaya},
  year =	 2020,
  booktitle =	 {{Proceedings of the Eighth International Conference
                  on Learning Representation}},
  series =	 {ICLR},
}

@misc{correia2019adaptively,
  title =	 {{Adaptively Sparse Transformers}},
  author =	 {Gonçalo M. Correia and Vlad Niculae and André
                  F. T. Martins},
  year =	 2019,
  booktitle =	 {{Proceedings of the 2019 Conference on Empirical
                  Methods in Natural Language Processing and the 9th
                  International Joint Conference on Natural Language
                  Processing}},
  series =	 {EMNLP-IJCNP},
}

@misc{gpt3-github,
  title =	 {{GPT-3: Language Models are Few-Shot Learners}},
  howpublished = {\url{https://github.com/openai/gpt-3}},
  author =	 {OpenAI},
  year =	 2020,
}

@misc{gpt2-github,
  title =	 {{gpt-2 Github}},
  author =	 {OpenAI},
  howpublished = {\url{https://github.com/openai/gpt-2}},
  year =	 2019,
}

@misc{megatron-github,
  author =	 {NVIDIA},
  title =	 {{Megatron-LM Github}},
  year =	 2018,
  howpublished = {\url{https://github.com/NVIDIA/Megatron-LM}},
}

@misc{ZhuPhanishayee2020-daydream,
  title =	 {{Daydream: Accurately Estimating the Efficacy of
                  Optimizations for DNN Training}},
  author =	 {Hongyu Zhu and Amar Phanishayee and Gennady
                  Pekhimenko},
  year =	 2020,
  eprint =	 {2006.03318},
  howpublished ={arXiv},
  primaryClass = {cs.DC}
}

@inproceedings{VillaStephenson2019-nvbit,
  author =	 {Villa, Oreste and Stephenson, Mark and Nellans,
                  David and Keckler, Stephen W.},
  title =	 {{NVBit: A Dynamic Binary Instrumentation Framework
                  for NVIDIA GPUs}},
  year =	 2019,
  isbn =	 9781450369381,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/3352460.3358307},
  doi =		 {10.1145/3352460.3358307},
  booktitle =	 {{Proceedings of the 52nd Annual IEEE/ACM
                  International Symposium on Microarchitecture}},
  pages =	 {372–383},
  numpages =	 12,
  keywords =	 {Dynamic binary instrumentation, GPGPU, GPU
                  computing, CUDA},
  location =	 {Columbus, OH, USA},
  series =	 {MICRO ’52}
}

@inproceedings{NarayananHarlap2019-pipedream,
  author =	 {Narayanan, Deepak and Harlap, Aaron and Phanishayee,
                  Amar and Seshadri, Vivek and Devanur, Nikhil R. and
                  Ganger, Gregory R. and Gibbons, Phillip B. and
                  Zaharia, Matei},
  title =	 {{PipeDream: Generalized Pipeline Parallelism for DNN
                  Training}},
  year =	 2019,
  isbn =	 9781450368735,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/3341301.3359646},
  doi =		 {10.1145/3341301.3359646},
  booktitle =	 {{Proceedings of the 27th ACM Symposium on Operating
                  Systems Principles}},
  pages =	 {1–15},
  numpages =	 15,
  location =	 {Huntsville, Ontario, Canada},
  series =	 {SOSP ’19}
}

@misc{LiZheng2020-horizFus,
  title =	 {{Automatic Horizontal Fusion for GPU Kernels}},
  author =	 {Ao Li and Bojian Zheng and Gennady Pekhimenko and
                  Fan Long},
  year =	 2020,
  eprint =	 {2007.01277},
  howpublished ={arXiv},
  primaryClass = {cs.DC}
}

@inproceedings{SivathanuChugh2019-astra,
  author =	 {Sivathanu, Muthian and Chugh, Tapan and Singapuram,
                  Sanjay S. and Zhou, Lidong},
  title =	 {{Astra: Exploiting Predictability to Optimize Deep
                  Learning}},
  year =	 2019,
  isbn =	 9781450362405,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/3297858.3304072},
  doi =		 {10.1145/3297858.3304072},
  booktitle =	 {{Proceedings of the Twenty-Fourth International
                  Conference on Architectural Support for Programming
                  Languages and Operating Systems}},
  pages =	 {909–923},
  numpages =	 15,
  keywords =	 {domain-specific compiler, deep learning, adaptation},
  location =	 {Providence, RI, USA},
  series =	 {ASPLOS ’19}
}

@inproceedings{SpringerWauligmann2017-fuseGPULang,
  author =	 {Springer, Matthias and Wauligmann, Peter and
                  Masuhara, Hidehiko},
  title =	 {{Modular Array-Based GPU Computing in a
                  Dynamically-Typed Language}},
  year =	 2017,
  isbn =	 9781450350693,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/3091966.3091974},
  doi =		 {10.1145/3091966.3091974},
  booktitle =	 {{Proceedings of the 4th ACM SIGPLAN International
                  Workshop on Libraries, Languages, and Compilers for
                  Array Programming}},
  pages =	 {48–55},
  numpages =	 8,
  keywords =	 {kernel fusion, Ruby, GPGPU, CUDA},
  location =	 {Barcelona, Spain},
  series =	 {ARRAY 2017}
}

@article{FilipovivcMadzin2015-blasCUDAFusion,
  author =	 {Filipovi\v{c}, Ji\v{r}\'{\i} and Madzin,
                  Mat\'{u}\v{s} and Fousek, Jan and Matyska,
                  Ludundefinedk},
  title =	 {{Optimizing CUDA Code by Kernel Fusion: Application
                  on BLAS}},
  year =	 2015,
  issue_date =	 {October 2015},
  publisher =	 {Kluwer Academic Publishers},
  address =	 {USA},
  volume =	 71,
  number =	 10,
  issn =	 {0920-8542},
  url =		 {https://doi.org/10.1007/s11227-015-1483-z},
  doi =		 {10.1007/s11227-015-1483-z},
  journal =	 {{The Journal of Supercomputing}},
  month =	 oct,
  pages =	 {3934–3957},
  numpages =	 24,
  keywords =	 {BLAS, GPGPU, Kernel fusion, Code generation, CUDA}
}

@article{FousekFilipovivc2011-fuseGPUMap,
  author =	 {Fousek, Jan and Filipovi\v{c}, Ji\v{r}i and Madzin,
                  Matu\v{s}},
  title =	 {{Automatic Fusions of CUDA-GPU Kernels for Parallel
                  Map}},
  year =	 2011,
  issue_date =	 {September 2011},
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  volume =	 39,
  number =	 4,
  issn =	 {0163-5964},
  url =		 {https://doi.org/10.1145/2082156.2082183},
  doi =		 {10.1145/2082156.2082183},
  journal =	 {SIGARCH Comput. Archit. News},
  month =	 dec,
  pages =	 {98–99},
  numpages =	 2
}

@inproceedings{WangLin2010-gpuKernelFusion,
  author =	 {Wang, Guibin and Lin, YiSong and Yi, Wei},
  title =	 {{Kernel Fusion: An Effective Method for Better Power
                  Efficiency on Multithreaded GPU}},
  year =	 2010,
  isbn =	 9780769543314,
  publisher =	 {IEEE Computer Society},
  address =	 {USA},
  url =		 {https://doi.org/10.1109/GreenCom-CPSCom.2010.102},
  doi =		 {10.1109/GreenCom-CPSCom.2010.102},
  booktitle =	 {{Proceedings of the 2010 IEEE/ACM Int’l Conference
                  on Green Computing and Communications \& Int’l
                  Conference on Cyber, Physical and Social Computing}},
  pages =	 {344–350},
  numpages =	 7,
  keywords =	 {Kernel Fusion, Power Efficiency, GPGPU, Power
                  Optimization},
  series =	 {GREENCOM-CPSCOM ’10}
}

@misc{cuDNN,
  title =	 {{NVIDIA cuDNN: GPU Accelerated Deep Learning}},
  author =	 {NVIDIA},
  year =	 2018,
  howpublished = {\url{https://developer.nvidia.com/cudnn}},
}

@article{Appleyard2016-optRNNGPU,
  author =	 {Jeremy Appleyard and Tom{\'{a}}s Kocisk{\'{y}} and
                  Phil Blunsom},
  title =	 {{Optimizing Performance of Recurrent Neural Networks
                  on GPUs}},
  journal =	 {{CoRR}},
  volume =	 {abs/1604.01946},
  year =	 2016,
  url =		 {http://arxiv.org/abs/1604.01946},
}

@misc{MehtaGhazvininejad2020-delight,
  title =	 {{DeLighT: Very Deep and Light-weight Transformer}},
  author =	 {Sachin Mehta and Marjan Ghazvininejad and Srinivasan
                  Iyer and Luke Zettlemoyer and Hannaneh Hajishirzi},
  year =	 2020,
  eprint =	 {2008.00623},
  howpublished ={arXiv},
  primaryClass = {cs.LG}
}

@inproceedings{MehtaKoncel2019-define,
  title =	 {{DeFINE: Deep Factorized Input Token Embeddings for
                  Neural Sequence Modeling}},
  author =	 {Mehta, Sachin and Koncel-Kedziorski, Rik and
                  Rastegari, Mohammad and Hajishirzi, Hannaneh},
  booktitle =	 {{International Conference on Learning
                  Representations}},
  series =	 {ICLR},
  year =	 2019
}

@misc{delight-github,
  title =	 {{DeLighT: Very Deep and Light-weight Transformers}},
  author =	 {Mehta, Sachin},
  howpublished = {\url{https://github.com/sacmehta/delight}},
  year =	 2020,
}

@misc{ampere,
  title =	 {{NVIDIA Ampere Architecture In-Depth}},
  author =	 {Krashinsky, Ronny and Giroux, Olivier and Jones,
                  Stephen and Stam, Nick and Ramaswamy, Sridhar},
  year =	 2020,
  month =	 {Month},
  howpublished =
                  {\url{https://developer.nvidia.com/blog/nvidia-ampere-architecture-in-depth/}},
}

@inproceedings{ChenMoreau2018-tvm,
  author =	 {Chen, Tianqi and Moreau, Thierry and Jiang, Ziheng
                  and Zheng, Lianmin and Yan, Eddie and Cowan, Meghan
                  and Shen, Haichen and Wang, Leyuan and Hu, Yuwei and
                  Ceze, Luis and Guestrin, Carlos and Krishnamurthy,
                  Arvind},
  title =	 {{TVM: An Automated End-to-End Optimizing Compiler
                  for Deep Learning}},
  year =	 2018,
  isbn =	 9781931971478,
  publisher =	 {USENIX Association},
  address =	 {USA},
  booktitle =	 {{Proceedings of the 13th USENIX Conference on
                  Operating Systems Design and Implementation}},
  pages =	 {579–594},
  numpages =	 16,
  location =	 {Carlsbad, CA, USA},
  series =	 {OSDI’18}
}

@misc{YangDai2019-xlnet,
  title =	 {{XLNet: Generalized Autoregressive Pretraining for
                  Language Understanding}},
  author =	 {Zhilin Yang and Zihang Dai and Yiming Yang and Jaime
                  Carbonell and Ruslan Salakhutdinov and Quoc V. Le},
  year =	 2019,
  eprint =	 {1906.08237},
  howpublished ={arXiv},
  primaryClass = {cs.CL}
}

@misc{xlnet-github,
  title =	 {{XLNet Github}},
  howpublished = {\url{https://github.com/zihangdai/xlnet}},
  year =	 2019,
  author =	 {Dai, Zihang},
}

@misc{LiuOtt2019-roberta,
  title =	 {{RoBERTa: A Robustly Optimized BERT Pretraining
                  Approach}},
  author =	 {Yinhan Liu and Myle Ott and Naman Goyal and Jingfei
                  Du and Mandar Joshi and Danqi Chen and Omer Levy and
                  Mike Lewis and Luke Zettlemoyer and Veselin
                  Stoyanov},
  year =	 2019,
  eprint =	 {1907.11692},
  howpublished ={arXiv},
  primaryClass = {cs.CL}
}

@misc{multiWeekGPUTraining,
  title =	 {{AI and Compute}},
  month =	 {May},
  howpublished = {\url{https://openai.com/blog/ai-and-compute/}},
  author =	 {Amodei, Dario and Hernandez, Danny and Sastry,
                  Girish and Clark, Jack and Brockman, Greg and
                  Sutskever, Ilya},
  year =	 2018,
}

@inproceedings{HuangCheng2019-gpipe,
  author =	 {Yanping Huang and Youlong Cheng and Ankur Bapna and
                  Orhan Firat and Mia Xu Chen and Dehao Chen and
                  HyoukJoong Lee and Jiquan Ngiam and Quoc V. Le and
                  Yonghui Wu and Zhifeng Chen},
  title =	 {{GPipe: Efficient Training of Giant Neural Networks
                  using Pipeline Parallelism}},
  booktitle =	 {{Proceedings of the 33rd International Conference on
                  Neural Information Processing Systems}},
  series =	 {{NeurIPS}},
  year =	 2019,
}

@misc{LinLi2020-bertMultiNode,
  title =	 {{Multi-node BERT-pretraining: Cost-efficient
                  Approach}},
  author =	 {Jiahuang Lin and Xin Li and Gennady Pekhimenko},
  year =	 2020,
  eprint =	 {2008.00177},
  howpublished ={arXiv},
  primaryClass = {cs.LG}
}

@article{kalamkar2019bfloat16,
  author =	 {Dhiraj D. Kalamkar and Dheevatsa Mudigere and Naveen
                  Mellempudi and Dipankar Das and Kunal Banerjee and
                  Sasikanth Avancha and Dharma Teja Vooturi and
                  Nataraj Jammalamadaka and Jianyu Huang and Hector
                  Yuen and Jiyan Yang and Jongsoo Park and Alexander
                  Heinecke and Evangelos Georganas and Sudarshan
                  Srinivasan and Abhisek Kundu and Misha Smelyanskiy
                  and Bharat Kaul and Pradeep Dubey},
  title =	 {A Study of {BFLOAT16} for Deep Learning Training},
  journal =	 {CoRR},
  volume =	 {abs/1905.12322},
  year =	 2019,
}

@misc{YangZhang2019-pipemare,
  title =	 {{PipeMare: Asynchronous Pipeline Parallel DNN
                  Training}},
  author =	 {Bowen Yang and Jian Zhang and Jonathan Li and
                  Christopher Ré and Christopher R. Aberger and
                  Christopher De Sa},
  year =	 2019,
  eprint =	 {1910.05124},
  howpublished ={arXiv},
  primaryClass = {cs.DC}
}

@inproceedings{QinyiHe2020-prague,
  author =	 {Luo, Qinyi and He, Jiaao and Zhuo, Youwei and Qian,
                  Xuehai},
  title =	 {{Prague: High-Performance Heterogeneity-Aware
                  Asynchronous Decentralized Training}},
  year =	 2020,
  isbn =	 9781450371025,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/3373376.3378499},
  doi =		 {10.1145/3373376.3378499},
  booktitle =	 {{Proceedings of the Twenty-Fifth International
                  Conference on Architectural Support for Programming
                  Languages and Operating Systems}},
  pages =	 {401–416},
  numpages =	 16,
  keywords =	 {heterogeneity, deep learning, decentralized
                  training, machine learning},
  location =	 {Lausanne, Switzerland},
  series =	 {ASPLOS ’20}
}

@INPROCEEDINGS{HamJung2020-a3,
  author =	 {Ham, Tae Jun and Jung, Sung Jun and Kim, Seonghak
                  and Park, Yeonhong and Oh, Young H. and Song, Yoon
                  Ho and Park, Junghoon and Lee, Sanghee and Park,
                  Kyoung and Lee, Jae W. and Jeong, Deog-Kyoon},
  booktitle =	 {{26th IEEE International Symposium on High
                  Performance Computer Architecture}},
  title =	 {{A3: Accelerating Attention Mechanisms in Neural
                  Networks with Approximation}},
  year =	 2020,
  series =	 {HPCA},
  month =	 {Feb},
}

@misc{RaihanAamodt2020-swat,
  title =	 {{Sparse Weight Activation Training}},
  author =	 {Md Aamir Raihan and Tor M. Aamodt},
  year =	 2020,
  eprint =	 {2001.01969},
  howpublished ={arXiv},
  primaryClass = {cs.LG}
}

@article{PatiAga2021-demystifying,
  title =	 {{Demystifying BERT: Implications for Accelerator
                  Design}},
  author =	 {Suchita Pati and Shaizeen Aga and Nuwan Jayasena and
                  Matthew D. Sinclair},
  year =	 2021,
  eprint =	 {2104.08335},
  journal =	 {CoRR},
  volume =	 {abs/2104.08335},
  howpublished ={arXiv},
  primaryClass = {cs.AR}
}

@INPROCEEDINGS{PatiAga2022-demystifying,
  title =	 {{Demystifying BERT: System Design Implications}},
  author =	 {Suchita Pati and Shaizeen Aga and Nuwan Jayasena and
                  Matthew D. Sinclair},
  year =	 2021,
  booktitle =	 {{IEEE International Symposium on Workload
                  Characterization}},
  series =	 {{IISWC}},
}

@INPROCEEDINGS{BruceAkram2021-gem5art,
  author =	 {Bruce, Bobby R. and Akram, Ayaz and Nguyen, Hoa and
                  Roarty, Kyle and Samani, Mahyar and Fariborz, Marjan
                  and Reddy, Trivikram and Sinclair, Matthew D. and
                  Lowe-Power, Jason},
  booktitle =	 {{IEEE International Symposium on Performance
                  Analysis of Systems and Software}},
  series =	 {ISPASS},
  title =	 {{Enabling Reproducible and Agile Full-System
                  Simulation}},
  year =	 2021,
}

@inproceedings{KuperPati2021-gpuUtil,
  title =	 {{Improving GPU Utilization in ML Workloads Through
                  Finer-Grained Synchronization}},
  author =	 {Kuper, Reese and Pati, Suchita and Sinclair, Matthew
                  D.},
  booktitle =	 {{3rd Young Architects Workshop}},
  series =	 {YArch},
  month =	 {April},
  year =	 2021,
}

@INPROCEEDINGS{LeBeanePotter2016-taskQueue,
  author =	 {LeBeane, Michael and Potter, Brandon and Pan,
                  Abhisek and Dutu, Alexandru and Agarwala, Vinay and
                  Lee, Wonchan and Majeti, Deepak and Ghimire, Bibek
                  and Tassell, Eric Van and Wasmundt, Samuel and
                  Benton, Brad and Breternitz, Mauricio and Chu,
                  Michael L. and Thottethodi, Mithuna and John, Lizy
                  K. and Reinhardt, Steven K.},
  booktitle =	 {{Proceedings of the International Conference for
                  High Performance Computing, Networking, Storage and
                  Analysis}},
  series =	 {SC},
  title =	 {{Extended Task Queuing: Active Messages for
                  Heterogeneous Systems}},
  year =	 2016,
  pages =	 {933-944},
  doi =		 {10.1109/SC.2016.79}
}

@inproceedings{LeBeaneHamidouche2018-cpNet,
  author =	 {LeBeane, Michael and Hamidouche, Khaled and Benton,
                  Brad and Breternitz, Mauricio and Reinhardt, Steven
                  K. and John, Lizy K.},
  title =	 {{ComP-Net: Command Processor Networking for
                  Efficient Intra-Kernel Communications on GPUs}},
  year =	 2018,
  isbn =	 9781450359863,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/3243176.3243179},
  doi =		 {10.1145/3243176.3243179},
  abstract =	 {Current state-of-the-art in GPU networking advocates
                  a host-centric model that reduces performance and
                  increases code complexity. Recently, researchers
                  have explored several techniques for networking
                  within a GPU kernel itself. These approaches,
                  however, suffer from high latency, waste energy on
                  the host, and are not scalable with larger/more GPUs
                  on a node. In this work, we introduce Command
                  Processor Networking (ComP-Net), which leverages the
                  availability of scalar cores integrated on the GPU
                  itself to provide high-performance intra-kernel
                  networking. ComP-Net enables efficient
                  synchronization between the Command Processors and
                  Compute Units on the GPU through a line locking
                  scheme implemented in the GPU's shared last-level
                  cache. We illustrate that ComP-Net can improve
                  application performance by up to 20\% and provide up
                  to 50\% reduction in energy consumption
                  vs. competing networking techniques across a Jacobi
                  stencil, allreduce collective, and machine learning
                  applications.},
  booktitle =	 {{Proceedings of the 27th International Conference on
                  Parallel Architectures and Compilation Techniques}},
  articleno =	 29,
  numpages =	 13,
  keywords =	 {GPUs, programming models, RDMA networks},
  location =	 {Limassol, Cyprus},
  series =	 {PACT '18}
}

@misc{nvidia-stream,
  author =	 {NVIDIA},
  title =	 {NVIDIA, CUDA Stream Management},
  year =	 2018,
  url =
                  {http://developer.download.nvidia.com/compute/cuda/2_3/toolkit/docs/online/group__CUDART__STREAM.html},
  urldate =	 {2019-06-01}
}

@misc{nvidia-stream2,
  author =	 {Justin Luitjens},
  title =	 {CUDA Streams: Best Practices and Common Pitfalls},
  year =	 2014,
  series =	 {GPU Technology Conference},
}

@misc{amd-hip,
  author =	 {AMD},
  title =	 {{HIP: Heterogeneous-computing Interface for
                  Portability}},
  year =	 2018,
  url =		 {https://github.com/ROCm-Developer-Tools/HIP/},
  urldate =	 {2019-06-01}
}

@misc{amd-white,
  author =	 {AMD},
  title =	 {{AMD’s Asynchronous Shaders White Paper}},
  year =	 2012,
  url =
                  {https://developer.amd.com/wordpress/media/2012/10/Asynchronous-Shaders-White-Paper-FINAL.pdf},
  urldate =	 {2019-06-01}
}

@inproceedings{amd-dag,
  author =	 {Puthoor, Sooraj and Aji, Ashwin M. and Che, Shuai
                  and Daga, Mayank and Wu, Wei and Beckmann, Bradford
                  M. and Rodgers, Gregory},
  title =	 {{Implementing Directed Acyclic Graphs with the
                  Heterogeneous System Architecture}},
  booktitle =	 {{Proceedings of the 9th Annual Workshop on General
                  Purpose Processing Using Graphics Processing Unit}},
  series =	 {GPGPU '16},
  year =	 2016,
  isbn =	 {978-1-4503-4195-0},
  location =	 {Barcelona, Spain},
  pages =	 {53--62},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/2884045.2884052},
  doi =		 {10.1145/2884045.2884052},
  acmid =	 2884052,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {APU, directed acyclic graph (DAG), fine-grain task
                  management, heterogeneous system architecture (HSA)},
}

@misc{nvidia-hyperq,
  title =	 {{CUDA HyperQ Example}},
  author =	 {NVIDIA},
  year =	 2013,
  howpublished =
                  {\url{http://developer.download.nvidia.com/compute/DevZone/C/html_x64/6_Advanced/simpleHyperQ/doc/HyperQ.pdf}},
}

@article{nvidia_tesla,
  title =	 {{{NVIDIA Tesla}: A Unified Graphics and Computing
                  Architecture}},
  author =	 {Lindholm, E. and Nickolls, J. and Oberman, S. and
                  Montrym, J.},
  journal =	 {IEEE Micro},
  year =	 2008,
  month =	 {March-April},
  volume =	 28,
  number =	 2,
  pages =	 {39-55},
}

@inproceedings{RoartySinclair2020-gem5GPU,
  title =	 {{Modeling Modern GPU Applications in gem5}},
  author =	 {Roarty, Kyle and Sinclair, Matthew D.},
  year =	 2020,
  month =	 {June},
  booktitle =	 {{3rd gem5 Users' Workshop}},
}

@article{LowePowerAhmad2020-gem520,
  title =	 {The gem5 Simulator: Version 20.0+},
  author =	 {Jason Lowe-Power and Abdul Mutaal Ahmad and Ayaz
                  Akram and Mohammad Alian and Rico Amslinger and
                  Matteo Andreozzi and Adrià Armejach and Nils
                  Asmussen and Srikant Bharadwaj and Gabe Black and
                  Gedare Bloom and Bobby R. Bruce and Daniel Rodrigues
                  Carvalho and Jeronimo Castrillon and Lizhong Chen
                  and Nicolas Derumigny and Stephan Diestelhorst and
                  Wendy Elsasser and Marjan Fariborz and Amin
                  Farmahini-Farahani and Pouya Fotouhi and Ryan
                  Gambord and Jayneel Gandhi and Dibakar Gope and
                  Thomas Grass and Bagus Hanindhito and Andreas
                  Hansson and Swapnil Haria and Austin Harris and
                  Timothy Hayes and Adrian Herrera and Matthew
                  Horsnell and Syed Ali Raza Jafri and Radhika Jagtap
                  and Hanhwi Jang and Reiley Jeyapaul and Timothy
                  M. Jones and Matthias Jung and Subash Kannoth and
                  Hamidreza Khaleghzadeh and Yuetsu Kodama and Tushar
                  Krishna and Tommaso Marinelli and Christian Menard
                  and Andrea Mondelli and Tiago Mück and Omar Naji and
                  Krishnendra Nathella and Hoa Nguyen and Nikos
                  Nikoleris and Lena E. Olson and Marc Orr and Binh
                  Pham and Pablo Prieto and Trivikram Reddy and Alec
                  Roelke and Mahyar Samani and Andreas Sandberg and
                  Javier Setoain and Boris Shingarov and Matthew
                  D. Sinclair and Tuan Ta and Rahul Thakur and Giacomo
                  Travaglini and Michael Upton and Nilay Vaish and
                  Ilias Vougioukas and Zhengrong Wang and Norbert Wehn
                  and Christian Weis and David A. Wood and Hongil Yoon
                  and Éder F. Zulian},
  year =	 2020,
  journal =	 {CoRR},
  volume =	 {abs/2007.03152},
  eprint =	 {2007.03152},
  howpublished ={arXiv},
  primaryClass = {cs.AR}
}

@inproceedings{BrownMann2020-gpt3,
  author =	 {Brown, Tom and Mann, Benjamin and Ryder, Nick and
                  Subbiah, Melanie and Kaplan, Jared D and Dhariwal,
                  Prafulla and Neelakantan, Arvind and Shyam, Pranav
                  and Sastry, Girish and Askell, Amanda and Agarwal,
                  Sandhini and Herbert-Voss, Ariel and Krueger,
                  Gretchen and Henighan, Tom and Child, Rewon and
                  Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey
                  and Winter, Clemens and Hesse, Chris and Chen, Mark
                  and Sigler, Eric and Litwin, Mateusz and Gray, Scott
                  and Chess, Benjamin and Clark, Jack and Berner,
                  Christopher and McCandlish, Sam and Radford, Alec
                  and Sutskever, Ilya and Amodei, Dario},
  booktitle =	 {{Advances in Neural Information Processing Systems}},
  editor =	 {H. Larochelle and M. Ranzato and R. Hadsell and
                  M. F. Balcan and H. Lin},
  pages =	 {1877--1901},
  publisher =	 {Curran Associates, Inc.},
  address =	 {Red Hook, NY, USA},
  title =	 {{Language Models are Few-Shot Learners}},
  url =
                  {https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
  volume =	 33,
  year =	 2020,
  series =	 {NeurIPS},
}

@article{RadfordWu2019-gpt2,
  title =	 {Language Models are Unsupervised Multitask Learners},
  author =	 {Radford, Alec and Wu, Jeff and Child, Rewon and
                  Luan, David and Amodei, Dario and Sutskever, Ilya},
  year =	 2019,
  journal =	 {OpenAI Blog},
  volume =	 1,
  number =	 8,
}

@article{Microsoft2020-tnlg,
  title =	 {Turing-NLG: A 17-billion-parameter language model by
                  Microsoft},
  author =	 {Microsoft},
  year =	 2020,
  journal =	 {Microsoft Research Blog},
  url =
                  {https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/},
  volume =	 1,
  number =	 8,
}

@article{BanburyReddi2021-tinyMLPerf,
  author =	 {Colby R. Banbury and Vijay Janapa Reddi and Peter
                  Torelli and Jeremy Holleman and Nat Jeffries and
                  Csaba Kir{\'{a}}ly and Pietro Montino and David
                  Kanter and Sebastian Ahmed and Danilo Pau and Urmish
                  Thakker and Antonio Torrini and Pete Warden and Jay
                  Cordaro and Giuseppe Di Guglielmo and Javier
                  M. Duarte and Stephen Gibellini and Videet Parekh
                  and Honson Tran and Nhan Tran and Wenxu Niu and
                  Xuesong Xu},
  title =	 {MLPerf Tiny Benchmark},
  journal =	 {CoRR},
  volume =	 {abs/2106.07597},
  year =	 2021,
  url =		 {https://arxiv.org/abs/2106.07597},
  howpublished ={arXiv},
  eprint =	 {2106.07597},
  timestamp =	 {Wed, 16 Jun 2021 10:42:19 +0200},
  biburl =
                  {https://dblp.org/rec/journals/corr/abs-2106-07597.bib},
  bibsource =	 {dblp computer science bibliography,
                  https://dblp.org}
}

@ARTICLE{ReddiCheng2021-mlPerfVision,
  author =	 {Reddi, Vijay Janapa and Cheng, Christine and Kanter,
                  David and Mattson, Peter and Schmuelling, Guenther
                  and Wu, Carole-Jean},
  journal =	 {IEEE Micro},
  title =	 {{The Vision Behind MLPerf: Understanding AI
                  Inference Performance}},
  year =	 2021,
  volume =	 41,
  number =	 3,
  pages =	 {10-18},
  doi =		 {10.1109/MfM.2021.3066343}
}

% - L. Ke, et  al.  RecNMP:  Accelerating  Personalized  Recommendation with Near-Memory Processing. In ISCA, pp. 790-803, 2020.
% - LAX https://pages.cs.wisc.edu/~sinclair/papers/yeh-lax-hpca21.pdf
% - Batch-Maker P. Gao, et  al.  Low  latency  RNN  inference  with  cellular  batching, inEuroSys, pp. 1-15, 2018.
% - Prema
% - Successor of Prema from Minsoo: LazyBatching

@inproceedings{GaoYu2018-batchmaker,
  author =	 {Gao, Pin and Yu, Lingfan and Wu, Yongwei and Li,
                  Jinyang},
  title =	 {Low Latency RNN Inference with Cellular Batching},
  booktitle =	 {{Proceedings of the Thirteenth EuroSys Conference}},
  series =	 {EuroSys '18},
  year =	 2018,
  isbn =	 {978-1-4503-5584-1},
  location =	 {Porto, Portugal},
  pages =	 {31:1--31:15},
  articleno =	 31,
  numpages =	 15,
  url =		 {http://doi.acm.org/10.1145/3190508.3190541},
  doi =		 {10.1145/3190508.3190541},
  acmid =	 3190541,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {batching, dataflow graph, inference, recurrent
                  neural network},
}

@INPROCEEDINGS{YehSinclair2021-lax,
  author =	 {Yeh, Tsung Tai and Sinclair, Matthew D. and
                  Beckmann, Bradford M. and Rogers, Timothy G.},
  booktitle =	 {{27th IEEE International Symposium on High
                  Performance Computer Architecture}},
  series =	 {HPCA},
  title =	 {{Deadline-Aware Offloading for High-Throughput
                  Accelerators}},
  year =	 2021,
  pages =	 {479-492},
  doi =		 {10.1109/HPCA51647.2021.00048}
}

@INPROCEEDINGS{ChoiRhu2020-prema,
  author =	 {Choi, Yujeong and Rhu, Minsoo},
  booktitle =	 {{26th IEEE International Symposium on High
                  Performance Computer Architecture}},
  series =	 {HPCA},
  title =	 {{PREMA: A Predictive Multi-Task Scheduling Algorithm
                  For Preemptible Neural Processing Units}},
  year =	 2020,
  pages =	 {220-233},
  doi =		 {10.1109/HPCA47549.2020.00027}
}

@INPROCEEDINGS{ChoiKim2021-lazyBatching,
  author =	 {Y. Choi and Y. Kim and M. Rhu},
  booktitle =	 {{27th IEEE International Symposium on High
                  Performance Computer Architecture}},
  series =	 {HPCA},
  title =	 {{Lazy Batching: An SLA-aware Batching System for
                  Cloud Machine Learning Inference}},
  year =	 2021,
  pages =	 {493-506},
  keywords =	 {training;quality of service;machine
                  learning;computer architecture;throughput;time
                  factors},
  doi =		 {10.1109/HPCA51647.2021.00049},
  url =
                  {https://doi.ieeecomputersociety.org/10.1109/HPCA51647.2021.00049},
  publisher =	 {IEEE Computer Society},
  address =	 {Los Alamitos, CA, USA},
  month =	 {mar}
}

@inproceedings{KeGupta2020-recNMP,
  author =	 {Ke, Liu and Gupta, Udit and Cho, Benjamin Youngjae
                  and Brooks, David and Chandra, Vikas and Diril, Utku
                  and Firoozshahian, Amin and Hazelwood, Kim and Jia,
                  Bill and Lee, Hsien-Hsin S. and Li, Meng and Maher,
                  Bert and Mudigere, Dheevatsa and Naumov, Maxim and
                  Schatz, Martin and Smelyanskiy, Mikhail and Wang,
                  Xiaodong and Reagen, Brandon and Wu, Carole-Jean and
                  Hempstead, Mark and Zhang, Xuan},
  title =	 {{RecNMP: Accelerating Personalized Recommendation
                  with near-Memory Processing}},
  year =	 2020,
  isbn =	 9781728146614,
  publisher =	 {IEEE Press},
  url =		 {https://doi.org/10.1109/ISCA45697.2020.00070},
  abstract =	 {Personalized recommendation systems leverage deep
                  learning models and account for the majority of data
                  center AI cycles. Their performance is dominated by
                  memory-bound sparse embedding operations with unique
                  irregular memory access patterns that pose a
                  fundamental challenge to accelerate. This paper
                  proposes a lightweight, commodity DRAM compliant,
                  near-memory processing solution to accelerate
                  personalized recommendation inference. The in-depth
                  characterization of production-grade recommendation
                  models shows that embedding operations with high
                  model-, operator- and data-level parallelism lead to
                  memory bandwidth saturation, limiting recommendation
                  inference performance.  We propose RecNMP which
                  provides a scalable solution to improve system
                  throughput, supporting a broad range of sparse
                  embedding models. RecNMP is specifically tailored to
                  production environments with heavy co-location of
                  operators on a single server.  Several
                  hardware/software co-optimization techniques such as
                  memory-side caching, table-aware packet scheduling,
                  and hot entry profiling are studied, providing up to
                  9.8x memory latency speedup over a highly-optimized
                  baseline. Overall, RecNMP offers 4.2x throughput
                  improvement and 45.8\% memory energy savings.},
  booktitle =	 {{Proceedings of the ACM/IEEE 47th Annual
                  International Symposium on Computer Architecture}},
  series =	 {ISCA},
  pages =	 {790–803},
  numpages =	 14
}

@article{MattsonCheng2019-mlperfTrain,
  author =	 {Peter Mattson and Christine Cheng and Cody Coleman
                  and Greg Diamos and Paulius Micikevicius and David
                  A. Patterson and Hanlin Tang and Gu{-}Yeon Wei and
                  Peter Bailis and Victor Bittorf and David Brooks and
                  Dehao Chen and Debojyoti Dutta and Udit Gupta and
                  Kim M. Hazelwood and Andrew Hock and Xinyuan Huang
                  and Bill Jia and Daniel Kang and David Kanter and
                  Naveen Kumar and Jeffery Liao and Guokai Ma and
                  Deepak Narayanan and Tayo Oguntebi and Gennady
                  Pekhimenko and Lillian Pentecost and Vijay Janapa
                  Reddi and Taylor Robie and Tom St. John and
                  Carole{-}Jean Wu and Lingjie Xu and Cliff Young and
                  Matei Zaharia},
  title =	 {{MLPerf Training Benchmark}},
  journal =	 {CoRR},
  volume =	 {abs/1910.01500},
  year =	 2019,
  url =		 {http://arxiv.org/abs/1910.01500},
  howpublished ={arXiv},
  eprint =	 {1910.01500},
  timestamp =	 {Mon, 04 Nov 2019 08:16:51 +0100},
  biburl =
                  {https://dblp.org/rec/journals/corr/abs-1910-01500.bib},
  bibsource =	 {dblp computer science bibliography,
                  https://dblp.org},
  numpages =	 14,
}

@misc{pytorch-amp,
  title =	 {{Pytorch Automatic Mixed Precision Package}},
  author =	 {PyTorch},
  year =	 2019,
  howpublished = {\url{https://pytorch.org/docs/stable/amp.html}},
}

@misc{sklearn-multiclass-log-reg,
  title =	 {{Sklearn Multi-class Logistic Regression}},
  author =	 {Sklearn},
  year =	 2019,
  howpublished =
                  {\url{https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression}},
}

@article{hosmer1997comparison,
  title =	 {{A Comparison of Goodness-of-fit Tests for the
                  Logistic Regression Model}},
  author =	 {Hosmer, David W and Hosmer, Trina and Le Cessie,
                  Saskia and Lemeshow, Stanley},
  journal =	 {Statistics in medicine},
  volume =	 16,
  number =	 9,
  pages =	 {965--980},
  year =	 1997,
  publisher =	 {Wiley Online Library}
}

@article{carroll1993robustness,
  title =	 {{On Robustness in the Logistic Regression Model}},
  author =	 {Carroll, Raymond J and Pederson, Shane},
  journal =	 {Journal of the Royal Statistical Society: Series B
                  (Methodological)},
  volume =	 55,
  number =	 3,
  pages =	 {693--706},
  year =	 1993,
  publisher =	 {Wiley Online Library}
}

@misc{he2018streaming,
  title =	 {Streaming End-to-end Speech Recognition For Mobile
                  Devices},
  author =	 {Yanzhang He and Tara N. Sainath and Rohit
                  Prabhavalkar and Ian McGraw and Raziel Alvarez and
                  Ding Zhao and David Rybach and Anjuli Kannan and
                  Yonghui Wu and Ruoming Pang and Qiao Liang and
                  Deepti Bhatia and Yuan Shangguan and Bo Li and Golan
                  Pundak and Khe Chai Sim and Tom Bagby and Shuo-yiin
                  Chang and Kanishka Rao and Alexander Gruenstein},
  year =	 2018,
  eprint =	 {1811.06621},
  howpublished ={arXiv},
  primaryClass = {cs.CL}
}

@INPROCEEDINGS{Reddi2020mlperf-Infer,
  author =	 {Reddi, Vijay Janapa and Cheng, Christine and Kanter,
                  David and Mattson, Peter and Schmuelling, Guenther
                  and Wu, Carole-Jean and Anderson, Brian and Breughe,
                  Maximilien and Charlebois, Mark and Chou, William
                  and Chukka, Ramesh and Coleman, Cody and Davis, Sam
                  and Deng, Pan and Diamos, Greg and Duke, Jared and
                  Fick, Dave and Gardner, J. Scott and Hubara, Itay
                  and Idgunji, Sachin and Jablin, Thomas B. and Jiao,
                  Jeff and John, Tom St. and Kanwar, Pankaj and Lee,
                  David and Liao, Jeffery and Lokhmotov, Anton and
                  Massa, Francisco and Meng, Peng and Micikevicius,
                  Paulius and Osborne, Colin and Pekhimenko, Gennady
                  and Rajan, Arun Tejusve Raghunath and Sequeira,
                  Dilip and Sirasao, Ashish and Sun, Fei and Tang,
                  Hanlin and Thomson, Michael and Wei, Frank and Wu,
                  Ephrem and Xu, Lingjie and Yamada, Koichi and Yu,
                  Bing and Yuan, George and Zhong, Aaron and Zhang,
                  Peizhao and Zhou, Yuchen},
  booktitle =	 {{2020 ACM/IEEE 47th Annual International Symposium
                  on Computer Architecture}},
  series =	 {ISCA},
  title =	 {{MLPerf Inference Benchmark}},
  year =	 2020,
  pages =	 {446-459},
  doi =		 {10.1109/ISCA45697.2020.00045}
}

@article{riscv-story,
  title =	 {{NVIDIA RISC-V Story}},
  author =	 {NVIDIA},
  year =	 2016,
  journal =	 {{4th RISC-V Workshop}},
  url =
                  {https://riscv.org/wp-content/uploads/2016/07/Tue1100_Nvidia_RISCV_Story_V2.pdf},
}

@inproceedings{kotra2021increasing,
  title =	 {{Increasing GPU Translation Reach by Leveraging
                  Under-Utilized On-Chip Resources}},
  author =	 {Kotra, Jagadish B and LeBeane, Michael and Kandemir,
                  Mahmut T and Loh, Gabriel H},
  booktitle =	 {{54th Annual IEEE/ACM International Symposium on
                  Microarchitecture}},
  series =	 {MICRO},
  pages =	 {1169--1181},
  year =	 2021
}

@misc{tensorflow2015-whitepaper,
  title =	 {{TensorFlow}: Large-Scale Machine Learning on
                  Heterogeneous Systems},
  url =		 {http://tensorflow.org/},
  note =	 {Software available from tensorflow.org},
  author =	 { Mart\'{\i}n~Abadi and Ashish~Agarwal and
                  Paul~Barham and Eugene~Brevdo and Zhifeng~Chen and
                  Craig~Citro and Greg~S.~Corrado and Andy~Davis and
                  Jeffrey~Dean and Matthieu~Devin and Sanjay~Ghemawat
                  and Ian~Goodfellow and Andrew~Harp and
                  Geoffrey~Irving and Michael~Isard and Yangqing Jia
                  and Rafal~Jozefowicz and Lukasz~Kaiser and
                  Manjunath~Kudlur and Josh~Levenberg and Dan~Man\'{e}
                  and Rajat~Monga and Sherry~Moore and Derek~Murray
                  and Chris~Olah and Mike~Schuster and Jonathon~Shlens
                  and Benoit~Steiner and Ilya~Sutskever and
                  Kunal~Talwar and Paul~Tucker and Vincent~Vanhoucke
                  and Vijay~Vasudevan and Fernanda~Vi\'{e}gas and
                  Oriol~Vinyals and Pete~Warden and Martin~Wattenberg
                  and Martin~Wicke and Yuan~Yu and Xiaoqiang~Zheng},
  year =	 2015,
}

@inproceedings{paszke2017-pytorch,
  title =	 {{Automatic differentiation in PyTorch}},
  author =	 {Paszke, Adam and Gross, Sam and Chintala, Soumith
                  and Chanan, Gregory and Yang, Edward and DeVito,
                  Zachary and Lin, Zeming and Desmaison, Alban and
                  Antiga, Luca and Lerer, Adam},
  booktitle =	 {NIPS-W},
  year =	 2017
}

@inproceedings{dwf,
  author =	 {Fung, Wilson W. L. and Sham, Ivan and Yuan, George
                  and Aamodt, Tor M.},
  title =	 {{Dynamic Warp Formation and Scheduling for Efficient
                  {GPU} Control Flow}},
  booktitle =	 MICRO,
  pages =	 {407--420},
  year =	 2007
}

@inproceedings{cruise,
  author =	 {Jaleel, Aamer and Najaf-abadi, Hashem H. and
                  Subramaniam, Samantika and Steely, Simon C. and
                  Emer, Joel},
  title =	 {{{CRUISE}: Cache Replacement and Utility-Aware
                  Scheduling}},
  booktitle =	 {{Proceedings of the International Conference on
                  Architectural Support for Programming Languages and
                  Operation Systems}},
  series =	 {ASPLOS},
  year =	 2012,
  pages =	 {249--260},
}

@misc{ccws_posted,
  author =	 {Rogers, Timothy G.},
  title =	 {{{CCWS Simulation Infrastructure}}},
  note =	 {Accessed July 6, 2015},
  organization = {{University of British Columbia}},
  year =	 2013,
  howpublished = { \url{http://www.ece.ubc.ca/~tgrogers/ccws.html} }
}

@article{ccws_toppicks,
  author =	 {Rogers, Timothy G. and O'Connor, Mike and Aamodt,
                  Tor M.},
  title =	 {{Cache-Conscious Thread Scheduling for Massively
                  Multithreaded Processors}},
  journal =	 {IEEE Micro, Special Issue: Micro's Top Picks from
                  2012 Computer Architecture Conferences},
  year =	 2013,
}

@article{tgrogers_cacm,
  author =	 {Rogers, Timothy G. and O'Connor, Mike and Aamodt,
                  Tor M.},
  title =	 {{Learning Your Limit: Managing Massively
                  Multithreaded Caches Through Scheduling}},
  journal =	 {Communications of the ACM},
  year =	 2014,
  month =	 {December},
}

@inproceedings{cawa,
  author =	 {Lee, Shin-Ying and Arunkumar, Akhil and Wu,
                  Carole-Jean},
  title =	 {{CAWA: Coordinated Warp Scheduling and Cache
                  Prioritization for Critical Warp Acceleration of
                  GPGPU Workloads}},
  booktitle =	 ISCA,
  year =	 2015,
  pages =	 {515--527},
}

@inproceedings{gpu-trace-schedule,
  author =	 {Jablin, James A. and Jablin, Thomas B. and Mutlu,
                  Onur and Herlihy, Maurice},
  title =	 {{Warp-aware Trace Scheduling for GPUs}},
  booktitle =	 PACT,
  year =	 2014,
  pages =	 {163--174},
}

@inproceedings{gputhread,
  author =	 {Lakshminarayana, Nagesh B. and Kim, Hyesoon},
  title =	 {{Effect of Instruction Fetch and Memory Scheduling
                  on GPU Performance}},
  booktitle =	 {{{Workshop on Language, Compiler, and Architecture
                  Support for GPGPU}}},
  year =	 2010,
}

@INPROCEEDINGS{RogersOConnor2013-daws,
  author =	 {Rogers, Timothy G. and O'Connor, Mike and Aamodt,
                  Tor M.},
  booktitle =	 {{In 46th Annual IEEE/ACM International Symposium on
                  Microarchitecture}},
  series =	 {MICRO},
  title =	 {{Divergence-Aware Warp Scheduling}},
  year =	 2013,
  pages =	 {99-110}
}

@inproceedings{stall-aware,
  author =	 {Yu, Yulong and Xiao, Weijun and He, Xubin and Guo,
                  He and Wang, Yuxin and Chen, Xin},
  title =	 {{A Stall-Aware Warp Scheduling for Dynamically
                  Optimizing Thread-level Parallelism in GPGPUs}},
  booktitle =	 ICS,
  year =	 2015,
  pages =	 {15--24},
}

@inproceedings{simd_sched_gra,
  author =	 {Hao, Benjamin and Pearson, David},
  title =	 {{Instruction Scheduling and Global Register
                  Allocation for SIMD Multiprocessors}},
  booktitle =	 {{2nd Int'l Workshop on Parallel Algorithms for
                  Irregularly Structured Problems}},
  year =	 1995,
  pages =	 {81--86},
}

@inproceedings{owl,
  author =	 {Jog, Adwait and Kayiran, Onur and Chidambaram
                  Nachiappan, Nachiappan and Mishra, Asit K. and
                  Kandemir, Mahmut T. and Mutlu, Onur and Iyer,
                  Ravishankar and Das, Chita R.},
  title =	 {{OWL: Cooperative Thread Array Aware Scheduling
                  Techniques for Improving GPGPU Performance}},
  booktitle =	 {{Proceedings of the International Conference on
                  Architectural Support for Programming Languages and
                  Operation Systems}},
  series =	 {ASPLOS},
  year =	 2013,
}

@inproceedings{micro_2_lvl,
  author =	 {Narasiman, Veynu and Shebanow, Michael and Lee,
                  Chang Joo and Miftakhutdinov, Rustam and Mutlu, Onur
                  and Patt, Yale N.},
  title =	 "{Improving GPU Performance via Large Warps and
                  Two-Level Warp Scheduling}",
  booktitle =	 MICRO,
  year =	 2011,
  month =	 {December},
  pages =	 {308--317}
}

@inproceedings{pats,
  author =	 {Xu, Qiumin and Annavaram, Murali},
  title =	 {{PATS: Pattern Aware Scheduling and Power Gating for
                  GPGPUs}},
  booktitle =	 PACT,
  year =	 2014,
  pages =	 {225--236},
}

@INPROCEEDINGS{LiuYang2015-saws,
  author =	 {J. {Liu} and J. {Yang} and R. {Melhem}},
  booktitle =	 {{Proceedings of the 48th Annual IEEE/ACM
                  International Symposium on Microarchitecture}},
  series =	 {MICRO},
  title =	 {{SAWS: Synchronization aware GPGPU warp scheduling
                  for multiple independent warp schedulers}},
  year =	 2015,
  pages =	 {383-394},
}

@inproceedings{ChenYang2017-prophet,
  author =	 {Chen, Quan and Yang, Hailong and Guo, Minyi and
                  Kannan, Ram Srivatsa and Mars, Jason and Tang,
                  Lingjia},
  title =	 {{Prophet: Precise QoS Prediction on Non-Preemptive
                  Accelerators to Improve Utilization in
                  Warehouse-Scale Computers}},
  booktitle =	 {{Proceedings of the Twenty-Second International
                  Conference on Architectural Support for Programming
                  Languages and Operating Systems}},
  series =	 {ASPLOS '17},
  year =	 2017,
  isbn =	 {978-1-4503-4465-4},
  location =	 {Xi'an, China},
  pages =	 {17--32},
  numpages =	 16,
  url =		 {http://doi.acm.org/10.1145/3037697.3037700},
  doi =		 {10.1145/3037697.3037700},
  acmid =	 3037700,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {non-preemptive accelerators, quality-of-service
                  prediction, warehouse-scale computers},
}

@inproceedings{ChenYang2016-baymax,
  author =	 {Chen, Quan and Yang, Hailong and Mars, Jason and
                  Tang, Lingjia},
  title =	 {{Baymax: QoS Awareness and Increased Utilization for
                  Non-Preemptive Accelerators in Warehouse Scale
                  Computers}},
  booktitle =	 {{Proceedings of the Twenty-First International
                  Conference on Architectural Support for Programming
                  Languages and Operating Systems}},
  series =	 {ASPLOS '16},
  year =	 2016,
  isbn =	 {978-1-4503-4091-5},
  location =	 {Atlanta, Georgia, USA},
  pages =	 {681--696},
  numpages =	 16,
  url =		 {http://doi.acm.org/10.1145/2872362.2872368},
  doi =		 {10.1145/2872362.2872368},
  acmid =	 2872368,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {non-preemptive accelerators, quality of service,
                  scheduling, warehouse scale computers},
}

@inproceedings{HolmesMawhirter2019-grnn,
  author =	 {Holmes, Connor and Mawhirter, Daniel and He, Yuxiong
                  and Yan, Feng and Wu, Bo},
  title =	 {GRNN: Low-Latency and Scalable RNN Inference on
                  GPUs},
  booktitle =	 {Proceedings of the Fourteenth EuroSys Conference
                  2019},
  series =	 {EuroSys '19},
  year =	 2019,
  isbn =	 {978-1-4503-6281-8},
  location =	 {Dresden, Germany},
  pages =	 {41:1--41:16},
  articleno =	 41,
  numpages =	 16,
  url =		 {http://doi.acm.org/10.1145/3302424.3303949},
  doi =		 {10.1145/3302424.3303949},
  acmid =	 3303949,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {GPUs, deep learning inference, recurrent neural
                  networks},
}

@INPROCEEDINGS{gpusync,
  author =	 {G. A. Elliott and B. C. Ward and J. H. Anderson},
  booktitle =	 {2013 IEEE 34th Real-Time Systems Symposium},
  title =	 {GPUSync: A Framework for Real-Time GPU Management},
  year =	 2013,
  pages =	 {33-44},
  keywords =	 {graphics processing units;processor
                  scheduling;real-time systems;GPUSync;real-time GPU
                  management;graphics processing unit
                  management;multiGPU multicore real-time
                  systems;static priority CPU scheduling;dynamic
                  priority CPU scheduling;GPU allocation;migration
                  cost predictors;GPU-related interrupt;worker
                  threads;sporadic task model;GPU drivers;Graphics
                  processing units;Engines;Real-time systems;Resource
                  management;Memory
                  management;Kernel;Protocols;GPGPU;real time
                  systems;schedulability;operating systems},
  doi =		 {10.1109/RTSS.2013.12},
  ISSN =	 {1052-8725},
  month =	 {Dec},
}

@inproceedings {KatoLakshmanan2011-timeGraph,
  author =	 {Kato, Shinpei and Lakshmanan, Karthik and Rajkumar,
                  Ragunathan and Ishikawa, Yutaka},
  title =	 {{TimeGraph: GPU Scheduling for Real-Time
                  Multi-Tasking Environments}},
  booktitle =	 {{USENIX Annual Technical Conference}},
  series =	 {USENIX ATC},
  year =	 2011,
  address =	 {Portland, OR},
  url =
                  {https://www.usenix.org/conference/usenixatc11/timegraph-gpu-scheduling-real-time-multi-tasking-environments},
  publisher =	 {{USENIX} Association},
  month =	 jun,
}

@INPROCEEDINGS{GutierrezBeckmann2018-gem5GPU,
  author =	 {Gutierrez, Anthony and Beckmann, Bradford M. and
                  Dutu, Alexandru and Gross, Joseph and LeBeane,
                  Michael and Kalamatianos, John and Kayiran, Onur and
                  Poremba, Matthew and Potter, Brandon and Puthoor,
                  Sooraj and Sinclair, Matthew D. and Wyse, Michael
                  and Yin, Jieming and Zhang, Xianwei and Jain, Akshay
                  and Rogers, Timothy},
  booktitle =	 {{24th IEEE International Symposium on High
                  Performance Computer Architecture}},
  series =	 {HPCA},
  title =	 {{Lost in Abstraction: Pitfalls of Analyzing GPUs at
                  the Intermediate Language Level}},
  year =	 2018,
  pages =	 {608-619},
  keywords =	 {embedded systems;graphics processing
                  units;instruction sets;microprocessor
                  chips;optimising compilers;parallel
                  architectures;program compilers;intermediate
                  language level;target GPU hardware;GPU
                  microarchitecture simulators;GPU microarchitecture
                  models;dynamic instruction count;Kernel;Graphics
                  processing units;Registers;Hardware;Computer
                  architecture;Microarchitecture;Runtime;ABI;GPU;Intermediate
                  Language;Intermediate Representation;ISA;Simulation},
  doi =		 {10.1109/HPCA.2018.00058},
  ISSN =	 {2378-203X},
  month =	 {Feb},
}

@misc{ba2016layer,
  title =	 {{Layer Normalization}},
  author =	 {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton,
                  Geoffrey E.},
  year =	 2016,
  eprint =	 {1607.06450},
  howpublished ={arXiv},
  primaryClass = {stat.ML}
}

@inproceedings{FowersOvtcharov2018-brainwave,
  author =	 {Fowers, Jeremy and Ovtcharov, Kalin and Papamichael,
                  Michael and Massengill, Todd and Liu, Ming and Lo,
                  Daniel and Alkalay, Shlomi and Haselman, Michael and
                  Adams, Logan and Ghandi, Mahdi and Heil, Stephen and
                  Patel, Prerak and Sapek, Adam and Weisz, Gabriel and
                  Woods, Lisa and Lanka, Sitaram and Reinhardt, Steven
                  K. and Caulfield, Adrian M. and Chung, Eric S. and
                  Burger, Doug},
  title =	 {{A Configurable Cloud-scale DNN Processor for
                  Real-time AI}},
  booktitle =	 {{Proceedings of the 45th Annual International
                  Symposium on Computer Architecture}},
  series =	 {{ISCA}},
  year =	 2018,
  isbn =	 {978-1-5386-5984-7},
  location =	 {Los Angeles, California},
  pages =	 {1--14},
  numpages =	 14,
  url =		 {https://doi.org/10.1109/ISCA.2018.00012},
  doi =		 {10.1109/ISCA.2018.00012},
  acmid =	 3276541,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  keywords =	 {accelerator architectures, field programmable gate
                  arrays, neural network hardware},
}

@inproceedings{YuLukefahr17-scalpel,
  author =	 {Yu, Jiecao and Lukefahr, Andrew and Palframan, David
                  and Dasika, Ganesh and Das, Reetuparna and Mahlke,
                  Scott},
  title =	 {{Scalpel: Customizing DNN Pruning to the Underlying
                  Hardware Parallelism}},
  booktitle =	 {{Proceedings of the 44th Annual International
                  Symposium on Computer Architecture}},
  series =	 {ISCA '17},
  year =	 2017,
  isbn =	 {978-1-4503-4892-8},
  location =	 {Toronto, ON, Canada},
  pages =	 {548--560},
  numpages =	 13,
  url =		 {http://doi.acm.org/10.1145/3079856.3080215},
  doi =		 {10.1145/3079856.3080215},
  acmid =	 3080215,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {hardware parallelism, multiple data, neural network
                  pruning, single instruction},
}

@article{mao2017exploring,
  title =	 {{Exploring the Regularity of Sparse Structure in
                  Convolutional Neural Networks}},
  author =	 {Mao, Huizi and Han, Song and Pool, Jeff and Li,
                  Wenshuo and Liu, Xingyu and Wang, Yu and Dally,
                  William J},
  journal =	 {arXiv preprint arXiv:1705.08922},
  year =	 2017
}

@inproceedings{HanKang2017-ese,
  author =	 {Han, Song and Kang, Junlong and Mao, Huizi and Hu,
                  Yiming and Li, Xin and Li, Yubin and Xie, Dongliang
                  and Luo, Hong and Yao, Song and Wang, Yu and Yang,
                  Huazhong and Dally, William (Bill) J.},
  title =	 {{ESE: Efficient Speech Recognition Engine with
                  Sparse LSTM on FPGA}},
  booktitle =	 {Proceedings of the 2017 ACM/SIGDA International
                  Symposium on Field-Programmable Gate Arrays},
  series =	 {FPGA '17},
  year =	 2017
}

@inproceedings{Zhu2018-sparsePRNN,
  author =	 {Feiwen Zhu and Jeff Pool and Michael Andersch and
                  Jeremy Appleyard and Fung Xie},
  title =	 {{Sparse Persistent RNNs: Squeezing Large Recurrent
                  Networks On-Chip}},
  booktitle =	 {{Proceedings of 6th International Conference on
                  Learning Representations}},
  series =	 {{ICLR}},
  year =	 2018,
}

@article{Narang2017-sparseRNNs,
  author =	 {Sharan Narang and Gregory F. Diamos and Shubho
                  Sengupta and Erich Elsen},
  title =	 {{Exploring Sparsity in Recurrent Neural Networks}},
  journal =	 {CoRR},
  volume =	 {abs/1704.05119},
  year =	 2017,
  url =		 {http://arxiv.org/abs/1704.05119},
}

@inproceedings{Parashar17-scnn,
  author =	 {Parashar, Angshuman and Rhu, Minsoo and Mukkara,
                  Anurag and Puglielli, Antonio and Venkatesan,
                  Rangharajan and Khailany, Brucek and Emer, Joel and
                  Keckler, Stephen W. and Dally, William J.},
  title =	 {{SCNN: An Accelerator for Compressed-sparse
                  Convolutional Neural Networks}},
  booktitle =	 {{Proceedings of the 44th Annual International
                  Symposium on Computer Architecture}},
  series =	 {ISCA},
  year =	 2017,
  isbn =	 {978-1-4503-4892-8},
  location =	 {Toronto, ON, Canada},
  pages =	 {27--40},
  numpages =	 14,
  url =		 {http://doi.acm.org/10.1145/3079856.3080254},
  doi =		 {10.1145/3079856.3080254},
  acmid =	 3080254,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Convolutional neural networks, accelerator
                  architecture},
}

@inproceedings{wagstaff2001constrained,
  title =	 {{Constrained K-means Clustering with Background
                  Knowledge}},
  author =	 {Wagstaff, Kiri and Cardie, Claire and Rogers, Seth
                  and Schr{\"o}dl, Stefan and others},
  booktitle =	 {Icml},
  volume =	 1,
  pages =	 {577--584},
  year =	 2001
}

@inproceedings{bottou1995convergence,
  title =	 {{Convergence Properties of the K-means Algorithms}},
  author =	 {Bottou, Leon and Bengio, Yoshua},
  booktitle =	 {Advances in neural information processing systems},
  pages =	 {585--592},
  year =	 1995
}

@inproceedings{ZhangRajbhandari2018-deepCPU,
  author =	 {Minjia Zhang and Samyam Rajbhandari and Wenhan Wang
                  and Yuxiong He},
  title =	 {DeepCPU: Serving RNN-based Deep Learning Models 10x
                  Faster},
  booktitle =	 {{2018 USENIX Annual Technical Conference}},
  series =	 {{USENIX ATC 18}},
  year =	 2018,
  isbn =	 {978-1-931971-44-7},
  address =	 {Boston, MA},
  pages =	 {951--965},
  url =
                  {https://www.usenix.org/conference/atc18/presentation/zhang-minjia},
  publisher =	 {{USENIX} Association},
}

@INPROCEEDINGS{AdolfRama2016-fathom,
  author =	 {Adolf, Robert and Rama, Saketh and Reagen, Brandon and Wei, Gu-yeon and Brooks, David},
  booktitle =	 {{IEEE International Symposium on Workload Characterization}},
  series =	 {IISWC},
  title =	 {{Fathom: Reference Workloads for Modern Deep Learning Methods}},
  year =	 2016,
  pages =	 {1-10},
  keywords =	 {inference mechanisms;learning (artificial
                  intelligence);neural nets;parallel
                  programming;Facebook AI research group;Fathom
                  workload behavior analysis;TensorFlow deep learning
                  framework;application domain;application-level
                  modeling tool;archetypal deep learning
                  workload;artificial intelligence;computational
                  power;deep convolutional neural network;exotic
                  memory network;inference;modern deep learning
                  methods;parallel scalability;training;Analytical
                  models;Computational modeling;Computer
                  architecture;Hardware;Libraries;Machine
                  learning;Training},
  doi =		 {10.1109/IISWC.2016.7581275},
  month =	 {9},
}

@inproceedings{DongKaeli2017-dnnmark,
  author =	 {Dong, Shi and Kaeli, David},
  title =	 {{DNNMark: A Deep Neural Network Benchmark Suite for
                  GPUs}},
  booktitle =	 {{Proceedings of the General Purpose GPUs}},
  series =	 {{GPGPU}},
  year =	 2017,
  isbn =	 {978-1-4503-4915-4},
  location =	 {Austin, TX, USA},
  pages =	 {63--72},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/3038228.3038239},
  doi =		 {10.1145/3038228.3038239},
  acmid =	 3038239,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Benchmark Suite, Deep Neural Network, GPU, cuDNN},
}

@inproceedings{Armitai2016,
  title =	 {{ML-Bench 1.0 Constructing and Analyzing a
                  Machine-Learning Benchmark}},
  author =	 {Armon, Amitai},
  year =	 2016,
  booktitle =	 {{Intel Machine Learning Summit}},
  howpublished =
                  {\url{https://software.intel.com/en-us/videos/l-bench-10-constructing-and-analyzing-a-machine-learning-benchmark}},
}

@inproceedings{jeon2019atc,
  title =	 {Analysis of large-scale multi-tenant GPU clusters
                  for DNN training workloads},
  author =	 {Jeon, Myeongjae and Venkataraman, Shivaram and
                  Phanishayee, Amar and Qian, Junjie and Xiao, Wencong
                  and Yang, Fan},
  booktitle =	 {2019 USENIX Annual Technical Conference},
  pages =	 {947--960},
  year =	 2019
}

%SP: for EW ops being negligible

@inproceedings{he2020newton,
  title =	 {Newton: A DRAM-maker’s accelerator-in-memory (AiM)
                  architecture for machine learning},
  author =	 {He, Mingxuan and Song, Choungki and Kim, Ilkon and
                  Jeong, Chunseok and Kim, Seho and Park, Il and
                  Thottethodi, Mithuna and Vijaykumar, TN},
  booktitle =	 {2020 53rd Annual IEEE/ACM International Symposium on
                  Microarchitecture (MICRO)},
  pages =	 {372--385},
  year =	 2020,
  organization = {IEEE}
}

@inproceedings{qin2020sigma,
  title =	 {Sigma: A sparse and irregular gemm accelerator with
                  flexible interconnects for dnn training},
  author =	 {Qin, Eric and Samajdar, Ananda and Kwon, Hyoukjun
                  and Nadella, Vineet and Srinivasan, Sudarshan and
                  Das, Dipankar and Kaul, Bharat and Krishna, Tushar},
  booktitle =	 {{26th IEEE International Symposium on High
                  Performance Computer Architecture}},
  series =	 {HPCA},
  pages =	 {58--70},
  year =	 2020,
  organization = {IEEE}
}

%SP: echeckpointing

@misc{chen2016training,
  title =	 {Training Deep Nets with Sublinear Memory Cost},
  author =	 {Tianqi Chen and Bing Xu and Chiyuan Zhang and Carlos
                  Guestrin},
  year =	 2016,
  eprint =	 {1604.06174},
  howpublished ={arXiv},
  primaryClass = {cs.LG}
}

%SP: Mixed Precision

@misc{micikevicius2018mixed,
  title =	 {{Mixed Precision Training}},
  author =	 {Paulius Micikevicius and Sharan Narang and Jonah
                  Alben and Gregory Diamos and Erich Elsen and David
                  Garcia and Boris Ginsburg and Michael Houston and
                  Oleksii Kuchaiev and Ganesh Venkatesh and Hao Wu},
  year =	 2018,
  eprint =	 {1710.03740},
  howpublished ={arXiv},
  primaryClass = {cs.AI}
}

@misc{ott2018scaling,
  title =	 {{Scaling Neural Machine Translation}},
  author =	 {Myle Ott and Sergey Edunov and David Grangier and
                  Michael Auli},
  year =	 2018,
  eprint =	 {1806.00187},
  howpublished ={arXiv},
  primaryClass = {cs.CL}
}

@inproceedings{wang2018training,
  title =	 {{Training Deep Neural Networks with 8-bit Floating
                  Point Numbers}},
  author =	 {Wang, Naigang and Choi, Jungwook and Brand, Daniel
                  and Chen, Chia-Yu and Gopalakrishnan, Kailash},
  booktitle =	 {{Proceedings of the 32nd International Conference on
                  Neural Information Processing Systems}},
  series =	 {NeurIPS},
  pages =	 {7686--7695},
  year =	 2018
}

@misc{mig,
  title =	 {{NVIDIA Multi-Instance GPU (MIG)}},
  author =	 {{NVIDIA Corp.}},
  howpublished = { \url{https://docs.nvidia.com/cuda/mig/index.html} },
  year =	 2021,
}

@misc{mxgpu,
  title =	 {{AMD MxGPU and VMware}},
  howpublished =
                  {\url{https://drivers.amd.com/relnotes/amd_mxgpu_deploymentguide_vmware.pdf}},
  year =	 2020,
  author =	 {{Advanced Micro Devices, Inc.}},
}

@inproceedings{kwon2021heterogeneous,
  title =	 {{Heterogeneous Dataflow Accelerators for Multi-DNN
                  Workloads}},
  author =	 {Kwon, Hyoukjun and Lai, Liangzhen and Pellauer,
                  Michael and Krishna, Tushar and Chen, Yu-Hsin and
                  Chandra, Vikas},
  booktitle =	 {{27th IEEE International Symposium on High
                  Performance Computer Architecture}},
  series =	 {HPCA},
  pages =	 {71--83},
  year =	 2021,
  organization = {IEEE}
}

@INPROCEEDINGS{NaffzigerBeck2021-amdChiplets,
  author =	 {Naffziger, Samuel and Beck, Noah and Burd, Thomas
                  and Lepak, Kevin and Loh, Gabriel H. and Subramony,
                  Mahesh and White, Sean},
  booktitle =	 {{ACM/IEEE 48th Annual International Symposium on
                  Computer Architecture}},
  series =	 {ISCA},
  title =	 {{Pioneering Chiplet Technology and Design for the
                  AMD EPYC™ and Ryzen™ Processor Families : Industrial
                  Product}},
  year =	 2021,
  pages =	 {57-70},
  doi =		 {10.1109/ISCA52012.2021.00014}
}

@article{jhurani2015gemm,
  title =	 {{A GEMM interface and implementation on NVIDIA GPUs
                  for multiple small matrices}},
  author =	 {Jhurani, Chetan and Mullowney, Paul},
  journal =	 {Journal of Parallel and Distributed Computing},
  volume =	 75,
  pages =	 {133--140},
  year =	 2015,
  publisher =	 {Elsevier}
}

@inproceedings{abdelfattah2016performance,
  title =	 {{Performance, design, and autotuning of batched GEMM
                  for GPUs}},
  author =	 {Abdelfattah, Ahmad and Haidar, Azzam and Tomov,
                  Stanimire and Dongarra, Jack},
  booktitle =	 {{International Conference on High Performance
                  Computing}},
  pages =	 {21--38},
  year =	 2016,
  organization = {Springer}
}

@INPROCEEDINGS{ElHajjGomezLuna2016-klap,
  author =	 {El Hajj, Izzat and Gomez-Luna, Juan and Li, Cheng
                  and Chang, Li-Wen and Milojicic, Dejan and Hwu,
                  Wen-mei},
  booktitle =	 {{49th Annual IEEE/ACM International Symposium on
                  Microarchitecture}},
  series =	 {MICRO},
  title =	 {{KLAP: Kernel launch aggregation and promotion for
                  optimizing dynamic parallelism}},
  year =	 2016,
  pages =	 {1-12},
  doi =		 {10.1109/MICRO.2016.7783716}
}

@inproceedings{chasapis2016runtime,
  author =	 {Chasapis, Dimitrios and Casas, Marc and Moret\'{o},
                  Miquel and Schulz, Martin and Ayguad\'{e}, Eduard
                  and Labarta, Jesus and Valero, Mateo},
  title =	 {{Runtime-Guided Mitigation of Manufacturing
                  Variability in Power-Constrained Multi-Socket NUMA
                  Nodes}},
  year =	 2016,
  articleno =	 5,
  numpages =	 12,
  location =	 {Istanbul, Turkey},
  booktitle =	 {{Proceedings of the 2016 International Conference on
                  Supercomputing}},
  series =	 {ICS '16}
}

@inproceedings{InadomiPatki2015-scVar,
  author =	 {Inadomi, Yuichi and Patki, Tapasya and Inoue, Koji
                  and Aoyagi, Mutsumi and Rountree, Barry and Schulz,
                  Martin and Lowenthal, David and Wada, Yasutaka and
                  Fukazawa, Keiichiro and Ueda, Masatsugu and Kondo,
                  Masaaki and Miyoshi, Ikuo},
  title =	 {{Analyzing and Mitigating the Impact of
                  Manufacturing Variability in Power-Constrained
                  Supercomputing}},
  year =	 2015,
  isbn =	 9781450337236,
  url =		 {https://doi.org/10.1145/2807591.2807638},
  doi =		 {10.1145/2807591.2807638},
  abstract =	 {A key challenge in next-generation supercomputing is
                  to effectively schedule limited power
                  resources. Modern processors suffer from
                  increasingly large power variations due to the chip
                  manufacturing process. These variations lead to
                  power inhomogeneity in current systems and manifest
                  into performance inhomogeneity in power constrained
                  environments, drastically limiting supercomputing
                  performance. We present a first-of-its-kind study on
                  manufacturing variability on four production HPC
                  systems spanning four microarchitectures, analyze
                  its impact on HPC applications, and propose a novel
                  variation-aware power budgeting scheme to maximize
                  effective application performance. Our low-cost and
                  scalable budgeting algorithm strives to achieve
                  performance homogeneity under a power constraint by
                  deriving application-specific, module-level power
                  allocations. Experimental results using a 1,920
                  socket system show up to 5.4X speedup, with an
                  average speedup of 1.8X across all benchmarks when
                  compared to a variation-unaware power allocation
                  scheme.},
  articleno =	 78,
  numpages =	 12,
  keywords =	 {power-constrained HPC, performance modeling},
  booktitle =	 {{Proceedings of the International Conference for
                  High Performance Computing, Networking, Storage and
                  Analysis}},
  series =	 {SC}
}
%  publisher = {Association for Computing Machinery},
%  address = {New York, NY, USA},
%  location = {Austin, Texas},

@inproceedings{DasOzdemir2007-processVar,
  author =	 {Das, Abhishek and Ozdemir, Serkan and Memik, Gokhan
                  and Zambreno, Joseph and Choudhary, Alok},
  title =	 {{Mitigating the Effects of Process Variations:
                  Architectural Approaches for Improving Batch
                  Performance}},
  booktitle =	 {{Workshop on Architectural Support for Gigascale
                  Integration}},
  series =	 {ASGI},
  year =	 2007,
}

@inproceedings{DuplyakinRicci2019-cloudlab,
  author =	 {Duplyakin, Dmitry and Ricci, Robert and Maricq,
                  Aleksander and Wong, Gary and Duerig, Jonathon and
                  Eide, Eric and Stoller, Leigh and Hibler, Mike and
                  Johnson, David and Webb, Kirk and Akella, Aditya and
                  Wang, Kuangching and Ricart, Glenn and Landweber,
                  Larry and Elliott, Chip and Zink, Michael and
                  Cecchet, Emmanuel and Kar, Snigdhaswin and Mishra,
                  Prabodh},
  title =	 {{The Design and Operation of Cloudlab}},
  year =	 2019,
  isbn =	 9781939133038,
  abstract =	 {Given the highly empirical nature of research in
                  cloud computing, networked systems, and related
                  fields, testbeds play an important role in the
                  research ecosystem. In this paper, we cover one such
                  facility, CloudLab, which supports systems research
                  by providing raw access to programmable hardware,
                  enabling research at large scales, and creating a
                  shared platform for repeatable research.We present
                  our experiences designing CloudLab and operating it
                  for four years, serving nearly 4,000 users who have
                  run over 79,000 experiments on 2,250 servers,
                  switches, and other pieces of datacenter
                  equipment. From this experience, we draw lessons
                  organized around two themes. The first set comes
                  from analysis of data regarding the use of CloudLab:
                  how users interact with it, what they use it for,
                  and the implications for facility design and
                  operation. Our second set of lessons comes from
                  looking at the ways that algorithms used "under the
                  hood," such as resource allocation, have important--
                  and sometimes unexpected--effects on user experience
                  and behavior. These lessons can be of value to the
                  designers and operators of IaaS facilities in
                  general, systems testbeds in particular, and users
                  who have a stake in understanding how these systems
                  are built.},
  booktitle =	 {{Proceedings of the 2019 USENIX Conference on Usenix
                  Annual Technical Conference}},
  series =	 {USENIX ATC},
  pages =	 {1–14},
  numpages =	 14,
}
%  location = {Renton, WA, USA},
%  publisher = {USENIX Association},

@misc{tacc,
  author =	 {TACC},
  title =	 {{Texas Advanced Computing Center}},
  howpublished = {\url{https://www.tacc.utexas.edu/}},
  year =	 2021,
}

@inproceedings{ChasapisMoreto2019-powerEfficJobSched,
  author =	 {Chasapis, Dimitrios and Moret\'{o}, Miquel and
                  Schulz, Martin and Rountree, Barry and Valero, Mateo
                  and Casas, Marc},
  title =	 {{Power Efficient Job Scheduling by Predicting the
                  Impact of Processor Manufacturing Variability}},
  year =	 2019,
  isbn =	 9781450360791,
  url =		 {https://doi.org/10.1145/3330345.3330372},
  doi =		 {10.1145/3330345.3330372},
  abstract =	 {Modern CPUs suffer from performance and power
                  consumption variability due to the manufacturing
                  process. As a result, systems that do not consider
                  such variability caused by manufacturing issues lead
                  to performance degradations and wasted power. In
                  order to avoid such negative impact, users and
                  system administrators must actively counteract any
                  manufacturing variability.In this work we show that
                  parallel systems benefit from taking into account
                  the consequences of manufacturing variability when
                  making scheduling decisions at the job scheduler
                  level. We also show that it is possible to predict
                  the impact of this variability on specific
                  applications by using variability-aware power
                  prediction models. Based on these power models, we
                  propose two job scheduling policies that consider
                  the effects of manufacturing variability for each
                  application and that ensure that power consumption
                  stays under a system-wide power budget. We evaluate
                  our policies under different power budgets and
                  traffic scenarios, consisting of both single- and
                  multi-node parallel applications, utilizing up to
                  4096 cores in total. We demonstrate that they
                  decrease job turnaround time, compared to
                  contemporary scheduling policies used on production
                  clusters, up to 31\% while saving up to 5.5\%
                  energy.},
  booktitle =	 {{Proceedings of the ACM International Conference on
                  Supercomputing}},
  series =	 {ICS '19},
  pages =	 {296–307},
  numpages =	 12,
  keywords =	 {power prediction, job scheduling, manufacturing
                  variability, HPC, energy efficient},
}
%  publisher = {Association for Computing Machinery},
%  address = {New York, NY, USA},
%  location = {Phoenix, Arizona},

@INPROCEEDINGS{GeVogt2013-dvfsKepler,
  author =	 {R. {Ge} and R. {Vogt} and J. {Majumder} and
                  A. {Alam} and M. {Burtscher} and Z. {Zong}},
  title =	 {{Effects of Dynamic Voltage and Frequency Scaling on
                  a K20 GPU}},
  year =	 2013,
  pages =	 {826-833},
  doi =		 {10.1109/ICPP.2013.98},
  booktitle =	 {{42nd International Conference on Parallel
                  Processing}},
  series =	 {ICPP},
}

@INPROCEEDINGS{CoplinBurtscher2016-gpgpuPower,
  author =	 {J. Coplin and M. Burtscher},
  booktitle =	 {{IEEE International Parallel and Distributed
                  Processing Symposium Workshops}},
  series =	 {IPDPSW},
  title =	 {{Energy, Power, and Performance Characterization of
                  GPGPU Benchmark Programs}},
  year =	 2016,
  pages =	 {1190-1199},
  keywords =	 {graphics processing units;benchmark
                  testing;instruction sets;runtime;energy
                  efficiency;hardware;power measurement},
  doi =		 {10.1109/IPDPSW.2016.164},
  url =
                  {https://doi.ieeecomputersociety.org/10.1109/IPDPSW.2016.164},
  month =	 {May}
} 
%  publisher = {IEEE Computer Society},
%  address = {Los Alamitos, CA, USA},

@misc{cublas,
  title =	 {{cuBLAS}},
  author =	 {NVIDIA},
  howpublished = {\url{https://developer.nvidia.com/cublas}},
  year =	 2021,
}

@misc{gpu-burn,
  title =	 {{Multi-GPU CUDA stress test}},
  author =	 {{Timonen, Ville}},
  howpublished = {\url{http://wili.cc/blog/gpu-burn.html}},
  year =	 2020,
}

@misc{nvprof,
  title =	 {{Profiler User's Guide}},
  author =	 {{NVIDIA Corp}},
  year =	 2018,
  howpublished =
                  {\url{https://docs.nvidia.com/cuda/profiler-users-guide/index.html}},
}

@misc{v100-tc,
  author =	 {{NVIDIA}},
  title =	 {{NVIDIA V100 Tensor Core GPU}},
  year =	 2020,
  howpublished =
                  {\url{https://images.nvidia.com/content/technologies/volta/pdf/volta-v100-datasheet-update-us-1165301-r5.pdf}},
}

@misc{coral2,
  author =	 {{Lawrence Livermore National Labs}},
  title =	 {{CORAL-2 Benchmarks}},
  howpublished = {\url{https://asc.llnl.gov/coral-2-benchmarks}},
  year =	 2020,
}

@misc{olcf6-bmks,
  author =	 {{Oak Ridge National Labs}},
  year =	 2024,
  title =	 {{OLCF-6 Benchmarks}},
  howpublished =
                  {\url{https://www.olcf.ornl.gov/draft-olcf-6-technical-requirements/benchmarks/}},
}

@misc{summit-layout,
  title =	 {{Job Step Viewer - Summit ORNL}},
  howpublished =
                  {\url{https://jobstepviewer.olcf.ornl.gov/summit/871957-1}},
  key =		 {summit}
}

@INPROCEEDINGS{BaruahShivdikar2021-gnnMark,
  author =	 {Baruah, Trinayan and Shivdikar, Kaustubh and Dong,
                  Shi and Sun, Yifan and Mojumder, Saiful A and Jung,
                  Kihoon and Abellán, José L. and Ukidave, Yash and
                  Joshi, Ajay and Kim, John and Kaeli, David},
  booktitle =	 {{IEEE International Symposium on Performance
                  Analysis of Systems and Software}},
  series =	 {ISPASS},
  title =	 {{GNNMark: A Benchmark Suite to Characterize Graph
                  Neural Network Training on GPUs}},
  year =	 2021,
  pages =	 {13-23},
  keywords =	 {Training;Machine learning
                  algorithms;Scalability;Software
                  performance;Benchmark testing;Hardware;Graph neural
                  networks;graphs;benchmarks;GNN training;GPUs},
  doi =		 {10.1109/ISPASS51385.2021.00013}
}

@inproceedings{ostrouchov2020gpulifetimes,
  author =	 {Ostrouchov, George and Maxwell, Don and Ashraf,
                  Rizwan A. and Engelmann, Christian and Shankar,
                  Mallikarjun and Rogers, James H.},
  title =	 {{GPU Lifetimes on Titan Supercomputer: Survival
                  Analysis and Reliability}},
  year =	 2020,
  publisher =	 {IEEE Press},
  booktitle =	 {{Proceedings of the International Conference for
                  High Performance Computing, Networking, Storage and
                  Analysis}},
  articleno =	 41,
  numpages =	 14,
  location =	 {Atlanta, Georgia},
  series =	 {SC '20}
}

@misc{gpu-throttling,
  title =	 {{What Is GPU Throttling And How To Fix It}},
  howpublished =
                  {\url{https://www.thesharedweb.com/gpu-throttling-and-how-to-fix-it}},
  key =		 {gpu-throttling},
}

@article{ZhengTiwari2018-ecoRNN,
  title =	 {{EcoRNN: Efficient Computing of LSTM RNN Training on
                  GPUs}},
  author =	 {Zheng, Bojian and Tiwari, Abhishek and Vijaykumar,
                  Nandita and Pekhimenko, Gennady},
  journal =	 {arXiv preprint arXiv:1805.08899},
  year =	 2018
}

@inproceedings{ZhuAkrout2018-tbd,
  title =	 {{TBD: Benchmarking and Analyzing Deep Neural Network
                  Training}},
  author =	 {Zhu, Hongyu and Akrout, Mohamed and Zheng, Bojian
                  and Pelegris, Andrew and Phanishayee, Amar and
                  Schroeder, Bianca and Pekhimenko, Gennady},
  booktitle =	 {{IEEE International Symposium on Workload
                  Characterization}},
  year =	 2018,
  month =	 {October},
  series =	 {{IISWC}},
}

@inproceedings{Sherwood02,
  author =	 {Sherwood, Timothy and Perelman, Erez and Hamerly,
                  Greg and Calder, Brad},
  title =	 {{Automatically Characterizing Large Scale Program
                  Behavior}},
  booktitle =	 {{Proceedings of the 10th International Conference on
                  Architectural Support for Programming Languages and
                  Operating Systems}},
  series =	 {ASPLOS X},
  year =	 2002,
}

@inproceedings{sherwood01,
  title =	 {Basic block distribution analysis to find periodic
                  behavior and simulation points in applications},
  author =	 {Sherwood, Timothy and Perelman, Erez and Calder,
                  Brad},
  booktitle =	 {Proceedings 2001 International Conference on
                  Parallel Architectures and Compilation Techniques},
  pages =	 {3--14},
  year =	 2001,
  organization = {IEEE}
}

@inproceedings{LymLee2019-delta,
  title =	 {DeLTA: GPU Performance Model for Deep Learning
                  Applications with In-depth Memory System Traffic
                  Analysis},
  author =	 {Lym, Sangkug and Lee, Donghyuk and O'Connor, Mike
                  and Chatterjee, Niladrish and Erez, Mattan},
  booktitle =	 {2019 IEEE International Symposium on Performance
                  Analysis of Systems and Software (ISPASS)},
  pages =	 {293--303},
  year =	 2019,
  organization = {IEEE}
}

@inproceedings{ParasharRaina2019-timeloop,
  title =	 {Timeloop: A Systematic Approach to DNN Accelerator
                  Evaluation},
  author =	 {Parashar, Angshuman and Raina, Priyanka and Shao,
                  Yakun Sophia and Chen, Yu-Hsin and Ying, Victor A
                  and Mukkara, Anurag and Venkatesan, Rangharajan and
                  Khailany, Brucek and Keckler, Stephen W and Emer,
                  Joel},
  booktitle =	 {{IEEE International Symposium on Performance
                  Analysis of Systems and Software}},
  series =	 {ISPASS},
  pages =	 {304--315},
  year =	 2019,
  organization = {IEEE}
}

@inproceedings{QiaoChoe2021-pollux,
  author =	 {Aurick Qiao and Sang Keun Choe and Suhas Jayaram
                  Subramanya and Willie Neiswanger and Qirong Ho and
                  Hao Zhang and Gregory R. Ganger and Eric P. Xing},
  title =	 {{Pollux: Co-adaptive Cluster Scheduling for
                  Goodput-Optimized Deep Learning}},
  booktitle =	 {{15th {USENIX} Symposium on Operating Systems Design
                  and Implementation}},
  series =	 {OSDI},
  year =	 2021,
  isbn =	 {978-1-939133-22-9},
  pages =	 {1--18},
  url =
                  {https://www.usenix.org/conference/osdi21/presentation/qiao},
  publisher =	 {{USENIX} Association},
  month =	 jul,
}

@article{AlsopNa2021-fcs,
  title =	 {{A Case for Fine-grain Coherence Specialization in
                  Heterogeneous Systems}},
  author =	 {Johnathan Alsop and Weon Taek Na and Matthew
                  D. Sinclair and Samuel Grayson and Sarita V. Adve},
  journal =	 {CoRR},
  volume =	 {abs/2104.11678},
  year =	 2021,
  eprint =	 {2104.11678},
  howpublished ={arXiv},
  primaryClass = {cs.AR}
}

@inproceedings{AlsopSinclair2018,
  author =	 {Alsop, Johnathan and Sinclair, Matthew D. and Adve,
                  Sarita V.},
  title =	 {{Spandex: A Flexible Interface for Efficient
                  Heterogeneous Coherence}},
  booktitle =	 {{Proceedings of the 45th Annual International
                  Symposium on Computer Architecture}},
  series =	 {ISCA},
  year =	 2018,
  isbn =	 {978-1-5386-5984-7},
  location =	 {Los Angeles, California},
  pages =	 {261--274},
  numpages =	 14,
  url =		 {https://doi.org/10.1109/ISCA.2018.00031},
  doi =		 {10.1109/ISCA.2018.00031},
  acmid =	 3276565,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
}

@inproceedings{Kotsifakou18-hpvm,
  author =	 {Kotsifakou, Maria and Srivastava, Prakalp and
                  Sinclair, Matthew D. and Komuravelli, Rakesh and
                  Adve, Vikram and Adve, Sarita},
  title =	 {{HPVM: Heterogeneous Parallel Virtual Machine}},
  booktitle =	 {{Proceedings of the 23rd ACM SIGPLAN Symposium on
                  Principles and Practice of Parallel Programming}},
  series =	 {PPoPP},
  year =	 2018,
  isbn =	 {978-1-4503-4982-6},
  location =	 {Vienna, Austria},
  pages =	 {68--80},
  numpages =	 13,
  url =		 {http://doi.acm.org/10.1145/3178487.3178493},
  doi =		 {10.1145/3178487.3178493},
  acmid =	 3178493,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {GPU, compiler, heterogeneous systems, parallel IR,
                  vector SIMD, virtual ISA},
}

@INPROCEEDINGS{Srivastava16-hvisc,
  author =	 {P. Srivastava and M. Kotsifakou and M. D. Sinclair
                  and R. Komuravelli and V. Adve and S. Adve},
  booktitle =	 {{2016 International Conference on Parallel
                  Architecture and Compilation Techniques}},
  series =	 {PACT},
  title =	 {{POSTER - hVISC: A portable abstraction for
                  heterogeneous parallel systems}},
  year =	 2016,
  pages =	 {443-445},
  keywords =	 {instruction sets;parallel programming;storage
                  management;programming heterogeneous parallel
                  systems;POSTER-hVISC;portable abstraction;memory
                  hierarchies;heterogeneous hardware parallel
                  abstraction designed;hierarchical dataflow
                  graph;shared memory;virtual instruction set
                  architecture;ISA;functional portability;performance
                  portability;Hardware;Parallel processing;Instruction
                  sets;Image edge detection;Graphics processing
                  units;Streaming media;Data transfer},
  doi =		 {10.1145/2967938.2976039},
  month =	 {9},
}

@INPROCEEDINGS{AlsopSinclair2016,
  author =	 {Alsop, Johnathan and Sinclair, Matthew D. and
                  Komuravelli, Rakesh and Adve, Sarita V.},
  booktitle =	 {{IEEE International Symposium on Performance
                  Analysis of Systems and Software}},
  series =	 {ISPASS},
  title =	 {{GSI: A GPU Stall Inspector to Characterize the
                  Sources of Memory Stalls for Tightly Coupled GPUs}},
  year =	 2016,
  pages =	 {172-182},
  keywords =	 {electronic engineering computing;graphics processing
                  units;memory architecture;GSI;GPU stall
                  inspector;memory stalls;power wall;single core
                  performance;energy-efficient high-throughput GPU
                  cores;data-parallel applications;heterogeneous
                  cores;heterogeneous memory systems;performance
                  characterization;parallelism;GPU
                  codes;coarse-grained metrics;CPU-GPU memory
                  subsystem;heterogeneous CPU-GPU systems;graphics
                  processing unit;central processing unit;Graphics
                  processing units;Instruction
                  sets;Synchronization;Parallel
                  processing;Technological
                  innovation;Kernel;Classification algorithms},
  doi =		 {10.1109/ISPASS.2016.7482092},
  month =	 {April},
}

@misc{Boehm18-oota,
  title =	 {{P1217R0: Out-of-thin-air, revisited, again}},
  author =	 {Boehm, Hans},
  howpublished =
                  {\url{http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1217r0.html}},
  year =	 2018,
}

@MastersThesis{sinclair:msThesis,
  title =	 {Enabling New Uses for GPUs},
  author =	 {Matthew D. Sinclair},
  school =	 {University of Wisconsin-Madison},
  howpublished =
                  {\url{http://pages.cs.wisc.edu/~sinclair/papers/sinclair_mastersThesis.pdf}},
  year =	 2011,
  month =	 {May}
}

@article{SalvadorDarvin2020-specializingArxiv,
  title =	 {{Specializing Coherence, Consistency, and Push/Pull
                  for GPU Graph Analytics}},
  author =	 {Giordano Salvador and Wesley H. Darvin and Muhammad
                  Huzaifa and Johnathan Alsop and Matthew D. Sinclair
                  and Sarita V. Adve},
  year =	 2020,
  eprint =	 {2002.10245},
  journal =	 {arXiv preprint}
}

@inproceedings{SalvadorDarvin2020-specializing,
  title =	 {{Specializing Coherence, Consistency, and Push/Pull
                  for GPU Graph Analytics}},
  author =	 {Giordano Salvador and Wesley H. Darvin and Muhammad
                  Huzaifa and Johnathan Alsop and Matthew D. Sinclair
                  and Sarita V. Adve},
  year =	 2020,
  booktitle =	 {{IEEE International Symposium on Performance
                  Analysis of Systems and Software}},
  series =	 {ISPASS},
}

@article{HuzaifaAlsop2020-gpuReuse,
  author =	 {Huzaifa, Muhammad and Alsop, Johnathan and Mahmoud,
                  Abdulrahman and Salvador, Giordano and Sinclair,
                  Matthew D. and Adve, Sarita V.},
  title =	 {{Inter-Kernel Reuse-Aware Thread Block Scheduling}},
  year =	 2020,
  issue_date =	 {August 2020},
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  volume =	 17,
  number =	 3,
  issn =	 {1544-3566},
  url =		 {https://doi.org/10.1145/3406538},
  doi =		 {10.1145/3406538},
  abstract =	 {As GPUs have become more programmable, their
                  performance and energy benefits have made them
                  increasingly popular. However, while GPU compute
                  units continue to improve in performance, on-chip
                  memories lag behind and data accesses are becoming
                  increasingly expensive in performance and
                  energy. Emerging GPU coherence protocols can
                  mitigate this bottleneck by exploiting data reuse in
                  GPU caches across kernel boundaries. Unfortunately,
                  current GPU thread block schedulers are typically
                  not designed to expose such reuse. This article
                  proposes new hardware thread block schedulers that
                  optimize inter-kernel reuse while using work
                  stealing to preserve load balance. Our schedulers
                  are simple, decentralized, and have extremely low
                  overhead. Compared to a baseline round-robin
                  scheduler, the best performing scheduler reduces
                  average execution time and energy by 19\% and 11\%,
                  respectively, in regular applications, and 10\% and
                  8\%, respectively, in irregular applications.},
  journal =	 {{ACM Trans. Archit. Code Optim.}},
  series =	 {TACO},
  month =	 aug,
  articleno =	 24,
  numpages =	 27,
  keywords =	 {memory systems, GPUs, scheduling, caches}
}

@inproceedings{SinclairVenkataraman2021-gpuPower,
  title =	 {{Co-designing Power Management with Job Scheduling
                  for Efficient Exascale Computing}},
  author =	 {Sinclair, Matthew D. and Venkataraman, Shivaram},
  year =	 2021,
  booktitle =	 {{DOE ASCR Workshop on Reimagining Codesign}},
  month =	 {March},
}

@inproceedings{BruceLowePower2021-gem5HPC,
  title =	 {{Leveraging open source simulators for HPC
                  codesign}},
  author =	 {Bruce, Bobby and Lowe-Power, Jason and Sinclair,
                  Matthew D.},
  year =	 2021,
  booktitle =	 {{DOE ASCR Workshop on Reimagining Codesign}},
  month =	 {March},
}

@inproceedings{AlsopSinclair2019-iiswc,
  title =	 {{Optimizing GPU Cache Policies for MI Workloads}},
  author =	 {Alsop, Johnathan and Sinclair, Matthew D. and
                  Gutierrez, Anthony and Bharadwaj, Srikant and Zhang,
                  Xianwei and Beckmann, Bradford and Dutu, Alexandru
                  and Kayiran, Onur and LeBeane, Michael and Potter,
                  Brandon and Puthoor, Sooraj and Yeh, Tsung Tai},
  booktitle =	 {{IEEE International Symposium on Workload
                  Characterization}},
  series =	 {IISWC},
  year =	 2019,
}

@article{AlsopSinclair2019-arxiv,
  title =	 {{Optimizing GPU Cache Policies for MI Workloads}},
  author =	 {Alsop, Johnathan and Sinclair, Matthew D. and
                  Gutierrez, Anthony and Bharadwaj, Srikant and Zhang,
                  Xianwei and Beckmann, Bradford and Dutu, Alexandru
                  and Kayiran, Onur and LeBeane, Michael and Potter,
                  Brandon and Puthoor, Sooraj and Yeh, Tsung Tai},
  booktitle =	 {{IEEE International Symposium on Workload
                  Characterization}},
  journal =	 {arXiv preprint arXiv:1910.00134},
  year =	 2019,
}

@inproceedings{KomuravelliSinclair2015-stash,
  author =	 {Komuravelli, Rakesh and Sinclair, Matthew D. and
                  Alsop, Johnathan and Huzaifa, Muhammad and
                  Srivastava, Prakalp and Kotsifakou, Maria and Adve,
                  Sarita V. and Adve, Vikram S.},
  title =	 {{Stash: Have Your Scratchpad and Cache it Too}},
  booktitle =	 {{Proceedings of the 42nd Annual International
                  Symposium on Computer Architecture}},
  year =	 2015,
  numpages =	 13,
  pages =	 {707--719},
  series =	 {{ISCA}},
  location =	 {Portland, Oregon},
}

@inproceedings{SinclairAlsop2015,
  author =	 {Sinclair, Matthew D. and Alsop, Johnathan and Adve,
                  Sarita V.},
  title =	 {{Efficient GPU Synchronization without Scopes:
                  Saying No to Complex Consistency Models}},
  booktitle =	 {{Proceedings of the 48th Annual IEEE/ACM
                  International Symposium on Microarchitecture}},
  year =	 2015,
  MONTH =	 {December},
  pages =	 {647--659},
  series =	 {{MICRO}},
}

@techreport{SinclairDuwe2011,
  author =	 {Matthew Sinclair and Henry Duwe and Karthikeyan
                  Sankaralingam},
  title =	 {{Porting CMP Benchmarks to GPUs}},
  institution =	 "{Department of Computer Sciences, The University of
                  Wisconsin-Madison}",
  school =	 {The University of Wisconsin-Madison},
  year =	 2011,
  bib2html_dl_html ={http://www.cs.wisc.edu/techreports/},
  bib2html_dl_pdf ={http://www.cs.wisc.edu/techreports/},
  bib2html_pubtype ={Tech Report},
  bib2html_rescat ={Architecture},
}

@inproceedings{SinclairAlsop2017,
  author =	 {Sinclair, Matthew D. and Alsop, Johnathan and Adve,
                  Sarita V.},
  title =	 {{Chasing Away RAts: Semantics and Evaluation for
                  Relaxed Atomics on Heterogeneous Systems}},
  booktitle =	 {{Proceedings of the 44th Annual International
                  Symposium on Computer Architecture}},
  year =	 2017,
  series =	 {{ISCA}},
  isbn =	 {978-1-4503-4892-8},
  location =	 {Toronto, ON, Canada},
  pages =	 {161--174},
  numpages =	 14,
  url =		 {http://doi.acm.org/10.1145/3079856.3080206},
  doi =		 {10.1145/3079856.3080206},
  acmid =	 3080206,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {GPGPU, data-race-free models, memory consistency,
                  relaxed atomics},
}

@inproceedings{SinclairAlsop2017_2,
  author =	 {Sinclair, Matthew D. and Alsop, Johnathan and Adve,
                  Sarita V.},
  title =	 {{HeteroSync: A Benchmark Suite for Fine-Grained
                  Synchronization on Tightly Coupled GPUs}},
  booktitle =	 {{IEEE International Symposium on Workload
                  Characterization}},
  year =	 2017,
  month =	 {October},
  series =	 {{IISWC}},
}

@inproceedings{BlemSinclair2011,
  author =	 {Emily Blem and Matthew Sinclair and Karthikeyan
                  Sankaralingam},
  title =	 {Challenge Benchmarks that Must be Conquered to
                  Sustain the GPU Revolution},
  booktitle =	 "{Proceedings of the 4th Workshop on Emerging
                  Applications for Manycore Architecture}",
  bib2html_dl_pdf ={http://bit.ly/laizPz},
  bib2html_pubtype ={Refereed Conference},
  bib2html_rescat ={Architecture},
  month =	 {June},
  year =	 2011
}

@book{TownsendSankaralingam2010,
  author =	 {Richard Townsend and Karthikeyan Sankaralingam and
                  Matthew D. Sinclair},
  title =	 {{Leveraging the Untapped Computation Power of GPUs:
                  Fast Spectral Synthesis Using Texture
                  Interpolation}},
  publisher =	 {Addison-Wesley},
  year =	 2010
}
% editor={Wen Mei-Hwu},

@inproceedings{SankaralingamTownsend2010,
  author =	 {Karthikeyan Sankaralingam and Richard Townsend and
                  Matthew D. Sinclair},
  title =	 {GRASSY: Leveraging GPU Texture Units for
                  Asteroseismic Data Analysis},
  booktitle =	 "{Proceedings of GPU Technology Conference}",
  series =	 {{GTC}},
  year =	 2010
}

@inproceedings{ChouNg2020-dab,
  title =	 {{Deterministic Atomic Buffering}},
  author =	 {Chou, Yuan Hsi and Ng, Christopher and Cattell,
                  Shaylin and Intan, Jeremy and Sinclair, Matthew
                  D. and Devietti, Joseph and Rogers, Timothy G. and
                  Aamodt, Tor M.},
  booktitle =	 {{Proceedings of the 53rd IEEE/ACM International
                  Symposium on Microarchitecture}},
  series =	 {MICRO},
  month =	 {October},
  year =	 2020,
}

@inproceedings{DutuSinclair2020-ifp,
  title =	 {{Independent Forward Progress of Work-groups}},
  author =	 {Dutu, Alexandru and Sinclair, Matthew D. and
                  Beckmann, Bradford M. and Wood, David A. and Chow,
                  Marcus},
  booktitle =	 {{Proceedings of the 47th International Symposium on
                  Computer Architecture}},
  series =	 {ISCA},
  year =	 2020,
  month =	 {May}
}

@inproceedings{YogatamaSinclair2020-multiGPU,
  title =	 {{Enabling Multi-GPU Support in gem5}},
  author =	 {Yogatama, Bobbi W. and Sinclair, Matthew D. and
                  Swift, Michael M.},
  year =	 2020,
  month =	 {June},
  booktitle =	 {{3rd gem5 Users' Workshop}},
}

@misc{regem5,
  author =	 {Lowe-Power, Jason and Sinclair, Matthew D.},
  title =	 {{RE-gem5: Building Sustainable Research
                  Infrastructure}},
  howpublished =
                  {\url{https://www.sigarch.org/re-gem5-building-sustainable-research-infrastructure/}},
  year =	 2019,
  month =	 {September},
}

@article{LewShah2018-gpgpusimML,
  author =	 {Jonathan Lew and Deval Shah and Suchita Pati and
                  Shaylin Cattell and Mengchi Zhang and Amruth
                  Sandhupatla and Christopher Ng and Negar Goli and
                  Matthew D. Sinclair and Timothy G. Rogers and Tor
                  M. Aamodt},
  title =	 {{Analyzing Machine Learning Workloads Using a
                  Detailed GPU Simulator}},
  journal =	 {CoRR},
  volume =	 {abs/1811.08933},
  year =	 2018,
  url =		 {http://arxiv.org/abs/1811.08933},
  howpublished ={arXiv},
  eprint =	 {1811.08933},
  timestamp =	 {Fri, 30 Nov 2018 12:44:28 +0100},
  biburl =
                  {https://dblp.org/rec/bib/journals/corr/abs-1811-08933},
  bibsource =	 {dblp computer science bibliography,
                  https://dblp.org}
}

@inproceedings{LewShah2019-gpgpusimML,
  author =	 {Jonathan Lew and Deval Shah and Suchita Pati and
                  Shaylin Cattell and Mengchi Zhang and Amruth
                  Sandhupatla and Christopher Ng and Negar Goli and
                  Matthew D. Sinclair and Timothy G. Rogers and Tor
                  M. Aamodt},
  title =	 {{Analyzing Machine Learning Workloads Using a
                  Detailed GPU Simulator}},
  year =	 2019,
  booktitle =	 {{IEEE International Symposium on Performance
                  Analysis of Systems and Software}},
  series =	 {ISPASS},
}

@inproceedings{DalmiaMahapatra2022-lab,
  author =	 {Dalmia, Preyesh and Mahapatra, Rohan and Sinclair,
                  Matthew D.},
  title =	 {{Only Buffer When You Need To: Reducing On-chip GPU
                  Traffic with Reconfigurable Local Atomic Buffers}},
  year =	 2022,
  booktitle =	 {{28th IEEE International Symposium on High
                  Performance Computer Architecture}},
  series =	 {HPCA},
}

@article{PhillipsBraun2005-namd,
  title =	 {{Scalable Molecular Dynamics with NAMD}},
  author =	 {Phillips, James C and Braun, Rosemary and Wang, Wei
                  and Gumbart, James and Tajkhorshid, Emad and Villa,
                  Elizabeth and Chipot, Christophe and Skeel, Robert D
                  and Kale, Laxmikant and Schulten, Klaus},
  journal =	 {{Journal of Computational Chemistry}},
  volume =	 26,
  number =	 16,
  pages =	 {1781--1802},
  year =	 2005,
  publisher =	 {Wiley Online Library}
}

@article{HospitalGoni2015-md,
  title =	 {{Molecular Dynamics Simulations: Advances and
                  Applications}},
  author =	 {Hospital, Adam and Go{\~n}i, Josep Ramon and Orozco,
                  Modesto and Gelp{\'\i}, Josep L},
  journal =	 {{Advances and Applications in Bioinformatics and
                  Chemistry: AABC}},
  volume =	 8,
  pages =	 37,
  year =	 2015,
  publisher =	 {Dove Press}
}

@article{TorrieValleau1977-umbrella,
  title =	 {Nonphysical sampling distributions in Monte Carlo
                  free-energy estimation: Umbrella sampling},
  author =	 {Torrie, Glenn M and Valleau, John P},
  journal =	 {Journal of Computational Physics},
  volume =	 23,
  number =	 2,
  pages =	 {187--199},
  year =	 1977,
  publisher =	 {Elsevier}
}

@article{narayanan2021efficient,
  title =	 {Efficient large-scale language model training on gpu
                  clusters},
  author =	 {Narayanan, Deepak and Shoeybi, Mohammad and Casper,
                  Jared and LeGresley, Patrick and Patwary, Mostofa
                  and Korthikanti, Vijay Anand and Vainbrand, Dmitri
                  and Kashinkunti, Prethvi and Bernauer, Julie and
                  Catanzaro, Bryan and others},
  journal =	 {arXiv preprint arXiv:2104.04473},
  year =	 2021
}

@INPROCEEDINGS{JiaoLin2010-gpuPowerPerf,
  author =	 {Jiao, Y. and Lin, H. and Balaji, P. and Feng, W.},
  booktitle =	 {IEEE/ACM International Conference on Green Computing
                  and Communications \& International Conference on
                  Cyber, Physical and Social Computing},
  title =	 {{Power and Performance Characterization of
                  Computational Kernels on the GPU}},
  year =	 2010,
  pages =	 {221-228},
  doi =		 {10.1109/GreenCom-CPSCom.2010.143}
}

@InProceedings{pbs-qsub,
  author =	 "Henderson, Robert L.",
  editor =	 "Feitelson, Dror G. and Rudolph, Larry",
  title =	 "Job scheduling under the Portable Batch System",
  booktitle =	 "Job Scheduling Strategies for Parallel Processing",
  year =	 1995,
  publisher =	 "Springer Berlin Heidelberg",
  address =	 "Berlin, Heidelberg",
  pages =	 "279--294",
  isbn =	 "978-3-540-49459-1"
}

@article{condor,
  author =	 {Thain, Douglas and Tannenbaum, Todd and Livny,
                  Miron},
  title =	 {{Distributed Computing in Practice: the Condor
                  Experience}},
  journal =	 {Concurrency and Computation: Practice and
                  Experience},
  volume =	 17,
  number =	 {2‐4},
  pages =	 {323-356},
  year =	 2005
}

@book{barroso2009datacenter,
  title =	 {{The Datacenter as a Computer: An Introduction to
                  the Design of Warehouse-Scale Machines}},
  author =	 {Luiz André Barroso and Urs Hölzle},
  year =	 2009,
  booktitle =	 {{The Datacenter as a Computer: An Introduction to
                  the Design of Warehouse-Scale Machines}},
  publisher =	 {Morgan \& Claypool}
}

@inproceedings{feitelson1996packing,
  title =	 {{Packing Schemes for Gang Scheduling}},
  author =	 {Feitelson, Dror G},
  booktitle =	 {{Workshop on Job Scheduling Strategies for Parallel
                  Processing}},
  pages =	 {89--110},
  year =	 1996,
  organization = {Springer}
}

@inproceedings{verma2015large,
  title =	 {{Large-scale cluster management at Google with
                  Borg}},
  author =	 {Verma, Abhishek and Pedrosa, Luis and Korupolu,
                  Madhukar and Oppenheimer, David and Tune, Eric and
                  Wilkes, John},
  booktitle =	 {Eurosys},
  year =	 2015
}

@inproceedings{hindman2011mesos,
  title =	 {Mesos: A platform for fine-grained resource sharing
                  in the data center},
  author =	 {Hindman, Benjamin and Konwinski, Andy and Zaharia,
                  Matei and Ghodsi, Ali and Joseph, Anthony D and
                  Katz, Randy and Shenker, Scott and Stoica, Ion},
  booktitle =	 {NSDI},
  year =	 2011,
}

@inproceedings{isard2009quincy,
  title =	 {{Quincy: Fair scheduling for distributed computing
                  clusters}},
  author =	 {Isard, Michael and Prabhakaran, Vijayan and Currey,
                  Jon and Wieder, Udi and Talwar, Kunal and Goldberg,
                  Andrew},
  booktitle =	 {SOSP},
  year =	 2009
}

@inproceedings{malte2013omega,
  title =	 {Omega: flexible, scalable schedulers for large scale
                  compute clusters},
  author =	 {Schwarzkopf, Malte and Konwinski, Andy and
                  Abd-el-Malek, Michael and Wilkes, John},
  booktitle =	 {Eurosys},
  year =	 2013
}

@inproceedings{wencong1,
  title =	 {{Gandiva: Introspective Cluster Scheduling for Deep
                  Learning}},
  author =	 {{Wencong Xiao, Romil Bhardwaj, Ramachandran Ramjee,
                  Muthian Sivathanu, Nipun Kwatra, Zhenhua Han,
                  Pratyush Patel, Xuan Peng, Hanyu Zhao, Quanlu Zhang,
                  Fan Yang, Lidong Zhou}},
  booktitle =	 {OSDI},
  year =	 2018
}

@inproceedings{gu2019tiresias,
  title =	 {Tiresias: A GPU cluster manager for distributed deep
                  learning},
  author =	 {Gu, Juncheng and Chowdhury, Mosharaf and Shin, Kang
                  G and Zhu, Yibo and Jeon, Myeongjae and Qian, Junjie
                  and Liu, Hongqiang and Guo, Chuanxiong},
  booktitle =	 {16th USENIX Symposium on Networked Systems Design
                  and Implementation (NSDI)},
  pages =	 {485--500},
  year =	 2019
}

@inproceedings{ghodsi2011dominant,
  title =	 {{Dominant resource fairness: Fair allocation of
                  multiple resource types}},
  author =	 {Ghodsi, Ali and Zaharia, Matei and Hindman, Benjamin
                  and Konwinski, Andy and Shenker, Scott and Stoica,
                  Ion},
  booktitle =	 {USENIX NSDI},
  year =	 2011
}

@inproceedings{le2020allox,
  title =	 {{AlloX: Compute Allocation in Hybrid Clusters}},
  author =	 {Le, Tan N and Sun, Xiao and Chowdhury, Mosharaf and
                  Liu, Zhenhua},
  booktitle =	 {Proceedings of the Fifteenth European Conference on
                  Computer Systems},
  year =	 2020
}

@inproceedings{optimus,
  title =	 {{Optimus: an Efficient Dynamic Resource Scheduler
                  for Deep Learning Clusters}},
  author =	 {Peng, Yanghua and Bao, Yixin and Chen, Yangrui and
                  Wu, Chuan and Guo, Chuanxiong},
  booktitle =	 {{Proceedings of the Thirteenth EuroSys Conference}},
  pages =	 3,
  year =	 2018,
  organization = {ACM}
}

@inproceedings{slaq,
  title =	 {{SLAQ: quality-driven scheduling for distributed
                  machine learning}},
  author =	 {Zhang, Haoyu and Stafman, Logan and Or, Andrew and
                  Freedman, Michael J},
  booktitle =	 {Proceedings of the 2017 Symposium on Cloud
                  Computing},
  pages =	 {390--404},
  year =	 2017,
  organization = {ACM}
}

@article{gns_scaling,
  author =	 {Sam McCandlish and Jared Kaplan and Dario Amodei and
                  OpenAI Dota Team},
  title =	 {{An Empirical Model of Large-Batch Training}},
  journal =	 {CoRR},
  volume =	 {abs/1812.06162},
  year =	 2018,
  url =		 {http://arxiv.org/abs/1812.06162},
  eprinttype =	 {arXiv},
  eprint =	 {1812.06162},
  timestamp =	 {Tue, 01 Jan 2019 15:01:25 +0100},
  biburl =
                  {https://dblp.org/rec/journals/corr/abs-1812-06162.bib},
  bibsource =	 {dblp computer science bibliography,
                  https://dblp.org}
}

@inproceedings {kungfu20,
  author =	 {Luo Mai and Guo Li and Marcel Wagenl{\"a}nder and
                  Konstantinos Fertakis and Andrei-Octavian Brabete
                  and Peter Pietzuch},
  title =	 {KungFu: Making Training in Distributed Machine
                  Learning Adaptive},
  booktitle =	 {14th {USENIX} Symposium on Operating Systems Design
                  and Implementation ({OSDI} 20)},
  year =	 2020,
  isbn =	 {978-1-939133-19-9},
  pages =	 {937--954},
  url =
                  {https://www.usenix.org/conference/osdi20/presentation/mai},
  publisher =	 {{USENIX} Association},
  month =	 nov,
}

@article{agarwal2021adaptive,
  title =	 {Adaptive Gradient Communication via Critical
                  Learning Regime Identification},
  author =	 {Agarwal, Saurabh and Wang, Hongyi and Lee, Kangwook
                  and Venkataraman, Shivaram and Papailiopoulos,
                  Dimitris},
  journal =	 {Proceedings of Machine Learning and Systems},
  volume =	 3,
  year =	 2021
}

@InProceedings{slurmSimulator1,
  author =	 "Simakov, Nikolay A.  and Innus, Martins D.  and
                  Jones, Matthew D.  and DeLeon, Robert L.  and White,
                  Joseph P.  and Gallo, Steven M.  and Patra, Abani K.
                  and Furlani, Thomas R.",
  editor =	 "Jarvis, Stephen and Wright, Steven and Hammond,
                  Simon",
  title =	 "A Slurm Simulator: Implementation and Parametric
                  Analysis",
  booktitle =	 "High Performance Computing Systems. Performance
                  Modeling, Benchmarking, and Simulation",
  year =	 2018,
  publisher =	 "Springer International Publishing",
  pages =	 "197--217",
}

@inproceedings{slurmSimulator2,
  author =	 {Simakov, Nikolay A. and DeLeon, Robert L. and Innus,
                  Martins D. and Jones, Matthew D. and White, Joseph
                  P. and Gallo, Steven M. and Patra, Abani K. and
                  Furlani, Thomas R.},
  title =	 {{Slurm Simulator: Improving Slurm Scheduler
                  Performance on Large HPC Systems by Utilization of
                  Multiple Controllers and Node Sharing}},
  year =	 2018,
  isbn =	 9781450364461,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  booktitle =	 {{Proceedings of the Practice and Experience on
                  Advanced Research Computing}},
  articleno =	 25,
  numpages =	 8,
  keywords =	 {Workload, Simulation, HPC, Scheduling},
  location =	 {Pittsburgh, PA, USA},
  series =	 {PEARC '18}
}

@misc{balasubramanian2021accelerating,
  title =	 {{Accelerating Deep Learning Inference via Learned
                  Caches}},
  author =	 {Arjun Balasubramanian and Adarsh Kumar and Yuhan Liu
                  and Han Cao and Shivaram Venkataraman and Aditya
                  Akella},
  year =	 2021,
  eprint =	 {2101.07344},
  howpublished ={arXiv},
  primaryClass = {cs.LG}
}

@inproceedings{venkataraman2013presto,
  title =	 {{Presto: Distributed Machine Learning and Graph
                  Processing with Sparse Matrices}},
  author =	 {Venkataraman, Shivaram and Bodzsar, Erik and Roy,
                  Indrajit and AuYoung, Alvin and Schreiber, Robert S},
  booktitle =	 {{Proceedings of the 8th ACM European Conference on
                  Computer Systems}},
  pages =	 {197--210},
  year =	 2013
}

@inproceedings{wang2020blink,
  author =	 {Wang, Guanhua and Venkataraman, Shivaram and
                  Phanishayee, Amar and Devanur, Nikhil and Thelin,
                  Jorgen and Stoica, Ion},
  booktitle =	 {Proceedings of Machine Learning and Systems 2020},
  pages =	 {172--186},
  title =	 {{Blink: Fast and Generic Collectives for Distributed
                  ML}},
  year =	 2020
}

@inproceedings{kosaian2019parity,
  title =	 {Parity models: erasure-coded resilience for
                  prediction serving systems},
  author =	 {Kosaian, Jack and Rashmi, KV and Venkataraman,
                  Shivaram},
  booktitle =	 {Proceedings of the 27th ACM Symposium on Operating
                  Systems Principles},
  pages =	 {30--46},
  year =	 2019
}

@inproceedings{venkataraman2017drizzle,
  title =	 {Drizzle: Fast and adaptable stream processing at
                  scale},
  author =	 {Venkataraman, Shivaram and Panda, Aurojit and
                  Ousterhout, Kay and Armbrust, Michael and Ghodsi,
                  Ali and Franklin, Michael J and Recht, Benjamin and
                  Stoica, Ion},
  booktitle =	 {Proceedings of the 26th Symposium on Operating
                  Systems Principles},
  pages =	 {374--389},
  year =	 2017,
  organization = {ACM}
}

@inproceedings{venkataraman2014power,
  title =	 {The power of choice in data-aware cluster
                  scheduling},
  author =	 {Venkataraman, Shivaram and Panda, Aurojit and
                  Ananthanarayanan, Ganesh and Franklin, Michael J and
                  Stoica, Ion},
  booktitle =	 {OSDI},
  pages =	 {301--316},
  year =	 2014
}

@inproceedings{venkataraman2016sparkr,
  title =	 {Sparkr: Scaling r programs with spark},
  author =	 {Venkataraman, Shivaram and Yang, Zongheng and Liu,
                  Davies and Liang, Eric and Falaki, Hossein and Meng,
                  Xiangrui and Xin, Reynold and Ghodsi, Ali and
                  Franklin, Michael and Stoica, Ion and Zaharia,
                  Matei},
  booktitle =	 {Proceedings of the 2016 International Conference on
                  Management of Data},
  pages =	 {1099--1104},
  year =	 2016
}

@inproceedings{mohoney2021marius,
  title =	 {Marius: Learning Massive Graph Embeddings on a
                  Single Machine},
  author =	 {Mohoney, Jason and Waleffe, Roger and Xu, Henry and
                  Rekatsinas, Theodoros and Venkataraman, Shivaram},
  booktitle =	 {15th USENIX Symposium on Operating Systems Design
                  and Implementation (OSDI 21)},
  pages =	 {533--549},
  year =	 2021
}

@inproceedings {aarati-hotcloud,
  author =	 {Aarati Kakaraparthy and Abhay Venkatesh and Amar
                  Phanishayee and Shivaram Venkataraman},
  title =	 {The Case for Unifying Data Loading in Machine
                  Learning Clusters},
  booktitle =	 {11th {USENIX} Workshop on Hot Topics in Cloud
                  Computing (HotCloud 19)},
  year =	 2019,
  month =	 jul,
}

@misc{accordion-opensource,
  title =	 {{Source code for Accordion: Adaptive Gradient
                  Communication via Critical Learning Regime
                  Identification}},
  howpublished = {\url{https://github.com/uw-mad-dash/accordion}},
  year =	 2021,
  key =		 {accordion}
},

@misc{gati-opensource,
  title =	 {{Source code for Gati: Accelerating Deep Learning
                  Inference via Learned Caches}},
  howpublished = {\url{https://github.com/uw-mad-dash/gati-code}},
  year =	 2021,
  key =		 {gati}
}

@inproceedings{branzei2014fisher,
  title =	 {The fisher market game: Equilibrium and welfare},
  author =	 {Br{\^a}nzei, Simina and Chen, Yiling and Deng,
                  Xiaotie and Filos-Ratsikas, Aris and Frederiksen,
                  S{\o}ren and Zhang, Jie},
  booktitle =	 {Proceedings of the AAAI Conference on Artificial
                  Intelligence},
  volume =	 28,
  year =	 2014
}

@inproceedings {gavel20,
  author =	 {Deepak Narayanan and Keshav Santhanam and Fiodar
                  Kazhamiaka and Amar Phanishayee and Matei Zaharia},
  title =	 {Heterogeneity-Aware Cluster Scheduling Policies for
                  Deep Learning Workloads},
  booktitle =	 {14th {USENIX} Symposium on Operating Systems Design
                  and Implementation ({OSDI} 20)},
  year =	 2020,
  pages =	 {481--498},
  month =	 nov,
}

@inproceedings{chaudhary2020balancing,
  title =	 {Balancing efficiency and fairness in heterogeneous
                  GPU clusters for deep learning},
  author =	 {Chaudhary, Shubham and Ramjee, Ramachandran and
                  Sivathanu, Muthian and Kwatra, Nipun and Viswanatha,
                  Srinidhi},
  booktitle =	 {Proceedings of the Fifteenth European Conference on
                  Computer Systems},
  pages =	 {1--16},
  year =	 2020
}

@InProceedings{OtternessAnderson2020-cuMask,
  author =	 {Nathan Otterness and James H. Anderson},
  title =	 {{AMD GPUs as an Alternative to NVIDIA for Supporting
                  Real-Time Workloads}},
  booktitle =	 {32nd Euromicro Conference on Real-Time Systems},
  pages =	 {10:1--10:23},
  series =	 {ECRTS},
  ISBN =	 {978-3-95977-152-8},
  ISSN =	 {1868-8969},
  year =	 2020,
  volume =	 165,
  editor =	 {Marcus V{\"o}lp},
  publisher =	 {Schloss Dagstuhl--Leibniz-Zentrum f{\"u}r
                  Informatik},
  address =	 {Dagstuhl, Germany},
  URL =		 {https://drops.dagstuhl.de/opus/volltexte/2020/12373},
  URN =		 {urn:nbn:de:0030-drops-123732},
  doi =		 {10.4230/LIPIcs.ECRTS.2020.10},
  annote =	 {Keywords: real-time systems, graphics processing
                  units, parallel computing}
}

@inproceedings {XiaoRen2020-antMan,
  author =	 {Wencong Xiao and Shiru Ren and Yong Li and Yang
                  Zhang and Pengyang Hou and Zhi Li and Yihui Feng and
                  Wei Lin and Yangqing Jia},
  title =	 {{AntMan: Dynamic Scaling on GPU Clusters for Deep
                  Learning}},
  booktitle =	 {{14th USENIX Symposium on Operating Systems Design
                  and Implementation}},
  series =	 {OSDI},
  year =	 2020,
  isbn =	 {978-1-939133-19-9},
  pages =	 {533--548},
  url =
                  {https://www.usenix.org/conference/osdi20/presentation/xiao},
  publisher =	 {USENIX Association},
  month =	 nov,
}

@article{basar2010lecture,
  title =	 {Lecture notes on non-cooperative game theory},
  author =	 {Basar, Tamer and others},
  journal =	 {Game Theory Module of the Graduate Program in
                  Network Mathematics},
  pages =	 {3--6},
  year =	 2010
}

@article{thompson2022lammps,
  title =	 {LAMMPS-a flexible simulation tool for particle-based
                  materials modeling at the atomic, meso, and
                  continuum scales},
  author =	 {Thompson, Aidan P and Aktulga, H Metin and Berger,
                  Richard and Bolintineanu, Dan S and Brown, W Michael
                  and Crozier, Paul S and in't Veld, Pieter J and
                  Kohlmeyer, Axel and Moore, Stan G and Nguyen, Trung
                  Dac and others},
  journal =	 {Computer Physics Communications},
  volume =	 271,
  pages =	 108171,
  year =	 2022,
  publisher =	 {Elsevier}
}

@article{van2005gromacs,
  title =	 {GROMACS: fast, flexible, and free},
  author =	 {Van Der Spoel, David and Lindahl, Erik and Hess,
                  Berk and Groenhof, Gerrit and Mark, Alan E and
                  Berendsen, Herman JC},
  journal =	 {Journal of computational chemistry},
  volume =	 26,
  number =	 16,
  pages =	 {1701--1718},
  year =	 2005,
  publisher =	 {Wiley Online Library}
}

@article{case2005amber,
  title =	 {The Amber biomolecular simulation programs},
  author =	 {Case, David A and Cheatham III, Thomas E and Darden,
                  Tom and Gohlke, Holger and Luo, Ray and Merz Jr,
                  Kenneth M and Onufriev, Alexey and Simmerling,
                  Carlos and Wang, Bing and Woods, Robert J},
  journal =	 {Journal of computational chemistry},
  volume =	 26,
  number =	 16,
  pages =	 {1668--1688},
  year =	 2005,
  publisher =	 {Wiley Online Library}
}

@misc{brace2021achieving,
  title =	 {{Achieving 100X faster simulations of complex
                  biological phenomena by coupling ML to HPC
                  ensembles}},
  author =	 {Alexander Brace and Hyungro Lee and Heng Ma and Anda
                  Trifan and Matteo Turilli and Igor Yakushin and Todd
                  Munson and Ian Foster and Shantenu Jha and Arvind
                  Ramanathan},
  year =	 2021,
  eprint =	 {2104.04797},
  howpublished ={arXiv},
  primaryClass = {cs.DC}
}

@article{singhvi2019archipelago,
  title =	 {Archipelago: A Scalable Low-Latency Serverless
                  Platform},
  author =	 {Singhvi, Arjun and Houck, Kevin and Balasubramanian,
                  Arjun and Shaikh, Mohammed Danish and Venkataraman,
                  Shivaram and Akella, Aditya},
  journal =	 {arXiv preprint arXiv:1911.09849},
  year =	 2019
}

@article{mohanty2016using,
  title =	 {Using deep learning for image-based plant disease
                  detection},
  author =	 {Mohanty, Sharada P and Hughes, David P and
                  Salath{\'e}, Marcel},
  journal =	 {Frontiers in plant science},
  volume =	 7,
  pages =	 1419,
  year =	 2016,
  publisher =	 {frontiers}
}

@InProceedings{DeakinPrice2016-gpuStream,
  author =	 "Deakin, Tom and Price, James and Martineau, Matt and
                  McIntosh-Smith, Simon",
  editor =	 "Taufer, Michela and Mohr, Bernd and Kunkel, Julian
                  M.",
  title =	 "GPU-STREAM v2.0: Benchmarking the Achievable Memory
                  Bandwidth of Many-Core Processors Across Diverse
                  Parallel Programming Models",
  booktitle =	 "High Performance Computing",
  year =	 2016,
  publisher =	 "Springer International Publishing",
  address =	 "Cham",
  pages =	 "489--507",
  abstract =	 "Many scientific codes consist of memory bandwidth
                  bound kernels --- the dominating factor of the
                  runtime is the speed at which data can be loaded
                  from memory into the Arithmetic Logic Units, before
                  results are written back to memory. One major
                  advantage of many-core devices such as General
                  Purpose Graphics Processing Units (GPGPUs) and the
                  Intel Xeon Phi is their focus on providing increased
                  memory bandwidth over traditional CPU
                  architectures. However, as with CPUs, this peak
                  memory bandwidth is usually unachievable in practice
                  and so benchmarks are required to measure a
                  practical upper bound on expected performance.",
  isbn =	 "978-3-319-46079-6"
}

@article{zhang2022opt,
  title =	 {{Opt: Open Pre-trained Transformer Language Models}},
  author =	 {Zhang, Susan and Roller, Stephen and Goyal, Naman
                  and Artetxe, Mikel and Chen, Moya and Chen, Shuohui
                  and Dewan, Christopher and Diab, Mona and Li, Xian
                  and Lin, Xi Victoria and others},
  journal =	 {arXiv preprint arXiv:2205.01068},
  year =	 2022
}

@article{dosovitskiy2020image,
  title =	 {An image is worth 16x16 words: Transformers for
                  image recognition at scale},
  author =	 {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov,
                  Alexander and Weissenborn, Dirk and Zhai, Xiaohua
                  and Unterthiner, Thomas and Dehghani, Mostafa and
                  Minderer, Matthias and Heigold, Georg and Gelly,
                  Sylvain and others},
  journal =	 {arXiv preprint arXiv:2010.11929},
  year =	 2020
}

@article{ahdritz2022openfold,
  title =	 {{OpenFold: Retraining AlphaFold2 yields new insights
                  into its learning mechanisms and capacity for
                  generalization}},
  author =	 {Ahdritz, Gustaf and Bouatta, Nazim and Kadyan,
                  Sachin and Xia, Qinghui and Gerecke, William and
                  O'Donnell, Timothy J and Berenberg, Daniel and Fisk,
                  Ian and Zanichelli, Niccola and Zhang, Bo and
                  others},
  journal =	 {bioRxiv},
  year =	 2022,
  publisher =	 {Cold Spring Harbor Laboratory}
}

@misc{nsight,
  title =	 {{NVIDIA Nsight Systems}},
  author =	 {NVIDIA},
  year =	 2022,
  howpublished = {\url{https://developer.nvidia.com/nsight-systems}},
}

@misc{omnitrace,
  title =	 {{Omnitrace: Application Profiling, Tracing, and
                  Analysis}},
  author =	 {Madsen, Jonathan R.},
  year =	 2022,
  howpublished = {\url{https://github.com/AMDResearch/omnitrace}},
}

@misc{nvidia-smi,
  author =	 {{NVIDIA}},
  title =	 {{NVIDIA System Management Interface}},
  howpublished =
                  {\url{https://developer.nvidia.com/nvidia-system-management-interface}},
  year =	 2020,
}

@misc{rocm-smi,
  author =	 {{Advanced Micro Devices, Inc}},
  title =	 {{ROCm Command Line Interface}},
  howpublished =
                  {\url{https://rocmdocs.amd.com/en/latest/ROCm_System_Managment/ROCm-SMI-CLI.html}},
  year =	 2022,
}

@inproceedings{Scogland2014-MeasurementLevels,
  author =	 {Scogland, Thomas R.W. and Steffen, Craig P. and
                  Wilde, Torsten and Parent, Florent and Coghlan,
                  Susan and Bates, Natalie and Feng, Wu-chun and
                  Strohmaier, Erich},
  title =	 {{A Power-Measurement Methodology for Large-Scale,
                  High-Performance Computing}},
  year =	 2014,
  isbn =	 9781450327336,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/2568088.2576795},
  doi =		 {10.1145/2568088.2576795},
  abstract =	 {Improvement in the energy efficiency of
                  supercomputers can be accelerated by improving the
                  quality and comparability of efficiency
                  measurements. The ability to generate accurate
                  measurements at extreme scale are just now
                  emerging. The realization of system-level
                  measurement capabilities can be accelerated with a
                  commonly adopted and high quality measurement
                  methodology for use while running a workload,
                  typically a benchmark. This paper describes a
                  methodology that has been developed collaboratively
                  through the Energy Efficient HPC Working Group to
                  support architectural analysis and comparative
                  measurements for rankings, such as the Top500 and
                  Green500. To support measurements with varying
                  amounts of effort and equipment required we present
                  three distinct levels of measurement, which provide
                  increasing levels of accuracy. Level 1 is similar to
                  the Green500 run rules today, a single average power
                  measurement extrapolated from a subset of a
                  machine. Level 2 is more comprehensive, but still
                  widely achievable. Level 3 is the most rigorous of
                  the three methodologies but is only possible at a
                  few sites. However, the Level 3 methodology
                  generates a high quality result that exposes details
                  that the other methodologies may miss. In addition,
                  we present case studies from the Leibniz
                  Supercomputing Centre (LRZ), Argonne National
                  Laboratory (ANL) and Calcul Qu\'{e}bec
                  Universit\'{e} Laval that explore the benefits and
                  difficulties of gathering high quality, system-level
                  measurements on large-scale machines.},
  booktitle =	 {{Proceedings of the 5th ACM/SPEC International
                  Conference on Performance Engineering}},
  pages =	 {149–159},
  numpages =	 11,
  keywords =	 {green500, top500, power-measurement methodology,
                  datacenter, high-performance computing},
  location =	 {Dublin, Ireland},
  series =	 {ICPE '14}
}

@inproceedings{EsmaeilzadehBlem2011-darkSilicon,
  author =	 {Esmaeilzadeh, Hadi and Blem, Emily and St. Amant,
                  Renee and Sankaralingam, Karthikeyan and Burger,
                  Doug},
  title =	 {{Dark silicon and the End of Multicore Scaling}},
  year =	 2011,
  isbn =	 9781450304726,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/2000064.2000108},
  doi =		 {10.1145/2000064.2000108},
  abstract =	 {Since 2005, processor designers have increased core
                  counts to exploit Moore's Law scaling, rather than
                  focusing on single-core performance. The failure of
                  Dennard scaling, to which the shift to multicore
                  parts is partially a response, may soon limit
                  multicore scaling just as single-core scaling has
                  been curtailed. This paper models multicore scaling
                  limits by combining device scaling, single-core
                  scaling, and multicore scaling to measure the
                  speedup potential for a set of parallel workloads
                  for the next five technology generations. For device
                  scaling, we use both the ITRS projections and a set
                  of more conservative device scaling parameters. To
                  model single-core scaling, we combine measurements
                  from over 150 processors to derive Pareto-optimal
                  frontiers for area/performance and
                  power/performance. Finally, to model multicore
                  scaling, we build a detailed performance model of
                  upper-bound performance and lower-bound core
                  power. The multicore designs we study include
                  single-threaded CPU-like and massively threaded
                  GPU-like multicore chip organizations with
                  symmetric, asymmetric, dynamic, and composed
                  topologies. The study shows that regardless of chip
                  organization and topology, multicore scaling is
                  power limited to a degree not widely appreciated by
                  the computing community. Even at 22 nm (just one
                  year from now), 21\% of a fixed-size chip must be
                  powered off, and at 8 nm, this number grows to more
                  than 50\%. Through 2024, only 7.9x average speedup
                  is possible across commonly used parallel workloads,
                  leaving a nearly 24-fold gap from a target of
                  doubled performance per generation.},
  booktitle =	 {{Proceedings of the 38th Annual International
                  Symposium on Computer Architecture}},
  pages =	 {365–376},
  numpages =	 12,
  keywords =	 {dark silicon, modeling, multicore, power, technology
                  scaling},
  location =	 {San Jose, California, USA},
  series =	 {ISCA '11}
}

@inproceedings{Scogland2015-pwrPerspectives,
  author =	 {Scogland, Thomas and Azose, Jonathan and Rohr, David
                  and Rivoire, Suzanne and Bates, Natalie and
                  Hackenberg, Daniel},
  title =	 {{Node Variability in Large-Scale Power Measurements:
                  Perspectives from the Green500, Top500 and EEHPCWG}},
  year =	 2015,
  isbn =	 9781450337236,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/2807591.2807653},
  doi =		 {10.1145/2807591.2807653},
  abstract =	 {The last decade has seen power consumption move from
                  an afterthought to the foremost design constraint of
                  new supercomputers. Measuring the power of a
                  supercomputer can be a daunting proposition, and as
                  a result, many published measurements are
                  extrapolated. This paper explores the validity of
                  these extrapolations in the context of inter-node
                  power variability and power variations over time
                  within a run. We characterize power variability
                  across nodes in systems at eight supercomputer
                  centers across the globe. This characterization
                  shows that the current requirement for measurements
                  submitted to the Green500 and others is
                  insufficient, allowing variations of up to 20\% due
                  to measurement timing and a further 10--15\% due to
                  insufficient sample sizes. This paper proposes new
                  power and energy measurement requirements for
                  supercomputers, some of which have been accepted for
                  use by the Green500 and Top500, to ensure consistent
                  accuracy.},
  booktitle =	 {{Proceedings of the International Conference for
                  High Performance Computing, Networking, Storage and
                  Analysis}},
  articleno =	 74,
  numpages =	 11,
  location =	 {Austin, Texas},
  series =	 {SC '15}
}

@inproceedings{PatelWagenhauser2020-hpcPowerConsump,
  author =	 {Patel, Tirthak and Wagenhäuser, Adam and Eibel,
                  Christopher and Hönig, Timo and Zeiser, Thomas and
                  Tiwari, Devesh},
  booktitle =	 {{IEEE International Parallel and Distributed
                  Processing Symposium}},
  series =	 {IPDPS},
  title =	 {{What does Power Consumption Behavior of HPC Jobs
                  Reveal? : Demystifying, Quantifying, and Predicting
                  Power Consumption Characteristics}},
  year =	 2020,
  pages =	 {799-809},
  doi =		 {10.1109/IPDPS47924.2020.00087}
}

@misc{vtune,
  author =	 {{Intel}},
  title =	 {{Intel VTune Profiler: Find and Fix Performance
                  Bottlenecks Quickly and Realize All the Value of
                  Your Hardware}},
  howpublished =
                  {\url{https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler.html#gs.ldsbw8}},
  year =	 2022,
}

@misc{graphcore-prof,
  author =	 {{Graphcore}},
  title =	 {{Poplar: Profiling}},
  howpublished =
                  {\url{https://docs.graphcore.ai/projects/poplar-user-guide/en/latest/profiler.html}},
  year =	 2022,
}

@misc{PattersonGonzalez2021-mlCarbon,
  doi =		 {10.48550/ARXIV.2104.10350},
  url =		 {https://arxiv.org/abs/2104.10350},
  author =	 {Patterson, David and Gonzalez, Joseph and Le, Quoc
                  and Liang, Chen and Munguia, Lluis-Miquel and
                  Rothchild, Daniel and So, David and Texier, Maud and
                  Dean, Jeff},
  keywords =	 {Machine Learning (cs.LG), Computers and Society
                  (cs.CY), FOS: Computer and information sciences,
                  FOS: Computer and information sciences},
  title =	 {{Carbon Emissions and Large Neural Network
                  Training}},
  publisher =	 {arXiv},
  year =	 2021,
  copyright =	 {arXiv.org perpetual, non-exclusive license}
}

@misc{kecklerpicojoule,
  author =	 {Keckler, Stephen W.},
  title =	 {{Life After Dennard and How I Learned to Love the
                  Picojoule}},
  howpublished = {Keynote at MICRO},
  year =	 2011,
}

@misc{uarch,
  title =	 {{Second Undergrad Architecture Mentoring Workshop
                  (uArch)}},
  year =	 2020,
  howpublished = {\url{https://sites.google.com/view/uarch2020/home}},
}

@misc{sarita-will,
  title =	 {{Illinois Public Media: Women And Computer Science}},
  author =	 {WILL},
  year =	 2016,
  howpublished =
                  {\url{https://will.illinois.edu/player/audio/homelessness-prevention-women-and-computer-science-urban-gardening}},
}

@misc{taulbeeSurvey2019,
  title =	 {{2019 Taulbee Survey}},
  author =	 {CRA},
  year =	 2019,
  howpublished =
                  {\url{https://cra.org/wp-content/uploads/2020/05/2019-Taulbee-Survey.pdf}},
}

@misc{sigarch-pipelineProb,
  title =	 {{Tackling the Pipeline Problem in the Architecture
                  Research Community}},
  author =	 {Olson, Lena and Ardlani, Newsha},
  howpublished =
                  {\url{https://www.sigarch.org/tackling-the-pipeline-problem-in-the-architecture-research-community/}},
  year =	 2019,
  month =	 {April},
}

@misc{parityGame,
  title =	 {{Parity Magic}},
  author =	 {CS Unplugged},
  year =	 2022,
  howpublished =
                  {\url{https://csunplugged.org/en/topics/error-detection-and-correction/unit-plan/parity-magic/}},
}

@misc{BharadwajDas2022-gpuDVFS,
  doi =		 {10.48550/ARXIV.2205.00121},
  url =		 {https://arxiv.org/abs/2205.00121},
  author =	 {Bharadwaj, Srikant and Das, Shomit and Mazumdar,
                  Kaushik and Beckmann, Bradford and Kosonocky,
                  Stephen},
  keywords =	 {Hardware Architecture (cs.AR), FOS: Computer and
                  information sciences, FOS: Computer and information
                  sciences},
  title =	 {{Predict; Do not React for Enabling Efficient Fine
                  Grain DVFS in GPUs}},
  publisher =	 {arXiv},
  year =	 2022,
}

@INPROCEEDINGS{MeinerzhagenTokunaga2018-gpuDVFS,
  author =	 {Meinerzhagen, Pascal and Tokunaga, Carlos and
                  Malavasi, Andres and Vaidya, Vaibhav and Mendon,
                  Ashwin and Mathaikutty, Deepak and Kulkarni, Jaydeep
                  and Augustine, Charles and Cho, Minki and Kim,
                  Stephen and Matthew, George and Jain, Rinkle and
                  Ryan, Joseph and Peng, Chung-Ching and Paul, Somnath
                  and Vangal, Sriram and Esparza, Brando Perez and
                  Cuellar, Luis and Woodman, Michael and Iyer, Bala
                  and Maiyuran, Subramaniam and Chinya, Gautham and
                  Zou, Chris and Liao, Yuyun and Ravichandran,
                  Krishnan and Wang, Hong and Khellah, Muhammad and
                  Tschanz, James and De, Vivek},
  booktitle =	 {{IEEE International Solid - State Circuits
                  Conference}},
  series =	 {ISSCC},
  title =	 {{An energy-efficient graphics processor featuring
                  fine-grain DVFS with integrated voltage regulators,
                  execution-unit turbo, and retentive sleep in 14nm
                  tri-gate CMOS}},
  year =	 2018,
  pages =	 {38-40},
  doi =		 {10.1109/ISSCC.2018.8310172}
}

@inproceedings{NathTullsen2015-crisp,
  author =	 {Nath, Rajib and Tullsen, Dean},
  title =	 {{The CRISP Performance Model for Dynamic Voltage and
                  Frequency Scaling in a GPGPU}},
  year =	 2015,
  isbn =	 9781450340342,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/2830772.2830826},
  doi =		 {10.1145/2830772.2830826},
  abstract =	 {This paper presents CRISP, the first runtime
                  analytical model of performance in the face of
                  changing frequency in a GPGPU. It shows that prior
                  models not targeted at a GPGPU fail to account for
                  important characteristics of GPGPU execution,
                  including the high degree of overlap between memory
                  access and computation and the frequency of
                  store-related stalls.CRISP provides significantly
                  greater accuracy than prior runtime performance
                  models, being within 4\% on average when scaling
                  frequency by up to 7X. Using CRISP to drive a
                  runtime energy efficiency controller yields a 10.7\%
                  improvement in energy-delay product, vs 6.2\%
                  attainable via the best prior performance model.},
  booktitle =	 {{Proceedings of the 48th International Symposium on
                  Microarchitecture}},
  pages =	 {281–293},
  numpages =	 13,
  keywords =	 {DVFS, GPGPU, critical path},
  location =	 {Waikiki, Hawaii},
  series =	 {MICRO}
}

@inproceedings{MeiYung2013-gpuDVFSMeasure,
  author =	 {Mei, Xinxin and Yung, Ling Sing and Zhao, Kaiyong
                  and Chu, Xiaowen},
  title =	 {{A Measurement Study of GPU DVFS on Energy
                  Conservation}},
  year =	 2013,
  isbn =	 9781450324588,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/2525526.2525852},
  doi =		 {10.1145/2525526.2525852},
  abstract =	 {Nowadays, GPUs are widely used to accelerate many
                  high performance computing applications. Energy
                  conservation of such computing systems has become an
                  important research topic. Dynamic voltage/frequency
                  scaling (DVFS) is proved to be an appealing method
                  for saving energy for traditional computing
                  centers. However, there is still a lack of firsthand
                  study on the effectiveness of GPU DVFS. This paper
                  presents a thorough measurement study that aims to
                  explore how GPU DVFS affects the system energy
                  consumption. We conduct experiments on a real GPU
                  platform with 37 benchmark applications. Our results
                  show that GPU voltage/frequency scaling is an
                  effective approach to conserving energy. For
                  example, by scaling down the GPU core voltage and
                  frequency, we have achieved an average of 19.28\%
                  energy reduction compared with the default setting,
                  while giving up no more than 4\% of performance. For
                  all tested GPU applications, core voltage scaling is
                  significantly effective to reduce system energy
                  consumption. Meanwhile the effects of scaling core
                  frequency and memory frequency depend on the
                  characteristics of GPU applications.},
  booktitle =	 {{Proceedings of the Workshop on Power-Aware
                  Computing and Systems}},
  articleno =	 10,
  numpages =	 5,
  keywords =	 {voltage/frequency scaling, energy conservation, GPU},
  location =	 {Farmington, Pennsylvania},
  series =	 {HotPower}
}

@ARTICLE{LengBuyuktosunoglu2021-gpuGuardband,
  author =	 {Leng, Jingwen and Buyuktosunoglu, Alper and Bertran,
                  Ramon and Bose, Pradip and Zu, Yazhou and Reddi,
                  Vijay Janapa},
  journal =	 {{IEEE Transactions on Computer-Aided Design of
                  Integrated Circuits and Systems}},
  title =	 {{Predictive Guardbanding: Program-Driven Timing
                  Margin Reduction for GPUs}},
  year =	 2021,
  volume =	 40,
  number =	 1,
  pages =	 {171-184},
  doi =		 {10.1109/TCAD.2020.2992684}
}

@ARTICLE{KimShih2016-voltageReg,
  author =	 {Kim, Stephen T. and Shih, Yi-Chun and Mazumdar,
                  Kaushik and Jain, Rinkle and Ryan, Joseph F. and
                  Tokunaga, Carlos and Augustine, Charles and
                  Kulkarni, Jaydeep P. and Ravichandran, Krishnan and
                  Tschanz, James W. and Khellah, Muhammad M. and De,
                  Vivek},
  journal =	 {{IEEE Journal of Solid-State Circuits}},
  title =	 {{Enabling Wide Autonomous DVFS in a 22 nm Graphics
                  Execution Core Using a Digitally Controlled Fully
                  Integrated Voltage Regulator}},
  year =	 2016,
  volume =	 51,
  number =	 1,
  pages =	 {18-30},
  doi =		 {10.1109/JSSC.2015.2457920}
}

@INPROCEEDINGS{StraunbeLowePower2018-gpuCAPP,
  author =	 {Straube, Kramer and Lowe-Power, Jason and Nitta,
                  Christopher and Farrens, Matthew and Akella,
                  Venkatesh},
  booktitle =	 {{IEEE 25th International Conference on High
                  Performance Computing}},
  series =	 {HiPC},
  title =	 {{Improving Provisioned Power Efficiency in HPC
                  Systems with GPU-CAPP}},
  year =	 2018,
  pages =	 {112-122},
  doi =		 {10.1109/HiPC.2018.00021}
}

@inproceedings{NugterenVanDenBraak2014-rooflineGPUDVFS,
  author =	 {Nugteren, Cedric and van den Braak, Gert-Jan and
                  Corporaal, Henk},
  title =	 {{Roofline-Aware DVFS for GPUs}},
  year =	 2014,
  isbn =	 9781450325141,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/2553062.2553067},
  doi =		 {10.1145/2553062.2553067},
  abstract =	 {Graphics processing units (GPUs) are becoming
                  increasingly popular for compute workloads, mainly
                  because of their large number of processing elements
                  and high-bandwidth to off-chip memory. The roofline
                  model captures the ratio between the two (the
                  compute-memory ratio), an important architectural
                  parameter. This work proposes to change the
                  compute-memory ratio dynamically, scaling the
                  voltage and frequency (DVFS) of 1) memory for
                  compute-intensive workloads and 2) processing
                  elements for memory-intensive workloads. The result
                  is an adaptive roofline-aware GPU that increases
                  energy efficiency (up to 58\%) while maintaining
                  performance.},
  booktitle =	 {{Proceedings of International Workshop on Adaptive
                  Self-Tuning Computing Systems}},
  pages =	 {8–10},
  numpages =	 3,
  keywords =	 {Parallel Computing, GPU, The Roofline Model, DVFS},
  location =	 {Vienna, Austria},
  series =	 {ADAPT}
}

@misc{MishraKhare2016-gpuDVFSEval,
  title =	 {{Analysis of DVFS Techniques for Improving the GPU
                  Energy Efficiency}},
  author =	 {Mishra, Ashish and Khare, Nilay},
  year =	 2015,
  howpublished =
                  {\url{http://file.scirp.org/pdf/ojee_2015121415504865.pdf}},
}

@inproceedings{TangWang2019-gpuDVFSDL,
  author =	 {Tang, Zhenheng and Wang, Yuxin and Wang, Qiang and
                  Chu, Xiaowen},
  title =	 {{The Impact of GPU DVFS on the Energy and
                  Performance of Deep Learning: An Empirical Study}},
  year =	 2019,
  isbn =	 9781450366717,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/3307772.3328315},
  doi =		 {10.1145/3307772.3328315},
  abstract =	 {Over the past years, great progress has been made in
                  improving the computing power of general-purpose
                  graphics processing units (GPGPUs), which
                  facilitates the prosperity of deep neural networks
                  (DNNs) in multiple fields like computer vision and
                  natural language processing. A typical DNN training
                  process repeatedly updates tens of millions of
                  parameters, which not only requires huge computing
                  resources but also consumes significant energy. In
                  order to train DNNs in a more energy-efficient way,
                  we empirically investigate the impact of GPU Dynamic
                  Voltage and Frequency Scaling (DVFS) on the energy
                  consumption and performance of deep learning. Our
                  experiments cover a wide range of GPU architectures,
                  DVFS settings, and DNN configurations. We observe
                  that, compared to the default core frequency
                  settings of three tested GPUs, the optimal core
                  frequency can help conserve 8.7\%~23.1\% energy
                  consumption for different DNN training
                  cases. Regarding the inference, the benefits vary
                  from 19.6\%~26.4\%. Our findings suggest that GPU
                  DVFS has great potentials to help develop energy
                  efficient DNN training/inference schemes.},
  booktitle =	 {{Proceedings of the Tenth ACM International
                  Conference on Future Energy Systems}},
  pages =	 {315–325},
  numpages =	 11,
  keywords =	 {Graphics Processing Units, Dynamic Voltage and
                  Frequency Scaling, Deep Convolutional Neural
                  Network},
  location =	 {Phoenix, AZ, USA},
  series =	 {e-Energy}
}

@inproceedings{DuttaAdhinarayanan2018-gpuPowerPredML,
  author =	 {Dutta, Bishwajit and Adhinarayanan, Vignesh and
                  Feng, Wu-chun},
  title =	 {{GPU Power Prediction via Ensemble Machine Learning
                  for DVFS Space Exploration}},
  year =	 2018,
  isbn =	 9781450357616,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/3203217.3203273},
  doi =		 {10.1145/3203217.3203273},
  abstract =	 {A software-based approach to achieve high
                  performance within a power budget often involves
                  dynamic voltage and frequency scaling (DVFS). Thus,
                  accurately predicting the power consumption of an
                  application at different DVFS levels (or more
                  generally, different processor configurations) is
                  paramount for the energy-efficient functioning of a
                  high-performance computing (HPC) system. The
                  increasing prevalence of graphics processing units
                  (GPUs) in HPC systems presents new challenges in
                  power management, and machine learning presents an
                  unique way to improve the software-based power
                  management of these systems. As such, we explore the
                  problem of GPU power prediction at different DVFS
                  states via machine learning. Specifically, we
                  propose a new ensemble technique that incorporates
                  three machine-learning techniques --- sequential
                  minimal optimization regression, simple linear
                  regression, and decision tree --- to reduce the mean
                  absolute error (MAE) to 3.5\%.},
  booktitle =	 {{Proceedings of the 15th ACM International
                  Conference on Computing Frontiers}},
  pages =	 {240–243},
  numpages =	 4,
  location =	 {Ischia, Italy},
  series =	 {CF}
}

@inproceedings{FanCosenza2019-predGPUFreq,
  author =	 {Fan, Kaijie and Cosenza, Biagio and Juurlink, Ben},
  title =	 {{Predictable GPUs Frequency Scaling for Energy and
                  Performance}},
  year =	 2019,
  isbn =	 9781450362955,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/3337821.3337833},
  doi =		 {10.1145/3337821.3337833},
  abstract =	 {Dynamic voltage and frequency scaling (DVFS) is an
                  important solution to balance performance and energy
                  consumption, and hardware vendors provide management
                  libraries that allow the programmer to change both
                  memory and core frequencies. The possibility to
                  manually set these frequencies is a great
                  opportunity for application tuning, which can focus
                  on the best application-dependent setting. However,
                  this task is not straightforward because of the
                  large set of possible configurations and because of
                  the multi-objective nature of the problem, which
                  minimizes energy consumption and maximizes
                  performance.This paper proposes a method to predict
                  the best core and memory frequency configurations on
                  GPUs for an input OpenCL kernel. Our modeling
                  approach, based on machine learning, first predicts
                  speedup and normalized energy over the default
                  frequency configuration. Then, it combines the two
                  models into a multi-objective one that predicts a
                  Pareto-set of frequency configurations. The approach
                  uses static code features, is built on a set of
                  carefully designed micro-benchmarks, and can predict
                  the best frequency settings of a new kernel without
                  executing it. Test results show that our modeling
                  approach is very accurate on predicting extrema
                  points and Pareto set for ten out of twelve test
                  benchmarks, and discover frequency configurations
                  that dominate the default configuration in either
                  energy or performance.},
  booktitle =	 {{Proceedings of the 48th International Conference on
                  Parallel Processing}},
  articleno =	 52,
  numpages =	 10,
  keywords =	 {GPUs, Frequency scaling, Modeling, Energy
                  efficiency},
  location =	 {Kyoto, Japan},
  series =	 {ICPP 2019}
}

@misc{amd-power,
  author =	 {Chandrasekhar, Mithun},
  year =	 2019,
  title =	 {{AMD Radeon Community Update: More Control Over GPU
                  Power and Performance, Enhanced Thermal Monitoring,
                  Maximized Performance}},
  howpublished =
                  {\url{https://community.amd.com/t5/gaming/amd-radeon-community-update-more-control-over-gpu-power-and/ba-p/418629}},
}

@misc{vega11-maxTemp,
  author =	 {{SafeTemp}},
  title =	 {{AMD Radeon RX Vega 11 Max Temp}},
  year =	 2021,
  month =	 {November},
  howpublished =
                  {\url{https://safetemp.blogspot.com/2021/11/amd-radeon-rx-vega-11-max-temp.html}},
}

@article{Guerreiro-appClasses,
  title =	 {{DVFS-aware application classification to improve
                  GPGPUs energy efficiency}},
  journal =	 {Parallel Computing},
  volume =	 83,
  pages =	 {93-117},
  year =	 2019,
  issn =	 {0167-8191},
  doi =		 {https://doi.org/10.1016/j.parco.2018.02.001},
  url =
                  {https://www.sciencedirect.com/science/article/pii/S0167819118300243},
  author =	 {João Guerreiro and Aleksandar Ilic and Nuno Roma and
                  Pedro Tomás},
  keywords =	 {GPGPU, Application classification, DVFS, Optimal
                  frequency, Energy savings},
}

@misc{DRAMthermalissues,
  author =	 {Karen Heyman},
  title =	 {{DRAM Thermal Issues Reach Crisis Point}},
  howpublished =
                  {\url{https://semiengineering.com/dram-thermal-issues-reach-crisis-point/}},
  year =	 2022
}

@misc{SinhaGuliani2022-gpuPowerVar,
  doi =		 {10.48550/ARXIV.2208.11035},
  url =		 {https://arxiv.org/abs/2208.11035},
  author =	 {Sinha, Prasoon and Guliani, Akhil and Jain, Rutwik
                  and Tran, Brandon and Sinclair, Matthew D. and
                  Venkataraman, Shivaram},
  keywords =	 {Distributed, Parallel, and Cluster Computing
                  (cs.DC), FOS: Computer and information sciences,
                  FOS: Computer and information sciences},
  title =	 {{Not All GPUs Are Created Equal: Characterizing
                  Variability in Large-Scale, Accelerator-Rich
                  Systems}},
  publisher =	 {arXiv},
  year =	 2022,
  copyright =	 {arXiv.org perpetual, non-exclusive license}
}

@article{AcunLanger2016-power,
  author =	 {Acun, Bilge and Langer, Akhil and Meneses, Esteban
                  and Menon, Harshitha and Sarood, Osman and Totoni,
                  Ehsan and Kalé, Laxmikant V.},
  journal =	 {Computer},
  title =	 {{Power, Reliability, and Performance: One System to
                  Rule them All}},
  year =	 2016,
  volume =	 49,
  number =	 10,
  pages =	 {30-37},
  doi =		 {10.1109/MC.2016.310}
}

@inproceedings{AcunMiller2016-variationTurbo,
  author =	 {Acun, Bilge and Miller, Phil and Kale, Laxmikant V.},
  title =	 {{Variation Among Processors Under Turbo Boost in HPC
                  Systems}},
  year =	 2016,
  isbn =	 9781450343619,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/2925426.2926289},
  doi =		 {10.1145/2925426.2926289},
  abstract =	 {The design and manufacture of present-day CPUs
                  causes inherent variation in supercomputer
                  architectures such as variation in power and
                  temperature of the chips. The variation also
                  manifests itself as frequency differences among
                  processors under Turbo Boos\ t dynamic
                  overclocking. This variation can lead to
                  unpredictable and suboptimal performance in tightly
                  coupled HPC applications. In this study, we use
                  compute-intensive kernels and applications to
                  analyze the variation among processors in four top
                  supercomputers: Edison\ , Cab, Stampede, and Blue
                  Waters. We observe that there is an execution time
                  difference of up to 16\% among processors on the
                  Turbo Boost-enabled supercomputers: Edison, Cab,
                  Stampede. There is less than 1\% variation on Blue
                  Waters, which does not have a dynamic overcl\ ocking
                  feature. We analyze measurements from temperature
                  and power instrumentation and find that intrinsic
                  differences in the chips' power efficiency is the
                  culprit behind the frequency variation. Moreover, we
                  analyze potential solutions such as disabling Turbo
                  Boost, l\ eaving idle cores and replacing slow chips
                  to mitigate the variation. We also propose a
                  speed-aware dynamic task redistribution (load
                  balancing) algorithm to reduce the negative effects
                  of performance variation. Our speed-aware load
                  balancing algorithm improves the perf\ ormance up to
                  18\% compared to no load balancing performance and
                  6\% better than the non-speed aware counterpart.},
  booktitle =	 {{Proceedings of the 2016 International Conference on
                  Supercomputing}},
  articleno =	 6,
  numpages =	 12,
  location =	 {Istanbul, Turkey},
  series =	 {ICS '16}
}

@inproceedings{AcunKale2016-varLoadBal,
  author =	 {Acun, Bilge and Kale, Laxmikant V.},
  booktitle =	 {{IEEE International Parallel and Distributed
                  Processing Symposium Workshops}},
  series =	 {IPDPSW},
  title =	 {{Mitigating Processor Variation through Dynamic Load
                  Balancing}},
  year =	 2016,
  pages =	 {1073-1076},
  doi =		 {10.1109/IPDPSW.2016.74}
}

@inproceedings{AcunLee2017-proactiveCooling,
  author =	 {Acun, Bilge and Lee, Eun Kyung and Park, Yoonho and
                  Kale, Laxmikant V.},
  booktitle =	 {{IEEE 24th International Conference on High
                  Performance Computing}},
  series =	 {HiPC},
  title =	 {{Support for Power Efficient Proactive Cooling
                  Mechanisms}},
  year =	 2017,
  pages =	 {94-103},
  doi =		 {10.1109/HiPC.2017.00020}
}

@inproceedings{MenonAcun2013-thermAwareLoadBal,
  author =	 {Menon, Harshitha and Acun, Bilge and De Gonzalo,
                  Simon Garcia and Sarood, Osman and Kalé, Laxmikant},
  booktitle =	 {{IEEE International Conference on Cluster
                  Computing}},
  series =	 {CLUSTER},
  title =	 {{Thermal aware automated load balancing for HPC
                  applications}},
  year =	 2013,
  pages =	 {1-8},
  doi =		 {10.1109/CLUSTER.2013.6702627}
}

@inproceedings{SaroodLanger2014-throughputPowerBudget,
  author =	 {Sarood, Osman and Langer, Akhil and Gupta, Abhishek
                  and Kale, Laxmikant},
  booktitle =	 {{Proceedings of the International Conference for
                  High Performance Computing, Networking, Storage and
                  Analysis}},
  series =	 {SC},
  title =	 {{Maximizing Throughput of Overprovisioned HPC Data
                  Centers Under a Strict Power Budget}},
  year =	 2014,
  pages =	 {807-818},
  doi =		 {10.1109/SC.2014.71}
}

@inproceedings{AcunLee2016-nnFanControl,
  author =	 {Acun, Bilge and Lee, Eun Kyung and Park, Yoonho and
                  Kale, Laxmikant V.},
  booktitle =	 {{4th International Workshop on Energy Efficient
                  Supercomputing}},
  series =	 {E2SC},
  title =	 {{Neural Network-Based Task Scheduling with
                  Preemptive Fan Control}},
  year =	 2016,
  pages =	 {77-84},
  doi =		 {10.1109/E2SC.2016.016}
}

@inproceedings{ZhangOgrenci2015-minThermalVar,
  author =	 {Zhang, Kaicheng and Ogrenci-Memik, Seda and Memik,
                  Gokhan and Yoshii, Kazutomo and Sankaran, Rajesh and
                  Beckman, Pete},
  booktitle =	 {{IEEE International Parallel and Distributed
                  Processing Symposium}},
  series =	 {IPDPS},
  title =	 {{Minimizing Thermal Variation Across System
                  Components}},
  year =	 2015,
  pages =	 {1139-1148},
  doi =		 {10.1109/IPDPS.2015.37}
}

@inproceedings{SkinnerKramer2005-perfVarCauses,
  author =	 {Skinner, D. and Kramer, W.},
  booktitle =	 {{Proceedings of the IEEE Workload Characterization
                  Symposium}},
  series =	 {IISWC},
  title =	 {{Understanding the causes of performance variability
                  in HPC workloads}},
  year =	 2005,
  pages =	 {137-149},
  doi =		 {10.1109/IISWC.2005.1526010}
}

@inproceedings{AvalosKhairy2021-pka,
  author =	 {Avalos Baddouh, Cesar and Khairy, Mahmoud and Green,
                  Roland N. and Payer, Mathias and Rogers, Timothy G.},
  title =	 {{Principal Kernel Analysis: A Tractable Methodology
                  to Simulate Scaled GPU Workloads}},
  year =	 2021,
  isbn =	 9781450385572,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/3466752.3480100},
  doi =		 {10.1145/3466752.3480100},
  abstract =	 {Simulating all threads in a scaled GPU workload
                  results in prohibitive simulation cost. Cycle-level
                  simulation is orders of magnitude slower than native
                  silicon, the only solution is to reduce the amount
                  of work simulated while accurately representing the
                  program. Existing solutions to simulate GPU programs
                  either scale the input size, simulate the first
                  several billion instructions, or simulate a portion
                  of both the GPU and the workload. These solutions
                  lack validation against scaled systems, produce
                  unrealistic contention conditions and frequently
                  miss critical code sections. Existing CPU sampling
                  mechanisms, like SimPoint, reduce per-thread
                  workload, and are ill-suited to GPU programs where
                  reducing the number of threads is critical. Sampling
                  solutions on GPUs space lack silicon validation,
                  require per-workload parameter tuning, and do not
                  scale. A tractable solution, validated on
                  contemporary scaled workloads, is needed to provide
                  credible simulation results. By studying scaled
                  workloads with centuries-long simulation times, we
                  uncover practical and algorithmic limitations of
                  existing solutions and propose Principal Kernel
                  Analysis: a hierarchical program sampling
                  methodology that concisely represents GPU programs
                  by selecting representative kernel portions using a
                  scalable profiling methodology, tractable clustering
                  algorithm and detection of intra-kernel IPC
                  stability. We validate Principal Kernel Analysis
                  across 147 workloads and three GPU generations using
                  the Accel-Sim simulator, demonstrating a better
                  performance/error tradeoff than prior work and that
                  century-long MLPerf simulations are reduced to hours
                  with an average cycle error of 27\% versus silicon.},
  booktitle =	 {{54th Annual IEEE/ACM International Symposium on
                  Microarchitecture}},
  pages =	 {724–737},
  numpages =	 14,
  keywords =	 {Simulation methodology, GPU, Workload sampling},
  location =	 {Virtual Event, Greece},
  series =	 {MICRO '21}
}

@INPROCEEDINGS{WunderlichWenisch2003-smarts,
  author =	 {Wunderlich, R.E. and Wenisch, T.F. and Falsafi,
                  B. and Hoe, J.C.},
  booktitle =	 {{Proceedings of 30th Annual International Symposium
                  on Computer Architecture}},
  title =	 {{SMARTS: Accelerating Microarchitecture Simulation
                  via Rigorous Statistical Sampling}},
  year =	 2003,
  pages =	 {84-95},
  doi =		 {10.1109/ISCA.2003.1206991}
}

@misc{mlcommons-power,
  title =	 {{Best Practices Working Group: Power Working Group}},
  author =	 {{MLCommons}},
  howpublished =
                  {\url{https://mlcommons.org/en/groups/best-practices-power/}},
  year =	 2022,
}

@inproceedings{philly_atc19,
  author =	 {Jeon, Myeongjae and Venkataraman, Shivaram and
                  Phanishayee, Amar and Qian, unjie and Xiao, Wencong
                  and Yang, Fan},
  title =	 {Analysis of Large-Scale Multi-Tenant GPU Clusters
                  for DNN Training Workloads},
  year =	 2019,
  isbn =	 9781939133038,
  publisher =	 {USENIX Association},
  address =	 {USA},
  abstract =	 {With widespread advances in machine learning, a
                  number of large enterprises are beginning to
                  incorporate machine learning models across a number
                  of products. These models are typically trained on
                  shared, multi-tenant GPU clusters. Similar to
                  existing cluster computing workloads, scheduling
                  frameworks aim to provide features like high
                  efficiency, resource isolation, fair sharing across
                  users, etc. However Deep Neural Network (DNN) based
                  workloads, predominantly trained on GPUs, differ in
                  two significant ways from traditional big data
                  analytics workloads. First, from a cluster
                  utilization perspective, GPUs represent a monolithic
                  resource that cannot be shared at a fine granularity
                  across users. Second, from a workload perspective,
                  deep learning frameworks require gang scheduling
                  reducing the flexibility of scheduling and making
                  the jobs themselves inelastic to failures at
                  runtime. In this paper we present a detailed
                  workload characterization of a two-month long trace
                  from a multi-tenant GPU cluster in Microsoft. By
                  correlating scheduler logs with logs from individual
                  jobs, we study three distinct issues that affect
                  cluster utilization for DNN training workloads on
                  multi-tenant clusters: (1) the effect of gang
                  scheduling and locality constraints on queuing, (2)
                  the effect of locality on GPU utilization, and (3)
                  failures during training. Based on our experience
                  running a large-scale operation, we provide design
                  guidelines pertaining to next-generation cluster
                  schedulers for DNN training workloads.},
  booktitle =	 {Proceedings of the 2019 USENIX Conference on Usenix
                  Annual Technical Conference},
  pages =	 {947–960},
  numpages =	 14,
  location =	 {Renton, WA, USA},
  series =	 {USENIX ATC '19}
}

@INPROCEEDINGS{CheBeckmann2013,
  author =	 {Che, Shuai and Beckmann, Bradford M. and Reinhardt,
                  Stephen K. and Skadron, Kevin},
  booktitle =	 {{IEEE International Symposium on Workload
                  Characterization}},
  series =	 {{IISWC}},
  title =	 {{Pannotia: Understanding Irregular GPGPU Graph
                  Applications}},
  year =	 2013,
  pages =	 {185-195},
  keywords =	 {data mining;data structures;graph theory;graphics
                  processing units;parallel processing;pattern
                  clustering;scheduling;Pannotia;irregular GPGPU graph
                  applications;general-purpose data-parallel
                  applications;GPU-friendly applications;data
                  structures;access patterns;commercial
                  domains;scientific domains;graph mining;Web
                  analysis;social network analysis;graph
                  algorithms;SIMD architectures;data-dependent
                  behavior;branch and memory
                  divergence;OpenCL;clustering
                  analysis;Kernel;Labeling;Radiation detectors},
  doi =		 {10.1109/IISWC.2013.6704684},
  month =	 {9},
}

@article{mccalpin1995memory,
  title =	 {Memory bandwidth and machine balance in current high
                  performance computers},
  author =	 {McCalpin, John D and others},
  journal =	 {IEEE computer society technical committee on
                  computer architecture (TCCA) newsletter},
  volume =	 2,
  number =	 {19-25},
  year =	 1995
}

@article{WangPan2017-gunrock,
  author =	 {Wang, Yangzihao and Pan, Yuechao and Davidson,
                  Andrew and Wu, Yuduo and Yang, Carl and Wang, Leyuan
                  and Osama, Muhammad and Yuan, Chenshan and Liu,
                  Weitang and Riffel, Andy T. and Owens, John D.},
  title =	 {{Gunrock: GPU Graph Analytics}},
  year =	 2017,
  issue_date =	 {March 2017},
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  volume =	 4,
  number =	 1,
  issn =	 {2329-4949},
  url =		 {https://doi.org/10.1145/3108140},
  doi =		 {10.1145/3108140},
  abstract =	 {For large-scale graph analytics on the GPU, the
                  irregularity of data access and control flow, and
                  the complexity of programming GPUs, have presented
                  two significant challenges to developing a
                  programmable high-performance graph
                  library. “Gunrock,” our graph-processing system
                  designed specifically for the GPU, uses a
                  high-level, bulk-synchronous, data-centric
                  abstraction focused on operations on a vertex or
                  edge frontier. Gunrock achieves a balance between
                  performance and expressiveness by coupling
                  high-performance GPU computing primitives and
                  optimization strategies with a high-level
                  programming model that allows programmers to quickly
                  develop new graph primitives with small code size
                  and minimal GPU programming knowledge. We
                  characterize the performance of various optimization
                  strategies and evaluate Gunrock’s overall
                  performance on different GPU architectures on a wide
                  range of graph primitives that span from
                  traversal-based algorithms and ranking algorithms,
                  to triangle counting and bipartite-graph-based
                  algorithms. The results show that on a single GPU,
                  Gunrock has on average at least an order of
                  magnitude speedup over Boost and PowerGraph,
                  comparable performance to the fastest GPU hardwired
                  primitives and CPU shared-memory graph libraries,
                  such as Ligra and Galois, and better performance
                  than any other GPU high-level graph library.},
  journal =	 {ACM Trans. Parallel Comput.},
  month =	 {Aug},
  articleno =	 3,
  numpages =	 49,
  keywords =	 {GPU, Graph processing, runtime framework}
}

@techreport{LULESH:spec,
  title =	 {{H}ydrodynamics {C}hallenge {P}roblem, {L}awrence
                  {L}ivermore {N}ational {L}aboratory},
  number =	 {LLNL-TR-490254},
  location =	 {Livermore, CA},
  institution =	 {Lawrence Livermore National Laboratory},
  pages =	 {1-28},
  author =	 {Hornung, R. D. and Keasler, Jeff A. and Gokhale,
                  M. B.},
  year =	 2011,
}

@techreport{LULESH2:changes,
  author =	 {Karlin, Ian and Keasler, Jeff and Neely, Rob},
  title =	 {{LULESH 2.0 Updates and Changes}},
  institution =	 {Lawrence Livermore National Laboratory},
  number =	 {LLNL-TR-641973},
  location =	 {Livermore, CA},
  pages =	 {1-9},
  year =	 2013,
  month =	 {August}
}

@techreport{LULESH:prog,
  author =	 {Ian Karlin},
  title =	 {{LULESH Programming Model and Performance Ports
                  Overview}},
  institution =	 {Lawrence Livermore National Laboratory},
  number =	 {LLNL-TR-608824},
  location =	 {Livermore, CA},
  pages =	 {1-17},
  year =	 2012,
  month =	 {December}
}

@INPROCEEDINGS{IPDPS13:LULESH,
  AUTHOR =	 "Ian Karlin and Abhinav Bhatele and Jeff Keasler and
                  Bradford L. Chamberlain and Jonathan Cohen and
                  Zachary DeVito and Riyaz Haque and Dan Laney and
                  Edward Luke and Felix Wang and David Richards and
                  Martin Schulz and Charles Still",
  TITLE =	 "Exploring Traditional and Emerging Parallel
                  Programming Models using a Proxy Application",
  BOOKTITLE =	 "27th IEEE International Parallel \& Distributed
                  Processing Symposium",
  series =	 {IPDPS},
  ADDRESS =	 "Boston, USA",
  MONTH =	 may,
  YEAR =	 2013
}

@inproceedings{JainTran2024-pal,
  author =	 {Jain, Rutwik and Tran, Brandon and Chen, Keting and
                  Sinclair, Matthew D. and Venkataraman, Shivaram},
  title =	 {{PAL: A Variability-Aware Policy for Scheduling ML
                  Workloads in GPU Clusters}},
  booktitle =	 {{Proceedings of the International Conference for
                  High Performance Computing, Networking, Storage, and
                  Analysis}},
  series =	 {SC},
  year =	 2024,
  month =	 {November},
}

@inproceedings{YouXuan2024-gvarp,
  author =	 {You, Xin and Xuan, Zhibo and Yang, Hailong and Luan,
                  Zhongzhi and Liu, Yi and Qian, Depei},
  title =	 {{GVARP: Detecting Performance Variance on
                  Large-Scale Heterogeneous System}},
  booktitle =	 {{Proceedings of the International Conference for
                  High Performance Computing, Networking, Storage, and
                  Analysis}},
  series =	 {SC},
  year =	 2024,
}

@inproceedings{KandiahPeverelle2021-accelWattch,
  author =	 {Kandiah, Vijay and Peverelle, Scott and Khairy,
                  Mahmoud and Manjunath, Amogh and Pan, Junrui and
                  Rogers, Timothy G. and Aamodt, Tor M. and
                  Hardavellas, Nikos},
  title =	 {{AccelWattch: A Power Modeling Framework for Modern
                  GPUs}},
  booktitle =	 {{Proceedings of the 54th IEEE/ACM International
                  Symposium on Microarchitecture}},
  series =	 {MICRO},
  year =	 2021,
  month =	 {October}
}

@inproceedings{JamiesonChandrashekar2022-gap,
  title =	 {{GAP: gem5 GPU Accuracy Profiler}},
  author =	 {Jamieson, Charles and Chandrashekar, Anushka and
                  McDougall, Ian and M. D. Sinclair},
  year =	 2022,
  month =	 {June},
  booktitle =	 {{4th gem5 Users' Workshop}},
}

@inproceedings{RamadasKouchekinia2023-gap,
  title =	 {{Closing the Gap: Improving the Accuracy of gem5’s
                  GPU Models}},
  author =	 {Ramadas, Vishnu and Kouchekinia, Daniel and Osuji,
                  Ndubuisi and Sinclair, Matthew D.},
  year =	 2023,
  month =	 {June},
  booktitle =	 {{5th gem5 Users' Workshop}},
}

@inproceedings{RamadasKouchekinia2024-gap,
  title =	 {{Further Closing the GAP: Improving the Accuracy of
                  gem5’s GPU Models}},
  author =	 {Ramadas, Vishnu and Kouchekinia, Daniel and
                  Sinclair, Matthew D.},
  year =	 2024,
  month =	 {April},
  booktitle =	 {{6th Young Architects' Workshop}},
  series =	 {YArch},
}

@inproceedings{SunBaruah2019-mgpusim,
  author =	 {Sun, Yifan and Baruah, Trinayan and Mojumder, Saiful
                  A. and Dong, Shi and Gong, Xiang and Treadway, Shane
                  and Bao, Yuhui and Hance, Spencer and McCardwell,
                  Carter and Zhao, Vincent and Barclay, Harrison and
                  Ziabari, Amir Kavyan and Chen, Zhongliang and Ubal,
                  Rafael and Abell\'{a}n, Jos\'{e} L. and Kim, John
                  and Joshi, Ajay and Kaeli, David},
  title =	 {{MGPUSim: Enabling Multi-GPU Performance Modeling
                  and Optimization}},
  year =	 2019,
  isbn =	 9781450366694,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/3307650.3322230},
  doi =		 {10.1145/3307650.3322230},
  abstract =	 {The rapidly growing popularity and scale of
                  data-parallel workloads demand a corresponding
                  increase in raw computational power of Graphics
                  Processing Units (GPUs). As single-GPU platforms
                  struggle to satisfy these performance demands,
                  multi-GPU platforms have started to dominate the
                  high-performance computing world. The advent of such
                  systems raises a number of design challenges,
                  including the GPU microarchitecture, multi-GPU
                  interconnect fabric, runtime libraries, and
                  associated programming models. The research
                  community currently lacks a publicly available and
                  comprehensive multi-GPU simulation framework to
                  evaluate next-generation multi-GPU system designs.In
                  this work, we present MGPUSim, a cycle-accurate,
                  extensively validated, multi-GPU simulator, based on
                  AMD's Graphics Core Next 3 (GCN3) instruction set
                  architecture. MGPUSim comes with in-built support
                  for multi-threaded execution to enable fast,
                  parallelized, and accurate simulation.  In terms of
                  performance accuracy, MGPUSim differs by only 5.5%
                  on average from the actual GPU hardware. We also
                  achieve a 3.5\texttimes{} and a 2.5\texttimes{}
                  average speedup running functional emulation and
                  detailed timing simulation, respectively, on a
                  4-core CPU, while delivering the same accuracy as
                  serial simulation.We illustrate the flexibility and
                  capability of the simulator through two concrete
                  design studies. In the first, we propose the
                  Locality API, an API extension that allows the GPU
                  programmer to both avoid the complexity of multi-GPU
                  programming, while precisely controlling data
                  placement in the multi-GPU memory. In the second
                  design study, we propose Progressive Page Splitting
                  Migration (PASI), a customized multi-GPU memory
                  management system enabling the hardware to
                  progressively improve data placement. For a discrete
                  4-GPU system, we observe that the Locality API can
                  speed up the system by 1.6\texttimes{} (geometric
                  mean), and PASI can improve the system performance
                  by 2.6\texttimes{} (geometric mean) across all
                  benchmarks, compared to a unified 4-GPU platform.},
  booktitle =	 {{Proceedings of the 46th International Symposium on
                  Computer Architecture}},
  pages =	 {197–209},
  numpages =	 13,
  keywords =	 {memory management, multi-GPU systems, simulation},
  location =	 {Phoenix, Arizona},
  series =	 {ISCA '19}
}

@inproceedings{GPUWattch,
  author =	 {Leng, Jingwen and Hetherington, Tayler and
                  ElTantawy, Ahmed and Gilani, Syed and Kim, Nam Sung
                  and Aamodt, Tor M. and Reddi, Vijay Janapa},
  title =	 {{GPUWattch: Enabling Energy Optimizations in
                  GPGPUs}},
  booktitle =	 {{Proceedings of the 40th International Symposium on
                  Computer Architecture}},
  year =	 2013,
}

@inproceedings{hopper,
  author =	 {NVIDIA},
  title =	 {{NVIDIA H100 Tensor Core GPU Architecture}},
  booktitle =	 "{Proceedings of GPU Technology Conference}",
  series =	 {{GTC}},
  year =	 2022,
  howpublished =
                  {\url{https://resources.nvidia.com/en-us-tensor-core/gtc22-whitepaper-hopper}},
}

@misc{blackwell,
  title =	 {{NVIDIA Blackwell Architecture Technical Brief}},
  author =	 {{NVIDIA}},
  howpublished =
                  {\url{https://resources.nvidia.com/en-us-blackwell-architecture/blackwell-architecture-technical-brief}},
  year =	 2024,
}

@INPROCEEDINGS{RaghavanLuo2012-compSprint,
  author =	 {Raghavan, Arun and Luo, Yixin and Chandawalla, Anuj
                  and Papaefthymiou, Marios and Pipe, Kevin P. and
                  Wenisch, Thomas F. and Martin, Milo M. K.},
  booktitle =	 {IEEE International Symposium on High-Performance
                  Comp Architecture},
  series =	 {HPCA},
  title =	 {{Computational Sprinting}},
  year =	 2012,
  pages =	 {1-12},
  keywords =	 {Heating;Phase change
                  materials;Capacitance;Silicon;Thermal
                  conductivity;Mobile communication},
  doi =		 {10.1109/HPCA.2012.6169031}
}

@inproceedings{FanZahedi2016-compSprintGame,
  author =	 {Fan, Songchun and Zahedi, Seyed Majid and Lee,
                  Benjamin C.},
  title =	 {{The Computational Sprinting Game}},
  year =	 2016,
  isbn =	 9781450340915,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/2872362.2872383},
  doi =		 {10.1145/2872362.2872383},
  abstract =	 {Computational sprinting is a class of mechanisms
                  that boost performance but dissipate additional
                  power. We describe a sprinting architecture in which
                  many, independent chip multiprocessors share a power
                  supply and sprints are constrained by the chips'
                  thermal limits and the rack's power
                  limits. Moreover, we present the computational
                  sprinting game, a multi-agent perspective on
                  managing sprints. Strategic agents decide whether to
                  sprint based on application phases and system
                  conditions. The game produces an equilibrium that
                  improves task throughput for data analytics
                  workloads by 4-6\texttimes{} over prior greedy
                  heuristics and performs within 90\% of an upper
                  bound on throughput from a globally optimized
                  policy.},
  booktitle =	 {{Proceedings of the Twenty-First International
                  Conference on Architectural Support for Programming
                  Languages and Operating Systems}},
  pages =	 {561–575},
  numpages =	 15,
  keywords =	 {computational sprinting, energy efficiency, game
                  theory, performance},
  location =	 {Atlanta, Georgia, USA},
  series =	 {ASPLOS '16}
}

@inproceedings{MorrisSaravanan2018-compSprintSLO,
  author =	 {Morris, Nathaniel and Saravanan, Indrajeet and Cao,
                  Pollyanna and Ding, Jerry and Stewart, Christopher},
  title =	 {{SLO Computational Sprinting}},
  year =	 2018,
  isbn =	 9781450360111,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/3267809.3275452},
  doi =		 {10.1145/3267809.3275452},
  booktitle =	 {{Proceedings of the ACM Symposium on Cloud
                  Computing}},
  pages =	 510,
  numpages =	 1,
  keywords =	 {Resource Management, Queuing Models, Computational
                  Sprinting},
  location =	 {Carlsbad, CA, USA},
  series =	 {SoCC '18}
}

@INPROCEEDINGS{MorrisRenganathan2016-compSprintSW,
  author =	 {Morris, Nathaniel and Renganathan, Siva Meenakshi
                  and Stewart, Christopher and Birke, Robert and Chen,
                  Lydia},
  booktitle =	 {{IEEE International Conference on Autonomic
                  Computing}},
  series =	 {ICAC},
  title =	 {{Sprint Ability: How Well Does Your Software Exploit
                  Bursts in Processing Capacity?}},
  year =	 2016,
  pages =	 {173-178},
  keywords =	 {Time factors;Software;Computational
                  modeling;Delays;Resource management;Adaptation
                  models;sprinting;sprintability;queuing;dvfs;burst},
  doi =		 {10.1109/ICAC.2016.61}
}

@INPROCEEDINGS{YangAdamek2024-gpuPowerMeas,
  author =	 {Yang, Zeyu and Adamek, Karel and Armour, Wesley },
  booktitle =	 {{International Conference for High Performance
                  Computing, Networking, Storage and Analysis SC}},
  title =	 {{Accurate and Convenient Energy Measurements for
                  GPUs: A Detailed Study of NVIDIA GPU’s Built-In
                  Power Sensor}},
  year =	 2024,
  pages =	 {307-323},
  abstract =	 {GPU has emerged as the go-to accelerator for HPC
                  workloads, however its power consumption has become
                  a major limiting factor for further scaling HPC
                  systems. An accurate understanding of GPU power
                  consumption is essential for further improving its
                  energy efficiency, and consequently reducing the
                  associated carbon footprint. Despite the limited
                  documentation and lack of understanding, NVIDIA
                  GPUs’ built-in power sensor is widely used in
                  energy-efficient computing research. Our study seeks
                  to elucidate the internal mechanisms of the power
                  readings provided by nvidia-smi and assess the
                  accuracy of the measurements. We evaluated over 70
                  different GPUs across 12 architectural generations,
                  and identified several unforeseen problems that can
                  lead to drastic under/overestimation of energy
                  consumed, for example on the A100 and H100 GPUs only
                  25% of the runtime is sampled. We proposed several
                  mitigations that could reduce the energy measurement
                  error by an average of 35% in the test cases we
                  present.},
  keywords =	 {High performance computing;Green computing;Energy
                  consumption;Energy measurement;Power measurement},
  doi =		 {10.1109/SC41406.2024.00028},
  url =
                  {https://doi.ieeecomputersociety.org/10.1109/SC41406.2024.00028},
  publisher =	 {IEEE Computer Society},
  address =	 {Los Alamitos, CA, USA},
  month =	 {Nov},
}

@inproceedings{Stelmach2023-sysPower,
  author =	 {Stelmach, Shane},
  title =	 {{System Power Integrity Analysis: from the PMIC to
                  the Transistor}},
  booktitle =	 {{Proceedings of the 61st Design Automation
                  Conference}},
  series =	 {DAC},
  year =	 2023
}

@INPROCEEDINGS{FelixMorton2023-waferCapacitors,
  author =	 {Felix, Stephen and Morton, Shannon and Stacey, Simon
                  and Walsh, John},
  booktitle =	 {{IEEE International Solid-State Circuits
                  Conference}},
  series =	 {ISSCC},
  title =	 {{29.4 Wafer-Level Stacking of High-Density
                  Capacitors to Enhance the Performance of a Large
                  Multicore Processor for Machine Learning
                  Applications}},
  year =	 2023,
  pages =	 {424-426},
  keywords =	 {Multicore processing;Capacitors;Stacking;Random
                  access memory;Voltage;Machine learning;Packaging},
  doi =		 {10.1109/ISSCC42615.2023.10067282}
}

@INPROCEEDINGS{NithinShanmugam2010-voltageDrop,
  author =	 {Nithin, S K and Shanmugam, Gowrysankar and
                  Chandrasekar, Sreeram},
  booktitle =	 {{11th International Symposium on Quality Electronic
                  Design}},
  series =	 {ISQED},
  title =	 {{Dynamic Voltage (IR) Drop Analysis and Design
                  Closure: Issues and Challenges}},
  year =	 2010,
  pages =	 {611-617},
  keywords =	 {Voltage;Robustness;Switches;Power distribution;Power
                  grids;Power system dynamics;Switching
                  circuits;Design methodology;Energy
                  management;Timing;Dynamic voltage Drop;DvD;Dynamic
                  IR;Peak power;Power switch;VCD;Power gate;SDF},
  doi =		 {10.1109/ISQED.2010.5450515}
}

@inproceedings{Austin2006-razor,
  author =	 {Austin, Todd},
  title =	 {{Razor: A Low-power Pipeline Based on Circuit-level
                  Timing Speculation}},
  year =	 2006,
  isbn =	 1595934790,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/1150343.1150348},
  doi =		 {10.1145/1150343.1150348},
  abstract =	 {With increasing clock frequencies and silicon
                  integration, power aware computing has become a
                  critical concern in the design of embedded
                  processors and systems-on-chip. One of the more
                  effective and widely used methods for power-aware
                  computing is dynamic voltage scaling (DVS). In order
                  to obtain the maximum power savings from DVS, it is
                  essential to scale the supply voltage as low as
                  possible while ensuring correct operation of the
                  processor. The critical voltage is chosen such that
                  under a worst-case scenario of process and
                  environmental variations, the processor always
                  operates correctly. However, this approach leads to
                  a very conservative supply voltage since such a
                  worst-case combination of different variabilities
                  will be very rare.In this talk, I detail a novel
                  approach to DVS, called Razor, based on dynamic
                  detection and correction of circuit timing
                  errors. The key idea of Razor is to tune the supply
                  voltage by monitoring the error rate during circuit
                  operation, thereby eliminating the need for voltage
                  margins and exploiting the data dependence of
                  circuit delay. A Razor flip-flop is introduced that
                  double-samples pipeline stage values, once with a
                  fast clock and again with a time-borrowing delayed
                  clock. A metastability tolerant comparator then
                  validates latch values sampled with the fast
                  clock. In the event of a timing error, a modified
                  pipeline mispeculation recovery mechanism restores
                  correct program state. A prototype Razor processor
                  will be described, along with physical
                  measurements.},
  booktitle =	 {{Proceedings of the 19th Annual Symposium on
                  Integrated Circuits and Systems Design}},
  pages =	 13,
  numpages =	 1,
  location =	 {Ouro Preto, MG, Brazil},
  series =	 {SBCCI '06}
}

@inproceedings{godoy2023software,
  title =	 {{Software Engineering to Sustain a High-performance
                  Computing Scientific Application: QMCPACK}},
  author =	 {Godoy, William F. and Hahn, Steven E. and Walsh,
                  Michael M. and Fackler, Philip W. and Krogel, Jaron
                  T. and Doak, Peter W. and Paul R. C. Kent and
                  Alfredo A. Correa and Ye Luo and Mark Dewing},
  year =	 2023,
  doi =		 {10.5281/zenodo.10420939},
  booktitle =	 {Proceedings of the 1st Annual Conference of the US
                  Research Software Engineering Association,
                  USRSE2023}
}

@article{kim2018qmcpack,
  title =	 {{QMCPACK: An Open Source ab initio Quantum Monte
                  Carlo Package for the Electronic Structure of Atoms,
                  Molecules and Solids}},
  author =	 {Kim, Jeongnim and Baczewski, Andrew D and Beaudet,
                  Todd D and Benali, Anouar and Bennett, M Chandler
                  and Berrill, Mark A and Blunt, Nick S and Borda,
                  Edgar Josu{\'e} Landinez and Casula, Michele and
                  Ceperley, David M and others},
  journal =	 {Journal of Physics: Condensed Matter},
  volume =	 30,
  number =	 19,
  pages =	 195901,
  year =	 2018,
  publisher =	 {IOP Publishing}
}

@article{WangZhang2018-deepmd,
  title =	 {{DeePMD-kit: A deep learning package for many-body
                  potential energy representation and molecular
                  dynamics}},
  journal =	 {{Computer Physics Communications}},
  volume =	 228,
  pages =	 {178-184},
  year =	 2018,
  issn =	 {0010-4655},
  doi =		 {https://doi.org/10.1016/j.cpc.2018.03.016},
  url =
                  {https://www.sciencedirect.com/science/article/pii/S0010465518300882},
  author =	 {Wang, Han and Zhang, Linfeng and Han, Jiequn and E,
                  Weinan},
  keywords =	 {Many-body potential energy, Molecular dynamics, Deep
                  neural networks},
  abstract =	 {Recent developments in many-body potential energy
                  representation via deep learning have brought new
                  hopes to addressing the accuracy-versus-efficiency
                  dilemma in molecular simulations. Here we describe
                  DeePMD-kit, a package written in Python/C++ that has
                  been designed to minimize the effort required to
                  build deep learning based representation of
                  potential energy and force field and to perform
                  molecular dynamics. Potential applications of
                  DeePMD-kit span from finite molecules to extended
                  systems and from metallic systems to chemically
                  bonded systems. DeePMD-kit is interfaced with
                  TensorFlow, one of the most popular deep learning
                  frameworks, making the training process highly
                  automatic and efficient. On the other end,
                  DeePMD-kit is interfaced with high-performance
                  classical molecular dynamics and quantum
                  (path-integral) molecular dynamics packages, i.e.,
                  LAMMPS and the i-PI, respectively. Thus, upon
                  training, the potential energy and force field
                  models can be used to perform efficient molecular
                  simulations for different purposes. As an example of
                  the many potential applications of the package, we
                  use DeePMD-kit to learn the interatomic potential
                  energy and forces of a water model using data
                  obtained from density functional theory. We
                  demonstrate that the resulted molecular dynamics
                  model reproduces accurately the structural
                  information contained in the original model.
                  Program summary Program Title: DeePMD-kit Program
                  Files doi: http://dx.doi.org/10.17632/hvfh9yvncf.1
                  Licensing provisions: LGPL Programming language:
                  Python/C++ Nature of problem: Modeling the many-body
                  atomic interactions by deep neural network
                  models. Running molecular dynamics simulations with
                  the models. Solution method: The Deep Potential for
                  Molecular Dynamics (DeePMD) method is implemented
                  based on the deep learning framework
                  TensorFlow. Supports for using a DeePMD model in
                  LAMMPS and i-PI, for classical and quantum (path
                  integral) molecular dynamics are
                  provided. Additional comments including Restrictions
                  and Unusual features: The code defines a data
                  protocol such that the energy, force, and virial
                  calculated by different third-party molecular
                  simulation packages can be easily processed and used
                  as model training data.}
}

@article{ZengZhang2023-deepmd2,
  author =	 {Zeng, Jinzhe and Zhang, Duo and Lu, Denghui and Mo,
                  Pinghui and Li, Zeyu and Chen, Yixiao and Rynik,
                  Marián and Huang, Li’ang and Li, Ziyao and Shi,
                  Shaochen and Wang, Yingze and Ye, Haotian and Tuo,
                  Ping and Yang, Jiabin and Ding, Ye and Li, Yifan and
                  Tisi, Davide and Zeng, Qiyu and Bao, Han and Xia, Yu
                  and Huang, Jiameng and Muraoka, Koki and Wang, Yibo
                  and Chang, Junhan and Yuan, Fengbo and Bore,
                  Sigbjørn Løland and Cai, Chun and Lin, Yinnian and
                  Wang, Bo and Xu, Jiayan and Zhu, Jia-Xin and Luo,
                  Chenxing and Zhang, Yuzhi and Goodall, Rhys
                  E. A. and Liang, Wenshuo and Singh, Anurag Kumar and
                  Yao, Sikai and Zhang, Jingchao and Wentzcovitch,
                  Renata and Han, Jiequn and Liu, Jie and Jia, Weile
                  and York, Darrin M. and E, Weinan and Car, Roberto
                  and Zhang, Linfeng and Wang, Han},
  title =	 "{DeePMD-kit v2: A software package for deep
                  potential models}",
  journal =	 {The Journal of Chemical Physics},
  volume =	 159,
  number =	 5,
  pages =	 054801,
  year =	 2023,
  month =	 08,
  abstract =	 "{DeePMD-kit is a powerful open-source software
                  package that facilitates molecular dynamics
                  simulations using machine learning potentials known
                  as Deep Potential (DP) models. This package, which
                  was released in 2017, has been widely used in the
                  fields of physics, chemistry, biology, and material
                  science for studying atomistic systems. The current
                  version of DeePMD-kit offers numerous advanced
                  features, such as DeepPot-SE, attention-based and
                  hybrid descriptors, the ability to fit tensile
                  properties, type embedding, model deviation,
                  DP-range correction, DP long range, graphics
                  processing unit support for customized operators,
                  model compression, non-von Neumann molecular
                  dynamics, and improved usability, including
                  documentation, compiled binary packages, graphical
                  user interfaces, and application programming
                  interfaces. This article presents an overview of the
                  current major version of the DeePMD-kit package,
                  highlighting its features and technical
                  details. Additionally, this article presents a
                  comprehensive procedure for conducting molecular
                  dynamics as a representative application, benchmarks
                  the accuracy and efficiency of different models, and
                  discusses ongoing developments.}",
  issn =	 {0021-9606},
  doi =		 {10.1063/5.0155600},
  url =		 {https://doi.org/10.1063/5.0155600},
  eprint =
                  {https://pubs.aip.org/aip/jcp/article-pdf/doi/10.1063/5.0155600/18281511/054801\_1\_5.0155600.pdf},
}

@misc{openfold2,
  title =	 {{OpenFold2: Replicating AlphaFold2 in the Dark}},
  author =	 {Derevyanko, Georgy and Lamoureux, Guillame and
                  Outeiral, Carlos and Oda, Toshiyuki and Fuchs,
                  Fabian and Mahajan, Sai Pooja and Moult, John and
                  Haas, Juergen and Maragakis, Paul and Ruzmetov,
                  Talant and AlQuraishi, Mohammed},
  year =	 2023,
  howpublished = {\url{https://lupoglaz.github.io/OpenFold2/}},
}

@article{Stevens2023-auroraGPT,
  title =	 {{Argonne's "AuroraGPT" Project}},
  author =	 {Stevens, Rick},
  year =	 2023,
  journal =	 {{Trillion Parameter Consortium Seminar}},
  series =	 {TPC},
}

@inproceedings{WuTaylor2019-candle,
  author =	 {Wu, Xingfu and Taylor, Valerie and Wozniak, Justin M. and Stevens, Rick and Brettin, Thomas and Xia, Fangfang},
  title =	 {{Performance, Energy, and Scalability Analysis and Improvement of Parallel Cancer Deep Learning CANDLE Benchmarks}},
  year =	 2019,
  isbn =	 9781450362955,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/3337821.3337905},
  doi =		 {10.1145/3337821.3337905},
  abstract =	 {Training scientific deep learning models requires
                  the significant compute power of high-performance
                  computing systems. In this paper, we analyze the
                  performance characteristics of the benchmarks from
                  the exploratory research project CANDLE (Cancer
                  Distributed Learning Environment) with a focus on
                  the hyperparameters epochs, batch sizes, and
                  learning rates. We present the parallel methodology
                  that uses the distributed deep learning framework
                  Horovod to parallelize the CANDLE benchmarks. We
                  then use scaling strategies for both epochs and
                  batch size with linear learning rate scaling to
                  investigate how they impact the execution time and
                  accuracy as well as the power, energy, and
                  scalability of the parallel CANDLE benchmarks under
                  conditions of strong scaling and weak scaling on the
                  IBM Power9 heterogeneous system Summit at Oak Ridge
                  National Laboratory and the Cray XC40 Theta at
                  Argonne National Laboratory. This study provides
                  insights into how to set the proper numbers of
                  epochs, batch sizes, and compute resources for these
                  benchmarks to preserve the high accuracy and to
                  reduce the execution time of the benchmarks. We
                  identify the data-loading performance bottleneck and
                  then improve the performance and energy for better
                  scalability. Results with the modified benchmarks on
                  Summit indicate up to 78.25\% in performance
                  improvement and up to 78\% in energy saving under
                  strong scaling on up to 384 GPUs, and up to 79.5\%
                  in performance improvement and up to 77.11\% in
                  energy saving under weak scaling on up to 3,072
                  GPUs. On Theta, we achieve up to 45.22\% performance
                  improvement and up to 41.78\% in energy saving under
                  strong scaling on up to 384 nodes. Moreover, the
                  modification dramatically reduces the broadcast
                  overhead.},
  booktitle =	 {{Proceedings of the 48th International Conference on
                  Parallel Processing}},
  articleno =	 78,
  numpages =	 11,
  keywords =	 {CANDLE benchmarks, Deep learning, Horovod,
                  TensorFlow, energy, performance improvement},
  location =	 {Kyoto, Japan},
  series =	 {ICPP},
}

@InProceedings{ThiyagalingamVonLaszewski2022-aiForSciMLCommons,
  author =	 "Thiyagalingam, Jeyan and von Laszewski, Gregor and
                  Yin, Junqi and Emani, Murali and Papay, Juri and
                  Barrett, Gregg and Luszczek, Piotr and Tsaris,
                  Aristeidis and Kirkpatrick, Christine and Wang,
                  Feiyi and Gibbs, Tom and Vishwanath, Venkatram and
                  Shankar, Mallikarjun and Fox, Geoffrey and Hey,
                  Tony",
  editor =	 "Anzt, Hartwig and Bienz, Amanda and Luszczek, Piotr
                  and Baboulin, Marc",
  title =	 "AI Benchmarking for Science: Efforts from the MLCommons Science Working Group",
  booktitle =	 "High Performance Computing. ISC High Performance
                  2022 International Workshops",
  year =	 2022,
  publisher =	 "Springer International Publishing",
  address =	 "Cham",
  pages =	 "47--64",
  abstract =	 "With machine learning (ML) becoming a transformative
                  tool for science, the scientific community needs a
                  clear catalogue of ML techniques, and their relative
                  benefits on various scientific problems, if they
                  were to make significant advances in science using
                  AI. Although this comes under the purview of
                  benchmarking, conventional benchmarking initiatives
                  are focused on performance, and as such, science,
                  often becomes a secondary criteria.",
  isbn =	 "978-3-031-23220-6"
}

@article{ThiyagalingamShankar2022-mlSci,
  title =	 {{Scientific Machine Learning Benchmarks}},
  author =	 {Thiyagalingam, Jeyan and Shankar, Mallikarjun and
                  Fox, Geoffrey and Hey, Tony},
  journal =	 {Nature Reviews Physics},
  volume =	 4,
  number =	 6,
  pages =	 {413--420},
  year =	 2022,
  publisher =	 {Nature Publishing Group UK London}
}

@article{ColemanNarayanan2017-dawnbench,
  title =	 {{DAWNBench: An end-to-end Deep Learning Benchmark
                  and Competition}},
  author =	 {Coleman, Cody and Narayanan, Deepak and Kang, Daniel
                  and Zhao, Tian and Zhang, Jian and Nardi, Luigi and
                  Bailis, Peter and Olukotun, Kunle and R{\'e}, Chris
                  and Zaharia, Matei},
  journal =	 {Training},
  volume =	 100,
  number =	 101,
  pages =	 102,
  year =	 2017
}

@inproceedings{DeBardeleben-LBNL-EuroPar13,
  author =	 {Nathan DeBardeleben and Sean Blanchard and Laura
                  Monroe and Philip Romero and Daryl Grunau and Craig
                  Idler and Cornell Wright},
  editor =	 {Dieter an Mey and Michael Alexander and Paolo
                  Bientinesi and Mario Cannataro and Carsten Clauss
                  and Alexandru Costan and Gabor Kecskemeti and
                  Christine Morin and Laura Ricci and Julio Sahuquillo
                  and Martin Schulz and Vittorio Scarano and Stephen
                  L. Scott and Josef Weidendorfer},
  title =	 {{{GPU} Behavior on a Large {HPC} Cluster}},
  booktitle =	 {Euro-Par 2013: Parallel Processing Workshops -
                  BigDataCloud, DIHC, FedICI, HeteroPar, HiBB, LSDVE,
                  MHPC, OMHI, PADABS, PROPER, Resilience, ROME, and
                  {UCHPC} 2013, Aachen, Germany, August 26-27,
                  2013. Revised Selected Papers},
  series =	 {Lecture Notes in Computer Science},
  volume =	 8374,
  pages =	 {680--689},
  publisher =	 {Springer},
  year =	 2013,
  url =		 {https://doi.org/10.1007/978-3-642-54420-0_66},
  doi =		 {10.1007/978-3-642-54420-0\_66},
  timestamp =	 {Wed, 19 Feb 2020 14:52:57 +0100},
  biburl =
                  {https://dblp.org/rec/conf/europar/DeBardelebenBMRGIW13.bib},
  bibsource =	 {dblp computer science bibliography,
                  https://dblp.org}
}

@ARTICLE{Fraternali-EEHPCVar-2018,
  author =	 {Fraternali, Francesco and Bartolini, Andrea and
                  Cavazzoni, Carlo and Benini, Luca},
  journal =	 {IEEE Transactions on Parallel and Distributed
                  Systems},
  title =	 {{Quantifying the Impact of Variability and
                  Heterogeneity on the Energy Efficiency for a
                  Next-Generation Ultra-Green Supercomputer}},
  year =	 2018,
  volume =	 29,
  number =	 7,
  pages =	 {1575-1588},
  keywords =	 {Supercomputers;Frequency measurement;Computer
                  architecture;Power measurement;Hardware;Energy
                  measurement;Program
                  processors;Green500;high-performance
                  computing;hardware variability;energy-efficient
                  software design;energy-aware computing;green
                  supercomputer;heterogeneous supercomputer;dynamic
                  resource management;hardware accelerator;DVFS},
  doi =		 {10.1109/TPDS.2017.2766151}
}

@article{DBLP:journals/corr/abs-2102-06604,
  author =	 {Frank Schneider and Felix Dangel and Philipp Hennig},
  title =	 {Cockpit: {A} Practical Debugging Tool for Training
                  Deep Neural Networks},
  journal =	 {CoRR},
  volume =	 {abs/2102.06604},
  year =	 2021,
  url =		 {https://arxiv.org/abs/2102.06604},
  eprinttype =	 {arXiv},
  eprint =	 {2102.06604},
  timestamp =	 {Mon, 06 Mar 2023 15:08:32 +0100},
  biburl =
                  {https://dblp.org/rec/journals/corr/abs-2102-06604.bib},
  bibsource =	 {dblp computer science bibliography,
                  https://dblp.org}
}

@misc{zhao2024deepcontextcontextawarecrossplatformcrossframework,
  title =	 {DeepContext: A Context-aware, Cross-platform, and
                  Cross-framework Tool for Performance Profiling and
                  Analysis of Deep Learning Workloads},
  author =	 {Qidong Zhao and Hao Wu and Yuming Hao and Zilingfeng
                  Ye and Jiajia Li and Xu Liu and Keren Zhou},
  year =	 2024,
  eprint =	 {2411.02797},
  howpublished ={arXiv},
  primaryClass = {cs.PF},
  url =		 {https://arxiv.org/abs/2411.02797},
}

@article{binkert2011gem5,
  title={The gem5 simulator},
  author = {Binkert, Nathan and Beckmann, Bradford and Black, Gabriel and
  Reinhardt, Steven K. and Saidi, Ali and Basu, Arkaprava and Hestness, Joel and
  Hower, Derek R. and Krishna, Tushar and Sardashti, Somayeh and Sen, Rathijit
  and Sewell, Korey and Shoaib, Muhammad and Vaish, Nilay and Hill, Mark D. and
  Wood, David A.},
  journal={ACM SIGARCH Computer Architecture News},
  volume={39},
  number={2},
  pages={1--7},
  year={2011},
  publisher={ACM}
}

@inproceedings{RamadasPoremba2023-gem5GPUFS,
  title = {{Improving gem5’s GPU FS Support}},
  author = {Ramadas, Vishnu and Poremba, Matthew and Beckmann, Bradford M. and Sinclair, Matthew D.},
  booktitle = {{The 5th gem5 Users’ Workshop}},
  year = {2023},
  month = {6},
}

@inproceedings{RamadasPoremba2024-gem5MLSim,
  author = {Ramadas, Vishnu and Poremba, Matthew and Beckmann, Bradford M. and Sinclair, Matthew D.},
  title = {{Simulation Support for Fast and Accurate Large-Scale GPGPU and Accelerator Workloads}},
  year = {2024},
  booktitle = {{3rd Open-Source Computer Architecture Research Workshop}},
  series = {OSCAR},
}

@inproceedings{SmithBruce2024-gem5Power,
  author = {Smith, Alex and Bruce, Bobby and Lowe-Power, Jason and Sinclair, Matthew D.},
  title = {{Designing Generalizable Power Models For Open-Source Architecture Simulators}},
  year = {2024},
  booktitle = {{3rd Open-Source Computer Architecture Research Workshop}},
  series = {OSCAR},
}

@inproceedings{RamadasSinclair2024-gem5MLSim,
  author = {Ramadas, Vishnu and Sinclair, Matthew D.},
  title = {{Simulating Machine Learning Models at Scale}},
  year = {2024},
  booktitle = {{SRC TECHCON}},
  month = {9},
}

@article{RodriguesHemmert2011-sst,
  author = {Rodrigues, A. F. and Hemmert, K. S. and Barrett, B. W. and Kersey, C. and Oldfield, R. and Weston, M. and Risen, R. and Cook, J. and Rosenfeld, P. and Cooper-Balis, E. and Jacob, B.},
  title = {{The Structural Simulation Toolkit}},
  year = {2011},
  issue_date = {March 2011},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {38},
  number = {4},
  issn = {0163-5999},
  url = {https://doi.org/10.1145/1964218.1964225},
  doi = {10.1145/1964218.1964225},
  abstract = {As supercomputers grow, understanding their behavior and performance has become increasingly challenging. New hurdles in scalability, programmability, power consumption, reliability, cost, and cooling are emerging, along with new technologies such as 3D integration, GP-GPUs, silicon-photonics, and other "game changers". Currently, they HPC community lacks a unified toolset to evaluate these technologies and design for these challenges.To address this problem, a number of institutions have joined together to create the Structural Simulation Toolkit (SST), an open, modular, parallel, multi-criteria, multi-scale simulation framework. The SST includes a number of processor, memory, and network models. The SST has been used in a variety of network, memory, and application studies and aims to become the standard simulation framework for designing and procuring HPC systems.},
  journal = {SIGMETRICS Perform. Eval. Rev.},
  month = mar,
  pages = {37–42},
  numpages = {6},
  keywords = {simulation, performance analysis, architecture, SST}
}

@article{SST,
  title = {{ERAS: Enabling the Integration of Real-World Intellectual Properties (IPs) in Architectural Simulators}},
  author = {Nema, Shubham and Razdan, Rohin and Rodrigues, Arun and Hemmert, Karl and Voskuilen, Gwendolyn and Adak, Debratim and Hammond, Simon and Awad, Amro and Hughes, Clayton},
  abstractNote = {Sandia National Laboratories is investigating scalable architectural simulation capabilities with a focus on simulating and evaluating highly scalable supercomputers for high performance comput- ing applications. There is a growing demand for RTL model integration to provide the capability to simulate customized node architectures and heterogeneous systems. This report describes the ?rst steps integrating the ESSENTial Signal Simulation Enabled by Netlist Transforms (ESSENT) tool with the Structural Simulation Toolkit (SST). ESSENT can emit C++ models from models written in FIRRTL to automatically generate components. The integration work?ow will automatically generate the SST component and necessary interfaces to ?plug? the ESSENT model into the SST framework.},
  doi = {10.2172/1854734},
  url = {https://www.osti.gov/biblio/1854734},
  journal = {Sandia National Labs Tech Report},
  number = {},
  volume = {},
  place = {United States},
  year = {2021},
  month = {9}
}

@inproceedings{nguyen2022gem5sst,
 title = {{gem5/SST Integration 2021: Scaling Full-system Simulations}},
 author = {Hoa Nguyen and Jason Lowe-Power},
 booktitle = {The 4th gem5 Users’ Workshop with ISCA},
 year = {2022}
}

@inproceedings{hsieh2012gem5sst,
  author = {Hsieh, Mingyu and Pedretti, Kevin and Meng, Jie and Coskun, Ayse and Levenhagen, Michael and Rodrigues, Arun},
  title = {{SST + Gem5 = a Scalable Simulation Infrastructure for High Performance Computing}},
  year = {2012},
  isbn = {9781450315104},
  publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
  address = {Brussels, BEL},
  booktitle = {{Proceedings of the 5th International ICST Conference on Simulation Tools and Techniques}},
  pages = {196–201},
  numpages = {6},
  keywords = {architecture, simulation},
  location = {Desenzano del Garda, Italy},
  series = {SIMUTOOLS '12}
}

@INPROCEEDINGS{RogersSlycord2020-gem5Salam,
  author={Rogers, Samuel and Slycord, Joshua and Baharani, Mohammadreza and Tabkhi, Hamed},
  booktitle={{53rd Annual IEEE/ACM International Symposium on Microarchitecture}},
  series = {MICRO},
  title={{gem5-SALAM: A System Architecture for LLVM-based Accelerator Modeling}},
  year={2020},
  volume={},
  number={},
  pages={471-482},
  doi={10.1109/MICRO50266.2020.00047}
}

@article{SpencerRogers2024-gem5Salam2,
  title = {{Expanding Hardware Accelerator System Design Space Exploration with gem5-SALAMv2}},
  journal = {{Journal of Systems Architecture}},
  volume = {154},
  pages = {103211},
  year = {2024},
  issn = {1383-7621},
  doi = {https://doi.org/10.1016/j.sysarc.2024.103211},
  url = {https://www.sciencedirect.com/science/article/pii/S1383762124001486},
  author = {Zephaniah Spencer and Samuel Rogers and Joshua Slycord and Hamed Tabkhi},
  keywords = {Pre-RTL simulation, Design space exploration, Hardware simulation, Gem5}
}

@inproceedings{ChaudhariSinclair2025-gem5Accel,
  author = {Chaudhari, Akanksha and Sinclair, Matthew D.},
  title = {{Toward Full-System Heterogeneous Simulation: Merging gem5-SALAM with Mainline gem5}},
  year = {2025},
  booktitle = {6th gem5 Users' Workshop},
  month = {6},
  numpages = {2}
}

@article{sandia_2,
  title = {{SST-GPU: A Scalable SST GPU Component for Performance Modeling and Profiling}},
  author = {Hughes, Clayton and Hammond, Simon David and Hoekstra, Robert J. and Zhang, Mengchi and Liu, Yechen and Rogers, Tim},
  doi = {10.2172/1762830},
  url = {https://www.osti.gov/biblio/1762830},
  journal = {Sandia National Lab},
  place = {United States},
  year = {2021},
  month = {1}
}

@article{sandia_3,
  title = {{Balar: A SST GPU Component for Performance Modeling and Profiling}},
  author = {Hughes, Clayton and Hammond, Simon David and Khairy, Mahmoud and Zhang, Mengchi and Green, Roland and Rogers, Timothy and Hoekstra, Robert J.},
  doi = {10.2172/1560919},
  url = {https://www.osti.gov/biblio/1560919},
  journal = {Sandia National Lab},
  place = {United States},
  year = {2019},
  month = {9}
}

@article{DeSensiDeMatteis2022-cloudPerfVar,
  author = {De Sensi, Daniele and De Matteis, Tiziano and Taranov, Konstantin and Di Girolamo, Salvatore and Rahn, Tobias and Hoefler, Torsten},
  title = {{Noise in the Clouds: Influence of Network Performance Variability on Application Scalability}},
  year = {2022},
  issue_date = {December 2022},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {6},
  number = {3},
  url = {https://doi.org/10.1145/3570609},
  doi = {10.1145/3570609},
  month = dec,
  articleno = {49},
  numpages = {27},
  keywords = {scalability, network noise, hpc, cloud}
}

@inproceedings{ZhongSultanov2025-uncorePowerWaste,
  author = {Zhong, Zheng and Sultanov, Seyfal and Papka, Michael and Lan, Zhiling},
  title = {{Minimizing Power Waste in Heterogenous Computing via Adaptive Uncore Scaling}},
  booktitle = {{Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis}},
  series = {SC},
  year = {2025},
}

@article{TopcuKarabacak2025-gpuPowerPerfVar,
  author = {Topcu, Burak and Karabacak, Deniz and Oz, Isil},
  title = {{Demystifying Power and Performance Variations in GPU Systems through Microarchitectural Analysis}},
  journal = {{Computer Science and Information Systems}},
  year = {2025},
  numpages = {30},
  volume = {22},
  number = {2},
  pages = {533-561},
  doi = {https://doi.org/10.2298/CSIS240722021T},
}

@inproceedings{SencanKulkarni2025-gpuHPCUtil,
  author = {Sencan, Efe and Kulkarni, Dhruva and Coskun, Ayse and Konate, Kadidia},
  title = {{Analyzing GPU Utilization in HPC Workloads: Insights from Large-Scale Systems}},
  year = {2025},
  isbn = {9798400713989},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3708035.3736010},
  doi = {10.1145/3708035.3736010},
  abstract = {Efficient resource utilization is a critical yet challenging problem in high-performance computing (HPC) systems, particularly in GPU-accelerated workloads. GPUs have become indispensable in modern datacenters, powering applications in AI, scientific computing, and large-scale simulations, but their potential is often hindered by imbalances in resource allocation and utilization. These inefficiencies across GPUs and nodes can lead to significant performance degradation and energy wastage. While existing works analyze resource utilization at a coarse level, they often fail to capture the intricate temporal and spatial imbalances present in multi-node GPU jobs. In this work, we analyze GPU jobs executed on the Perlmutter supercomputer, a GPU-accelerated system at the National Energy Research Scientific Computing Center (NERSC), using telemetry data from one month of operation in 2024. We identify inefficiencies in how resources are allocated and utilized across GPU nodes and GPUs within nodes. We propose novel methodologies to quantify these imbalances using refined metrics that capture both spatial and temporal variations in resource utilization. Our analysis reveals that GPU utilization is generally well-balanced temporally for most jobs, with no significant temporal imbalances observed. However, GPU memory utilization remains consistently low across many jobs, highlighting opportunities to optimize resource allocation and improve memory usage efficiency.},
  booktitle = {{Practice and Experience in Advanced Research Computing 2025: The Power of Collaboration}},
  articleno = {14},
  numpages = {8},
  keywords = {Workload Analysis, Resource Utilization, HPC Systems, GPU},
  location = {},
  series = {PEARC}
}

@INPROCEEDINGS{AtchleyZimmer2023-frontier,
  author={Atchley, Scott and Zimmer, Chris and Lange, John R. and Bernholdt, David E. and Melesse Vergara, Verónica G. and Beck, Thomas and Brim, Michael J. and Budiardja, Reuben and Chandrasekaran, Sunita and Eisenbach, Markus and Evans, Thomas and Ezell, Matthew and Frontiere, Nicholas and Georgiadou, Antigoni and Glenski, Joe and Grete, Philipp and Hamilton, Steven and Holmen, John and Huebl, Axel and Jacobson, Daniel and Joubert, Wayne and McMahon, Kim and Merzari, Elia and Moore, Stan G and Myers, Andrew and Nichols, Stephen and Oral, Sarp and Papatheodore, Thomas and Perez, Danny and Rogers, David M. and Schneider, Evan and Vay, Jean-Luc and Yeung, P.K.},
  series = {SC},
  booktitle={{International Conference for High Performance Computing, Networking, Storage and Analysis}},
  title={{Frontier: Exploring Exascale The System Architecture of the First Exascale Supercomputer}},
  year={2023},
  volume={},
  number={},
  pages={1-16},
  keywords={Measurement;US Department of Energy;Leadership;Exascale computing;Systems architecture;Computer architecture;Production},
  doi={10.1145/3581784.3607089}
}

@INPROCEEDINGS{Bland2012-titan,
  author={Bland, Buddy},
  booktitle={{SC Companion: High Performance Computing, Networking Storage and Analysis}},
  title={{Titan - Early experience with the Titan system at Oak Ridge National Laboratory}},
  year={2012},
  volume={},
  number={},
  pages={2189-2211},
  keywords={Technological innovation;Leadership;Graphics processing units;Transforms;Three-dimensional displays;Power grids;Parallel processing;Nuclear energy;Market research;Instruction sets},
  doi={10.1109/SC.Companion.2012.356}
}

@inproceedings{BlandRogers2009-jaguar,
  author = {Bland, Arthur S. and Rogers II, James H and Kendall, Ricky A and Kothe, Douglas B and Shipman, Galen M},
  title = {{Jaguar: The World's Most Powerful Computer}},
  booktitle = {{35th Cray User Group Meeting}},
  series = {CUG},
  year = {2009},
  month = {5},
}

@ARTICLE{WombleShankar2019-summit,
  author={Womble, D. E. and Shankar, M. and Joubert, W. and Johnston, J. T. and Wells, J. C. and Nichols, J. A.},
  journal={{IBM Journal of Research and Development}},
  title={{Early Experiences on Summit: Data Analytics and AI Applications}},
  year={2019},
  volume={63},
  number={6},
  pages={2:1-2:9},
  keywords={Computational modeling;Data models;Graphics processing units;Deep learning;Data analysis;Acceleration},
  doi={10.1147/JRD.2019.2944146}
}
@Article{article,
	author = "Author1 LastName1 and Author2 LastName2 and Author3 LastName3",
	title = "Article Title",
	volume = "30",
	number = "30",
	pages = "10127-10134",
	year = "2013",
	doi = "10.3389/fnins.2013.12345",
	URL = "http://www.frontiersin.org/Journal/10.3389/fnins.2013.12345/abstract",
	journal = "Frontiers in Neuroscience"
}

@book{book,
  author    = {Author Name}, 
  title     = {The title of the work},
  publisher = {The name of the publisher},
  address   = {The city},
  year      = 1993,
}

@incollection{chapter,
  author       = {Bauthor Surname}, 
  title        = {The title of the work},
  editor       = {Editor Name},
  booktitle    = {The title of the book},
  publisher    = {The name of the publisher},
  address      = {The city},
  year         = 2002,
  pages        = {201-213},
}

@InProceedings{conference,
  author = {Cauthor Name and Dauthor Surname and Fauthor LastName},
  title = {The title of the work},
  booktitle = {The title of the conference proceedings},
  year = 1996,
  publisher = {The name of the publisher},
  editor = {Editor Name1 and Editor Name2},
  pages = {41-50},
}

@book{cho,
  author       = {Gauthor Name1}, 
  title        = {The title of the work},
  publisher = {Country code and patent number},
  address      = {Patent Country},
  year = 2013
}

@book{patent,
  author    = {Hauthor Surname1}, 
  title     = {The title of the work},
  publisher = {Patent number},
  address   = {Patent country},
  year      = 2010,
}

% please use misc for datasets
@misc{dataset, 
	author = "Author1 LastName1 and Author2 LastName2 and Author3 LastName3",
	title = "Data Title",
	year = "2011",
	doi = "10.000/55555",
	URL = "http://www.frontiersin.org/",
}@misc{trillion-parameter-consortium,
  author = {{DOE}},
  title = {Trillion Parameter Consortium},
  url = "https://tpc.dev/",
  month = aug,
  year = 2023,
  note = "[Online; accessed 2025-11-30]"
}

@misc{cloudmesh-gpu,
author = {von Laszewski, Gregor},
  title = {Cloudmesh GPU Monitor},
  url = "https://github.com/cloudmesh/cloudmesh-gpu",
month = feb,
year = 2022,
  note = "[Online; accessed 2025-11-26]"
}


@misc{www-las-mlcommons-benchmark-collection,
      author = {
        Gregor von Laszewski and 
        Ben Hawks and 
        Marco Colombo and
        Reece Shiraishi and
        Anjay Krishnan and
        Nhan Tran and
        Geoffrey C. Fox},
      title = {MLCommons Science Working Group AI Benchmarks Collection},
      url = {https://mlcommons-science.github.io/benchmark/benchmarks.pdf},
      note = "Online Collection: \url={https://mlcommons-science.github.io/benchmark/}",
      month = jun,
      year = 2025,
      howpublished = "GitHub"
    } 

@misc{campolongo2025buildingmachinelearningchallenges3,
  howpublished = {arXiv},
  author        = {Elizabeth G. Campolongo and Yuan-Tang Chou and Ekaterina Govorkova and 
                   Wahid Bhimji and Wei-Lun Chao and Chris Harris and Shih-Chieh Hsu and 
                   Hilmar Lapp and Mark S. Neubauer and Josephine Namayanja and 
                   Aneesh Subramanian and Philip Harris and Advaith Anand and 
                   David E. Carlyn and Subhankar Ghosh and Christopher Lawrence and 
                   Eric Moreno and Ryan Raikman and Jiaman Wu and Ziheng Zhang and Bayu Adhi and 
                   Mohammad Ahmadi Gharehtoragh and Saúl Alonso Monsalve and Marta Babicz and 
                   Furqan Baig and Namrata Banerji and William Bardon and Tyler Barna and 
                   Tanya Berger-Wolf and Adji Bousso Dieng and Micah Brachman and Quentin Buat and 
                   David C. Y. Hui and Phuong Cao and Franco Cerino and Yi-Chun Chang and 
                   Shivaji Chaulagain and An-Kai Chen and Deming Chen and Eric Chen and Chia-Jui Chou and 
                   Zih-Chen Ciou and Miles Cochran-Branson and Artur Cordeiro Oudot Choi and 
                   Michael Coughlin and Matteo Cremonesi and Maria Dadarlat and Peter Darch and 
                   Malina Desai and Daniel Diaz and Steven Dillmann and Javier Duarte and Isla Duporge and 
                   Urbas Ekka and Saba Entezari Heravi and Hao Fang and Rian Flynn and Geoffrey Fox and 
                   Emily Freed and Hang Gao and Jing Gao and Julia Gonski and Matthew Graham and 
                   Abolfazl Hashemi and Scott Hauck and James Hazelden and Joshua Henry Peterson and 
                   Duc Hoang and Wei Hu and Mirco Huennefeld and David Hyde and Vandana Janeja and 
                   Nattapon Jaroenchai and Haoyi Jia and Yunfan Kang and Maksim Kholiavchenko and 
                   Elham E. Khoda and Sangin Kim and Aditya Kumar and Bo-Cheng Lai and Trung Le and 
                   Chi-Wei Lee and JangHyeon Lee and Shaocheng Lee and Suzan van der Lee and Charles Lewis and 
                   Haitong Li and Haoyang Li and Henry Liao and Mia Liu and Xiaolin Liu and Xiulong Liu and 
                   Vladimir Loncar and Fangzheng Lyu and Ilya Makarov and Abhishikth Mallampalli Chen-Yu Mao and 
                   Alexander Michels and Alexander Migala and Farouk Mokhtar and Mathieu Morlighem and 
                   Min Namgung and Andrzej Novak and Andrew Novick and Amy Orsborn and Anand Padmanabhan and 
                   Jia-Cheng Pan and Sneh Pandya and Zhiyuan Pei and Ana Peixoto and George Percivall and Alex Po Leung and Sanjay Purushotham and Zhiqiang Que and Melissa Quinnan and Arghya Ranjan and Dylan Rankin and Christina Reissel and Benedikt Riedel and Dan Rubenstein and Argyro Sasli and Eli Shlizerman and Arushi Singh and Kim Singh and Eric R. Sokol and Arturo Sorensen and Yu Su and Mitra Taheri and Vaibhav Thakkar and Ann Mariam Thomas and Eric Toberer and Chenghan Tsai and Rebecca Vandewalle and Arjun Verma and Ricco C. Venterea and He Wang and Jianwu Wang and Sam Wang and Shaowen Wang and Gordon Watts and Jason Weitz and Andrew Wildridge and Rebecca Williams and Scott Wolf and Yue Xu and Jianqi Yan and Jai Yu and Yulei Zhang and Haoran Zhao and Ying Zhao and Yibo Zhong},
  eprint        = {2503.02112},
  primaryclass  = {cs.LG},
  title         = {Building Machine Learning Challenges for Anomaly Detection in Science},
  url           = {https://arxiv.org/abs/2503.02112},
  year          = {2025}
}

@misc{campolongo2025buildingmachinelearningchallenges2,
  howpublished = {arXiv},
  author        = {Elizabeth G. Campolongo and Yuan-Tang Chou and Ekaterina Govorkova and Wahid Bhimji and Wei-Lun Chao and Chris Harris and Shih-Chieh Hsu and Hilmar Lapp and Mark S. Neubauer and Josephine Namayanja and Aneesh Subramanian and Philip Harris and Advaith Anand and David E. Carlyn and Subhankar Ghosh and Christopher Lawrence and Eric Moreno and Ryan Raikman and Jiaman Wu and Ziheng Zhang and Bayu Adhi and Mohammad Ahmadi Gharehtoragh and Saúl Alonso Monsalve and Marta Babicz and Furqan Baig and Namrata Banerji and William Bardon and Tyler Barna and Tanya Berger-Wolf and Adji Bousso Dieng and Micah Brachman and Quentin Buat and David C. Y. Hui and Phuong Cao and Franco Cerino and Yi-Chun Chang and Shivaji Chaulagain and An-Kai Chen and Deming Chen and Eric Chen and Chia-Jui Chou and Zih-Chen Ciou and Miles Cochran-Branson and Artur Cordeiro Oudot Choi and Michael Coughlin and Matteo Cremonesi and Maria Dadarlat and Peter Darch and Malina Desai and Daniel Diaz and Steven Dillmann and Javier Duarte and Isla Duporge and Urbas Ekka and Saba Entezari Heravi and Hao Fang and Rian Flynn and Geoffrey Fox and Emily Freed and Hang Gao and Jing Gao and Julia Gonski and Matthew Graham and Abolfazl Hashemi and Scott Hauck and James Hazelden and Joshua Henry Peterson and Duc Hoang and Wei Hu and Mirco Huennefeld and David Hyde and Vandana Janeja and Nattapon Jaroenchai and Haoyi Jia and Yunfan Kang and Maksim Kholiavchenko and Elham E. Khoda and Sangin Kim and Aditya Kumar and Bo-Cheng Lai and Trung Le and Chi-Wei Lee and JangHyeon Lee and Shaocheng Lee and Suzan van der Lee and Charles Lewis and Haitong Li and Haoyang Li and Henry Liao and Mia Liu and Xiaolin Liu and Xiulong Liu and Vladimir Loncar and Fangzheng Lyu and Ilya Makarov and Abhishikth Mallampalli Chen-Yu Mao and Alexander Michels and Alexander Migala and Farouk Mokhtar and Mathieu Morlighem and Min Namgung and Andrzej Novak and Andrew Novick and Amy Orsborn and Anand Padmanabhan and Jia-Cheng Pan and Sneh Pandya and Zhiyuan Pei and Ana Peixoto and George Percivall and Alex Po Leung and Sanjay Purushotham and Zhiqiang Que and Melissa Quinnan and Arghya Ranjan and Dylan Rankin and Christina Reissel and Benedikt Riedel and Dan Rubenstein and Argyro Sasli and Eli Shlizerman and Arushi Singh and Kim Singh and Eric R. Sokol and Arturo Sorensen and Yu Su and Mitra Taheri and Vaibhav Thakkar and Ann Mariam Thomas and Eric Toberer and Chenghan Tsai and Rebecca Vandewalle and Arjun Verma and Ricco C. Venterea and He Wang and Jianwu Wang and Sam Wang and Shaowen Wang and Gordon Watts and Jason Weitz and Andrew Wildridge and Rebecca Williams and Scott Wolf and Yue Xu and Jianqi Yan and Jai Yu and Yulei Zhang and Haoran Zhao and Ying Zhao and Yibo Zhong},
  eprint        = {2503.02112},
  primaryclass  = {cs.LG},
  title         = {Building Machine Learning Challenges for Anomaly Detection in Science},
  url           = {https://arxiv.org/abs/2503.02112},
  year          = {2025}
}

@misc{sbifair-ptycho,
author = {},
  title = {PtychoNN: deep learning network for ptychographic imaging that predicts sample amplitude and phase from diffraction data. | SBI-FAIR},
  url = "https://sbi-fair.github.io/docs/surrogates/ptychonn/",
month = {},
year = {},
  note = "[Online; accessed 2025-11-17]"
}

@InProceedings{las-mlcommons-science,
  author="Thiyagalingam, Jeyan
  and von Laszewski, Gregor
  and Yin, Junqi
  and Emani, Murali
  and Papay, Juri
  and Barrett, Gregg
  and Luszczek, Piotr
  and Tsaris, Aristeidis
  and Kirkpatrick, Christine
  and Wang, Feiyi
  and Gibbs, Tom
  and Vishwanath, Venkatram
  and Shankar, Mallikarjun
  and Fox, Geoffrey
  and Hey, Tony",
  editor="Anzt, Hartwig
  and Bienz, Amanda
  and Luszczek, Piotr
  and Baboulin, Marc",
  title="AI Benchmarking for Science: Efforts from the MLCommons Science Working Group",
  booktitle="High Performance Computing. ISC High Performance 2022 International Workshops",
  year="2022",
  publisher="Springer International Publishing",
  address="Cham",
  pages="47--64",
  abstract="With machine learning (ML) becoming a transformative tool for science, the scientific community needs a clear catalogue of ML techniques, and their relative benefits on various scientific problems, if they were to make significant advances in science using AI. Although this comes under the purview of benchmarking, conventional benchmarking initiatives are focused on performance, and as such, science, often becomes a secondary criteria.",
  isbn="978-3-031-23220-6"
}


@misc{calo-surrogate,
author = {UVA},
  title = {Calorimeter surrogates | SBI-FAIR},
  url = "https://sbi-fair.github.io/docs/surrogates/calorimeter/",
month = nov,
year = 2025,
  note = "[Online; accessed 2025-11-17]"
}



@misc{www-open-ondemand,
author = {},
  title = {Open OnDemand},
  url = "https://openondemand.org/",
month = {12},
year = {2024},
  note = "[Online; accessed 2025-10-28]"
}

@misc{www-las-mlcommons-benchmark-coolection,
  author = {
    Gregor von Laszewski and 
    Ben Hawks and 
    Marco Colombo and
    Reece Shiraishi and
    Anjay Krishnan and
    Nhan Tran and
    Geoffrey C. Fox},
  title = {MLCommons Science Working Group AI Benchmarks Collection},
  url = {https://mlcommons-science.github.io/benchmark/benchmarks.pdf},
  note = "Online Collection: \url={https://mlcommons-science.github.io/benchmark/}",
  month = jun,
  year = 2025,
  howpublished = "GitHub"
}

@article{awspcs:online,
  author =	 {{AWS}},
  title =	 {What is AWS ParallelCluster - AWS ParallelCluster},
  note =	 {\url
                  {https://docs.aws.amazon.com/parallelcluster/latest/ug/what-is-aws-parallelcluster.html}},
  month =	 oct,
  year =	 2024,
  journal =	 {NA},
  note =	 {(Accessed on 09/27/2024)}
}

@article{ec2ondemand:online,
  author =	 {{AWS}},
  author =	 {},
  title =	 {EC2 On-Demand Instance Pricing – Amazon Web
                  Services},
  note =	 {\url
                  {https://aws.amazon.com/ec2/pricing/on-demand/}},
  month =	 oct,
  year =	 2024,
  journal =	 {NA},
  note =	 {(Accessed on 09/28/2024)}
}

@article{CFD:online,
  author =	 {{AWS}},
  title =	 {CFD simulation of aerodynamic forces on the DrivAer
                  car model: Impact of computational parameters},
  note =	 {\url
                  {https://www.sciencedirect.com/science/article/pii/S0167610524000746}},
  month =	 oct,
  year =	 2024,
  note =	 {(Accessed on 10/24/2024)}
}

@article{awspcsblob1:online,
  author =	 {{AWS}},
  title =	 {You told us we needed to re-think HPC in the
                  cloud. So we did. | AWS HPC Blog},
  note =	 {\url
                  {https://aws.amazon.com/blogs/hpc/you-told-us-we-needed-to-re-think-hpc-in-the-cloud-so-we-did/}},
  month =	 oct,
  year =	 2024,
  note =	 {(Accessed on 10/24/2024)}
}

@article{awspcsstorage:online,
  author =	 {{AWS}},
  title =	 {Using network file systems with AWS PCS - AWS PCS},
  url = {https://docs.aws.amazon.com/pcs/latest/userguide/working-with_file-systems.html},
  month =	 oct,
  year =	 2024,
  note =	 {(Accessed on 10/24/2024)}
}


@article{yamldb,
  author =	 {von Laszewski, Gregor},
  title =	 {cloudmesh/yamldb},
  note = {\url{https://github.com/cloudmesh/yamldb}},
  year =	 {2020},
  note =	 {(Accessed on 10/25/2024)}
}

@misc{las-2022-hybrid,
  title =	 {Hybrid Reusable Computational Analytics Workflow
                  Management with Cloudmesh},
  author =	 {Gregor von Laszewski and J. P. Fleischer and
                  Geoffrey C. Fox},
  year =	 2022,
  eprint =	 {2210.16941},
  howpublished ={arXiv},
  primaryClass = {cs.DC},
  note =	 {\url{https://arxiv.org/abs/2210.16941}},
}

@INPROCEEDINGS{las-2022-templated,
  author =	 {von Laszewski, Gregor and Fleischer, J.P. and Fox,
                  Geoffrey C. and Papay, Juri and Jackson, Sam and
                  Thiyagalingam, Jeyan},
  booktitle =	 {2023 IEEE 19th International Conference on e-Science
                  (e-Science)},
  title =	 {Templated Hybrid Reusable Computational Analytics
                  Workflow Management with Cloudmesh, Applied to the
                  Deep Learning MLCommons Cloudmask Application},
  year =	 2023,
  pages =	 {1-6},
  keywords =	 {Deep learning;Codes;Operating
                  systems;Linux;Benchmark
                  testing;History;Synchronization;Task
                  analysis;Artificial
                  intelligence;Monitoring;experiment workflow;task
                  workflow;hyperparameter workflow;high-performance
                  computing;batch queue management;workflow web
                  service;cloudmesh},
  doi =		 {10.1109/e-Science58273.2023.10254942}
}

@article{www-cloudmesh-org,
  author =	 {},
  title =	 {Cloudmesh Version 4 },
  howpublished =
                  {\url{https://cloudmesh.github.io/cloudmesh-manual/index.html}},
  year =	 {},
  note =	 {(Accessed on 10/25/2024)}
}

@article{prace-fact,
  author =	 {},
  title =	 {Fact-Sheet-PRACE-Access.pdf},
  howpublished = {Web Page},
  note =	 {\url
                  {https://prace-ri.eu/wp-content/uploads/Fact-Sheet-PRACE-Access.pdf}},
  month =	 oct,
  year =	 2024
}

@article{www-prace,
  author =	 {},
  title =	 {PRACE HPC Infrastructure - PRACE},
  howpublished = {Web Page},
  note =	 {\url
                  {https://prace-ri.eu/prace-archive/infrastructure-support/prace-hpc-infrastructure/}},
  month =	 oct,
  year =	 2024
}

@article{incommon,
  author =	 {},
  title =	 {Home Page - InCommon},
  howpublished = {Web Page},
  url =		 {https://incommon.org/},
  month =	 oct,
  year =	 2024
}

@article{cylon,
  title =	 {In-depth analysis on parallel processing patterns
                  for high-performance Dataframes},
  journal =	 {Future Generation Computer Systems},
  volume =	 149,
  pages =	 {250-264},
  year =	 2023,
  issn =	 {0167-739X},
  doi =		 {https://doi.org/10.1016/j.future.2023.07.007},
  url =
                  {https://www.sciencedirect.com/science/article/pii/S0167739X23002595},
  author =	 {Niranda Perera and Arup Kumar Sarker and Mills
                  Staylor and Gregor {von Laszewski} and Kaiying Shan
                  and Supun Kamburugamuve and Chathura Widanage and
                  Vibhatha Abeykoon and Thejaka Amila Kanewela and
                  Geoffrey Fox},
  keywords =	 {Dataframes, High-performance computing, Data
                  engineering, Relational algebra, MPI, Distributed
                  Memory Parallel},
  abstract =	 {The Data Science domain has expanded monumentally in
                  both research and industry communities during the
                  past decade, predominantly owing to the Big Data
                  revolution. Artificial Intelligence (AI) and Machine
                  Learning (ML) are bringing more complexities to data
                  engineering applications, which are now integrated
                  into data processing pipelines to process terabytes
                  of data. Typically, a significant amount of time is
                  spent on data preprocessing in these pipelines, and
                  hence improving its efficiency directly impacts the
                  overall pipeline performance. The community has
                  recently embraced the concept of Dataframes as the
                  de-facto data structure for data representation and
                  manipulation. However, the most widely used serial
                  Dataframes today (R, pandas) experience performance
                  limitations while working on even moderately large
                  data sets. We believe that there is plenty of room
                  for improvement by taking a look at this problem
                  from a high-performance computing point of view. In
                  a prior publication, we presented a set of parallel
                  processing patterns for distributed dataframe
                  operators and the reference runtime implementation,
                  Cylon [1]. In this paper, we are expanding on the
                  initial concept by introducing a cost model for
                  evaluating the said patterns. Furthermore, we
                  evaluate the performance of Cylon on the ORNL Summit
                  supercomputer.}
}

@misc{cylon-radical,
  title =	 {Design and Implementation of an Analysis Pipeline
                  for Heterogeneous Data},
  author =	 {Arup Kumar Sarker and Aymen Alsaadi and Niranda
                  Perera and Mills Staylor and Gregor von Laszewski
                  and Matteo Turilli and Ozgur Ozan Kilic and Mikhail
                  Titov and Andre Merzky and Shantenu Jha and Geoffrey
                  Fox},
  year =	 2024,
  eprint =	 {2403.15721},
  howpublished ={arXiv},
  primaryClass = {cs.DC},
  url =		 {https://arxiv.org/abs/2403.15721},
}

@INPROCEEDINGS{eucalyptus,
  author =	 {Nurmi, Daniel and Wolski, Rich and Grzegorczyk,
                  Chris and Obertelli, Graziano and Soman, Sunil and
                  Youseff, Lamia and Zagorodnov, Dmitrii},
  booktitle =	 {2009 9th IEEE/ACM International Symposium on Cluster
                  Computing and the Grid},
  title =	 {The Eucalyptus Open-Source Cloud-Computing System},
  year =	 2009,
  pages =	 {124-131},
  keywords =	 {Open source software;Cloud computing;Computer
                  interfaces;Grid computing;Resource
                  management;Instruments;Control systems;Virtual
                  machining;Application software;Software
                  maintenance;cloud computing;virtualization},
  doi =		 {10.1109/CCGRID.2009.93}
}

@ARTICLE{opencirrus,
  author =	 {Avetisyan, Arutyun I. and Campbell, Roy and Gupta,
                  Indranil and Heath, Michael T. and Ko, Steven Y. and
                  Ganger, Gregory R. and Kozuch, Michael A. and
                  O'Hallaron, David and Kunze, Marcel and Kwan, Thomas
                  T. and Lai, Kevin and Lyons, Martha and Milojicic,
                  Dejan S. and Lee, Hing Yan and Soh, Yeng Chai and
                  Ming, Ng Kwang and Luke, Jing-Yuan and Namgoong,
                  Han},
  journal =	 {Computer},
  title =	 {Open Cirrus: A Global Cloud Computing Testbed},
  year =	 2010,
  volume =	 43,
  number =	 4,
  pages =	 {35-43},
  keywords =	 {Cloud computing;Testing;Technological
                  innovation;Open Cirrus;Cloud computing;Distributed
                  computing;Systems engineering;Internet/Web},
  doi =		 {10.1109/MC.2010.111}
}

@article{www-keydb,
  author =	 {},
  title =	 {KeyDB - The Faster Redis Alternative},
  howpublished = {Web Page},
  url =		 {https://docs.keydb.dev/},
  month =	 sep,
  year =	 2024
}

@article{cloudmesh-ee,
  author =	 {von Laszewski, Gregor},
  title =	 {{Cloudmesh Experiment Executor}},
  year =	 2023,
  month =	 sep,
  note =	 {[Online; accessed 8. Sep. 2023]
                  \url{https://github.com/cloudmesh/cloudmesh-ee} }
}

,
	url = {https://github.com/cloudmesh/cloudmesh-ee}
}

@article{cloudmesh-cc,
  author =	 {von Laszewski, Gregor},
  title =	 {{loudmesh Compute Coordinator}},
  year =	 2023,
  month =	 sep,
  note =	 {[Online; accessed 8. Sep. 2023]
                  \url{https://github.com/cloudmesh/cloudmesh-ee} }
}

,
	url = {https://github.com/cloudmesh/cloudmesh-ee}
}

@article{uva-ondemand,
  title =	 {{Open OnDemand {$\vert$} Research Computing}},
  year =	 2023,
  month =	 sep,
  note =	 {[Online; accessed 6. Sep. 2023]},
  url =
                  {https://www.rc.virginia.edu/userinfo/rivanna/ood/overview}
}

@article{www-pep8,
  title =	 {{PEP 8 {\textendash} Style Guide for Python Code
                  {$\vert$} peps.python.org}},
  year =	 2023,
  month =	 sep,
  note =	 {[Online; accessed 6. Sep. 2023]},
  url =		 {https://peps.python.org/pep-0008}
}

@inproceedings{las-2023-escience,
  address =	 {Limassol, Cyprus},
  author =	 {von Laszewski, Gregor and J.P. Fleischer, J.P. and
                  Fox, Geoffrey C. and Juri Papay and Sam Jackson and
                  Jeyan Thiyagalingam},
  booktitle =	 {eScience'23},
  month =	 {October},
  organization = {Second Workshop on Reproducible Workflows, Data, and
                  Security (ReWorDS 2022)},
  title =	 {Templated Hybrid Reusable Computational Analytics
                  Workflow Management with Cloudmesh, Applied to the
                  Deep Learning MLCommons Cloudmask Application},
  year =	 2023
}

@article{energy-price,
  title =	 {{Average energy prices for the United States,
                  regions, census divisions, and selected metropolitan
                  areas : Midwest Information Office : U.S. Bureau of
                  Labor Statistics}},
  year =	 2020,
  month =	 dec,
  note =	 {[Online; accessed 2. Sep. 2023]},
  url =
                  {https://www.bls.gov/regions/midwest/data/averageenergyprices_selectedareas_table.htm}
}

@article{greenhouse-calc,
  author =	 {Oar},
  title =	 {{Greenhouse Gas Equivalencies Calculator}},
  journal =	 {US EPA},
  year =	 2023,
  month =	 jul,
  url =
                  {https://www.epa.gov/energy/greenhouse-gas-equivalencies-calculator}
}

@inproceedings{las-22-mlcommons-science,
  address =	 {Cham},
  author =	 {Thiyagalingam, Jeyan and von Laszewski, Gregor and
                  Yin, Junqi and Emani, Murali and Papay, Juri and
                  Barrett, Gregg and Luszczek, Piotr and Tsaris,
                  Aristeidis and Kirkpatrick, Christine and Wang,
                  Feiyi and Gibbs, Tom and Vishwanath, Venkatram and
                  Shankar, Mallikarjun and Fox, Geoffrey and Hey,
                  Tony},
  booktitle =	 {High Performance Computing. ISC High Performance
                  2022 International Workshops},
  editor =	 {Anzt, Hartwig and Bienz, Amanda and Luszczek, Piotr
                  and Baboulin, Marc},
  pages =	 {47--64},
  publisher =	 {Springer International Publishing},
  title =	 {{AI Benchmarking for Science: Efforts from the
                  MLCommons Science Working Group}},
  year =	 2022,
  abstract =	 {With machine learning (ML) becoming a transformative
                  tool for science, the scientific community needs a
                  clear catalogue of ML techniques, and their relative
                  benefits on various scientific problems, if they
                  were to make significant advances in science using
                  AI.  Although this comes under the purview of
                  benchmarking, conventional benchmarking initiatives
                  are focused on performance, and as such, science,
                  often becomes a secondary criteria.},
  isbn =	 {978-3-031-23220-6},
}

@article{dongarra1997top500,
  author =	 {Dongarra, Jack J and Meuer, Hans W and Strohmaier,
                  Erich and others},
  journal =	 {Supercomputer},
  pages =	 {89--111},
  publisher =	 {ASFRA BV},
  title =	 {{TOP500 Supercomputer Sites}},
  volume =	 13,
  year =	 1997,
}

@article{www-mlcommons,
  journal =	 {Web page},
  key =		 {MLCommons},
  month =	 apr,
  note =	 {\url{https://mlcommons.org/} [Accessed April 13,
                  2023]},
  title =	 {{Machine learning innovation to benefit everyone}},
  year =	 2023,
  url =		 {https://mlcommons.org/},
}

@misc{mlperf-training,
  author =	 {Mattson, Peter and Cheng, Christine and Coleman,
                  Cody and Diamos, Greg and Micikevicius, Paulius and
                  Patterson, David and Tang, Hanlin and Wei, Gu-Yeon
                  and Bailis, Peter and Bittorf, Victor and Brooks,
                  David and Chen, Dehao and Dutta, Debojyoti and
                  Gupta, Udit and Hazelwood, Kim and Hock, Andrew and
                  Huang, Xinyuan and Ike, Atsushi and Jia, Bill and
                  Kang, Daniel and Kanter, David and Kumar, Naveen and
                  Liao, Jeffery and Ma, Guokai and Narayanan, Deepak
                  and Oguntebi, Tayo and Pekhimenko, Gennady and
                  Pentecost, Lillian and Reddi, Vijay Janapa and
                  Robie, Taylor and John, Tom St. and Tabaru,
                  Tsuguchika and Wu, Carole-Jean and Xu, Lingjie and
                  Yamazaki, Masafumi and Young, Cliff and Zaharia,
                  Matei},
  howpublished =	 {arXiv},
  title =	 {{MLPerf Training Benchmark}},
  year =	 2019,
  doi =		 {10.48550/ARXIV.1910.01500},
  url =		 {https://arxiv.org/abs/1910.01500},
}

@misc{cosmoflow,
  author =	 {Mathuriya, Amrita and Bard, Deborah and Mendygral,
                  Peter and Meadows, Lawrence and Arnemann, James and
                  Shao, Lei and He, Siyu and Karna, Tuomas and Moise,
                  Daina and Pennycook, Simon J. and Maschoff, Kristyn
                  and Sewall, Jason and Kumar, Nalini and Ho, Shirley
                  and Ringenburg, Mike and {Prabhat} and Lee, Victor},
  howpublished =	 {arXiv},
  title =	 {{CosmoFlow: Using Deep Learning to Learn the
                  Universe at Scale}},
  year =	 2018,
  doi =		 {10.48550/ARXIV.1808.04728},
  url =		 {https://arxiv.org/abs/1808.04728},
}

@article{las-2022-mdpi-crypto,
  author =	 {Fleischer, Jacques Phillipe and von Laszewski,
                  Gregor and Theran, Carlos and Parra Bautista, Yohn
                  Jairo},
  journal =	 {Algorithms},
  number =	 7,
  title =	 {Time Series Analysis of Cryptocurrency Prices Using
                  Long Short-Term Memory},
  volume =	 15,
  year =	 2022,
  doi =		 {10.3390/a15070230},
  issn =	 {1999-4893},
  url =		 {https://www.mdpi.com/1999-4893/15/7/230},
}

@article{nash-79,
  author =	 {J.E. Nash and J.V. Sutcliffe},
  journal =	 {Journal of Hydrology},
  number =	 3,
  pages =	 {282-290},
  title =	 {{River Flow Forecasting Through Conceptual Models
                  Part I -- A Discussion of Principles}},
  volume =	 10,
  year =	 1970,
  issn =	 {0022-1694},
}

@article{fox2022-jm,
  author =	 {Fox, Geoffrey and Rundle, John and Donnellan, Andrea
                  and Feng, Bo},
  journal =	 {Geohazards},
  month =	 apr,
  number =	 2,
  pages =	 199,
  publisher =	 {MDPI},
  title =	 {{Earthquake Nowcasting with Deep Learning}},
  volume =	 3,
  year =	 2022,
}

@article{TFT-21,
  author =	 {Bryan Lim and Sercan {\"O}. Ar{\i}k and Nicolas
                  Loeff and Tomas Pfister},
  journal =	 {International Journal of Forecasting},
  number =	 4,
  pages =	 {1748-1764},
  title =	 {Temporal Fusion Transformers for interpretable
                  multi-horizon time series forecasting},
  volume =	 37,
  year =	 2021,
}

@article{eq-code,
  author =	 {Fox, Geoffrey C and von Laszewski, Gregor and Robert
                  Knuuti and Thomas Butler and Jake Kolesar},
  journal =	 {GitHub},
  month =	 apr,
  note =
                  {\url{https://github.com/laszewsk/mlcommons/tree/main/benchmarks/earthquake}
                  [Accessed April 13, 2023]},
  title =	 {{MLCommons Science Benchmark Earthquake Code}},
  year =	 2023,
  url =
                  {https://github.com/laszewsk/mlcommons/tree/main/benchmarks/
                  earthquake},
}

@article{eq-data,
  journal =	 {GitHub},
  key =		 {von Laszewski, Gregor},
  month =	 apr,
  note =
                  {\url{https://github.com/laszewsk/mlcommons-data-earthquake}
                  [Accessed April 13, 2023]},
  title =	 {{MLCommons Earthquake Data}},
  year =	 2023,
  url =
                  {https://github.com/laszewsk/mlcommons-data-earthquake},
}

@article{www-papermill,
  author =	 {The nteract team},
  title =	 {{Home - papermill 2.4.0 documentation}},
  year =	 2023,
  month =	 jun,
  note =	 {[Online; accessed 2. Oct. 2023]},
  url =		 {https://papermill.readthedocs.io/en/latest}
}

@inproceedings{las-infogram,
  author =	 {von Laszewski, Gregor and Gawor, J. and Pena,
                  C.J. and Foster, I.},
  booktitle =	 {Proceedings 11th IEEE International Symposium on
                  High Performance Distributed Computing},
  pages =	 {333-342},
  title =	 {{InfoGram: a grid service that supports both
                  information queries and job execution}},
  year =	 2002,
  doi =		 {10.1109/HPDC.2002.1029933},
}

@techreport{las-workflow,
  address =	 {Argonne, IL},
  author =	 {von Laszewski, Gregor},
  institution =	 {Argonne National Laboratory},
  note =
                  {\url{https://www.mcs.anl.gov/uploads/cels/papers/P1259.pdf}},
  number =	 {P1259},
  title =	 {{Java CoG Kit Workflow Concepts for Scientific
                  Experiments}},
  year =	 2005,
  url =
                  {https://www.mcs.anl.gov/uploads/cels/papers/P1259.pdf},
}

@inbook{las07-workflow,
  address =	 {London},
  author =	 {von Laszewski, Gregor and Hategan, Mihael and
                  Kodeboyina, Deepti},
  booktitle =	 {Workflows for e-Science: Scientific Workflows for
                  Grids},
  editor =	 {Taylor, Ian J. and Deelman, Ewa and Gannon, Dennis
                  B. and Shields, Matthew},
  pages =	 {340--356},
  publisher =	 {Springer London},
  title =	 {Java CoG Kit Workflow},
  year =	 2007,
  abstract =	 {In order to satisfy the need for sophisticated
                  experiment and simulation management solutions for
                  the scientific user community, various frameworks
                  must be provided. Such frameworks include APIs,
                  services, templates, patterns, GUIs, command-line
                  tools, and workflow systems that are specifically
                  addressed towards the goal of assisting in the
                  complex process of experiment and simulation
                  management. Workflow by itself is just one of the
                  ingredients for a successful experiment and
                  simulation management tool.},
  doi =		 {10.1007/978-1-84628-757-2_21},
  isbn =	 {978-1-84628-757-2},
  url =		 {https://doi.org/10.1007/978-1-84628-757-2_21},
}

@misc{las-22-arxiv-workflow-cc,
  author =	 {von Laszewski, Gregor and Fleischer, J. P. and Fox,
                  Geoffrey C.},
  howpublished =	 {arXiv},
  month =	 oct,
  title =	 {Hybrid Reusable Computational Analytics Workflow
                  Management with Cloudmesh},
  year =	 2022,
  doi =		 {10.48550/ARXIV.2210.16941},
  url =		 {https://arxiv.org/abs/2210.16941},
}

@article{cloudmesh-stopwatch,
  author =	 {von Laszewski, Gregor},
  journal =	 {GitHub},
  month =	 may,
  note = {\url{https://github.com/cloudmesh/cloudmesh-common/blob/main/cloudmesh/common/StopWatch.py}
                  [Accessed April 13, 2023]},
  title =	 {{Cloudmesh Common StopWatch}},
  year =	 2022,
  url = {https://github.com/cloudmesh/cloudmesh-common/blob/main/cloudmesh/common/StopWatch.py},
}

@article{cloudmesh-vpn,
  author =	 {von Laszewski, Gregor},
  journal =	 {GitHub},
  month =	 may,
  note =	 {\url{https://github.com/cloudmesh/cloudmesh-vpn}
                  [Accessed April 13, 2023]},
  title =	 {{Cloudmesh VPN}},
  year =	 2022,
  url =		 {https://github.com/cloudmesh/cloudmesh-vpn},
  note =	 {\url{https://github.com/cloudmesh/cloudmesh-vpn}},
}

@article{www-rivanna,
  author =	 {{Univerity of Virginia Research Computing}},
  journal =	 {Web Page},
  month =	 apr,
  note =
                  {\url{https://www.rc.virginia.edu/userinfo/rivanna/overview}
                  [Accessed April 13, 2023]},
  title =	 {{Rivanna}},
  year =	 2023,
  url =
                  {https://www.rc.virginia.edu/userinfo/rivanna/overview},
}

@article{google-colab,
  author =	 {{Google Colaboratory}},
  journal =	 {Web Page},
  month =	 apr,
  note =	 {Web page
                  \url{https://research.google.com/colaboratory/faq.html}
                  [Accessed April 13, 2023]},
  publisher =	 {Google},
  title =	 {{Google Colab FAQ}},
  year =	 2023,
  url =		 {https://research.google.com/colaboratory/faq.html},
}


@inbook{fincher_robins_2019,
  author =	 {Fincher, Sally A. and Robins, Anthony V.},
  place =	 {Cambridge},
  series =	 {Cambridge Handbooks in Psychology},
  title =	 {Systems Software and Technology},
  booktitle =	 {The Cambridge Handbook of Computing Education
                  Research},
  publisher =	 {Cambridge University Press},
  year =	 2019,
  pages =	 {637–706},
  collection =	 {Cambridge Handbooks in Psychology}
}

@misc{tan_chen,
  title =	 {Visual Studio Code in Introductory Computer Science
                  Course: An Experience Report},
  author =	 {Jialiang Tan and Yu Chen and Shuyin Jiao},
  year =	 2023,
  eprint =	 {2303.10174},
  howpublished ={arXiv},
  url = {https://arxiv.org/abs/2303.10174},
  primaryClass = {cs.HC}
}

@inproceedings{Kovtaniuk2022,
  doi =		 {10.30525/978-9934-26-277-7-108},
  url =		 {https://doi.org/10.30525/978-9934-26-277-7-108},
  year =	 2022,
  publisher =	 {Baltija Publishing},
  author =	 {M. S. Kovtaniuk},
  title =	 {Online compiler
                  {\guillemotleft}Replit{\guillemotright} usage during
                  the study of the programming discipline},
  booktitle =	 {{INFORMATION} {TECHNOLOGIES} {AND} {MANAGEMENT} {IN}
                  {HIGHER} {EDUCATION} {AND} {SCIENCES}. {PART} 2}
}

@article{konigstorfer,
  title =	 {AI Documentation: A path to accountability},
  journal =	 {Journal of Responsible Technology},
  volume =	 11,
  pages =	 100043,
  year =	 2022,
  issn =	 {2666-6596},
  doi =		 {https://doi.org/10.1016/j.jrt.2022.100043},
  url =
                  {https://www.sciencedirect.com/science/article/pii/S2666659622000208},
  author =	 {Florian Königstorfer and Stefan Thalmann},
  keywords =	 {Artificial Intelligence, Documentation, IT adoption,
                  IT audit}
}

@article{emacs-reference,
  title =	 {{GNU Emacs Reference Cards - GNU Project - Free
                  Software Foundation}},
  year =	 2023,
  month =	 jul,
  note =	 {[Online; accessed 25. Jul. 2023]},
  url =		 {https://www.gnu.org/software/emacs/refcards}
}

@article{norem,
  author =	 {Josh Norem},
  title =	 {{Windows 11 Gains Market Share but Windows 10 Still
                  Leads by a Mile}},
  journal =	 {ExtremeTech},
  year =	 2023,
  month =	 feb,
  note =	 {[Online; accessed 25. Jul. 2023]},
  url =
                  {https://www.extremetech.com/computing/342819-windows-11-gains-market-share-but-windows-10-still-leads-by-a-mile}
}

@article{ivie,
  author =	 {Ivie, Peter and Thain, Douglas},
  title =	 {Reproducibility in Scientific Computing},
  year =	 2018,
  issue_date =	 {May 2019},
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  volume =	 51,
  number =	 3,
  issn =	 {0360-0300},
  url =		 {https://doi.org/10.1145/3186266},
  doi =		 {10.1145/3186266},
  journal =	 {ACM Comput. Surv.},
  month =	 {jul},
  articleno =	 63,
  numpages =	 36,
  keywords =	 {computational science, replicability, workflow,
                  workflows, reproducible, scientific computing,
                  scientific workflow, scientific workflows,
                  Reproducibility}
}

@article{leveque,
  title =	 {Reproducible research for scientific computing:
                  Tools and strategies for changing the culture},
  author =	 {LeVeque, Randall J and Mitchell, Ian M and Stodden,
                  Victoria},
  journal =	 {Computing in Science \& Engineering},
  volume =	 14,
  number =	 04,
  pages =	 {13--17},
  year =	 2012,
  publisher =	 {IEEE Computer Society}
}

@article{bailey,
  title =	 {Facilitating reproducibility in scientific
                  computing: Principles and practice},
  author =	 {Bailey, David H and Borwein, Jonathan M and Stodden,
                  Victoria},
  journal =	 {Reproducibility: Principles, Problems, Practices,
                  and Prospects},
  pages =	 {205--231},
  year =	 2016,
  publisher =	 {Wiley Online Library}
}

@inproceedings{reddi,
  author =	 {Janapa Reddi, Vijay and Kanter, David and Mattson,
                  Peter and Duke, Jared and Nguyen, Thai and Chukka,
                  Ramesh and Shiring, Ken and Tan, Koan-Sin and
                  Charlebois, Mark and Chou, William and El-Khamy,
                  Mostafa and Hong, Jungwook and St John, Tom and
                  Trinh, Cindy and Buch, Michael and Mazumder, Mark
                  and Markovic, Relja and Atta, Thomas and Cakir,
                  Fatih and Charkhabi, Masoud and Chen, Xiaodong and
                  Chiang, Cheng-Ming and Dexter, Dave and Heo, Terry
                  and Schmuelling, Guenther and Shabani, Maryam and
                  Zika, Dylan},
  booktitle =	 {Proceedings of Machine Learning and Systems},
  editor =	 {D. Marculescu and Y. Chi and C. Wu},
  pages =	 {352--369},
  title =	 {MLPerf Mobile Inference Benchmark: An
                  Industry-Standard Open-Source Machine Learning
                  Benchmark for On-Device AI},
  url =
                  {https://proceedings.mlsys.org/paper_files/paper/2022/file/a2b2702ea7e682c5ea2c20e8f71efb0c-Paper.pdf},
  volume =	 4,
  year =	 2022
}

@article{mitra,
  title =	 {Singularity containers improve reproducibility and
                  ease of use in computational image analysis
                  workflows},
  author =	 {Mitra-Behura, Shilpita and Fiolka, Reto Paul and
                  Daetwyler, Stephan},
  journal =	 {Frontiers in Bioinformatics},
  volume =	 1,
  pages =	 757291,
  year =	 2022,
  publisher =	 {Frontiers}
}

@article{beroza,
  title =	 {Machine learning and earthquake forecasting—next
                  steps},
  author =	 {Beroza, Gregory C and Segou, Margarita and Mostafa
                  Mousavi, S},
  journal =	 {Nature communications},
  volume =	 12,
  number =	 1,
  pages =	 4761,
  year =	 2021,
  publisher =	 {Nature Publishing Group UK London}
}

@article{johnson,
  author =	 {Paul A. Johnson and Bertrand Rouet-Leduc and Laura
                  J. Pyrak-Nolte and Gregory C. Beroza and Chris
                  J. Marone and Claudia Hulbert and Addison Howard and
                  Philipp Singer and Dmitry Gordeev and Dimosthenis
                  Karaflos and Corey J. Levinson and Pascal Pfeiffer
                  and Kin Ming Puk and Walter Reade },
  title =	 {Laboratory earthquake forecasting: A machine
                  learning competition},
  journal =	 {Proceedings of the National Academy of Sciences},
  volume =	 118,
  number =	 5,
  pages =	 {e2011362118},
  year =	 2021,
  doi =		 {10.1073/pnas.2011362118},
  URL =
                  {https://www.pnas.org/doi/abs/10.1073/pnas.2011362118},
  eprint =
                  {https://www.pnas.org/doi/pdf/10.1073/pnas.2011362118},
}

@inproceedings{giacomazzi,
  author =	 {Giacomazzi, Elena and Haag, Felix and Hopf,
                  Konstantin},
  title =	 {Short-Term Electricity Load Forecasting Using the
                  Temporal Fusion Transformer: Effect of Grid
                  Hierarchies and Data Sources},
  year =	 2023,
  isbn =	 9798400700323,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  url =		 {https://doi.org/10.1145/3575813.3597345},
  doi =		 {10.1145/3575813.3597345},
  booktitle =	 {Proceedings of the 14th ACM International Conference
                  on Future Energy Systems},
  pages =	 {353–360},
  numpages =	 8,
  keywords =	 {Temporal Fusion Transformer (TFT), Short-Term Load
                  Forecasting, Artificial Neural Networks, Long-Term
                  Short-Term Memory (LSTM)},
  location =	 {Orlando, FL, USA},
  series =	 {e-Energy '23}
}

@article{romano,
  author =	 {Romano, Joseph D and Le, Trang T and La Cava,
                  William and Gregg, John T and Goldberg, Daniel J and
                  Chakraborty, Praneel and Ray, Natasha L and
                  Himmelstein, Daniel and Fu, Weixuan and Moore, Jason
                  H},
  title =	 "{PMLB v1.0: an open-source dataset collection for
                  benchmarking machine learning methods}",
  journal =	 {Bioinformatics},
  volume =	 38,
  number =	 3,
  pages =	 {878-880},
  year =	 2021,
  month =	 10,
  issn =	 {1367-4803},
  doi =		 {10.1093/bioinformatics/btab727},
  url =		 {https://doi.org/10.1093/bioinformatics/btab727},
  eprint =
                  {https://academic.oup.com/bioinformatics/article-pdf/38/3/878/49007845/btab727.pdf},
}

@inproceedings{tovar,
  title =	 {Harnessing HPC resources for CMS jobs using a
                  Virtual Private Network},
  author =	 {Tovar, Benjamin and Bockelman, Brian and Hildreth,
                  Michael and Lannon, Kevin and Thain, Douglas},
  booktitle =	 {EPJ Web of Conferences},
  volume =	 251,
  pages =	 02032,
  year =	 2021,
  organization = {EDP Sciences}
}

@article{raibulet,
  title =	 {Collaborative and teamwork software development in
                  an undergraduate software engineering course},
  author =	 {Raibulet, Claudia and Fontana, Francesca Arcelli},
  journal =	 {Journal of Systems and Software},
  volume =	 144,
  pages =	 {409--422},
  year =	 2018,
  publisher =	 {Elsevier}
}

@INPROCEEDINGS{zeidmane,
  author =	 {Zeidmane, Anda and Cernajeva, Sarmite},
  booktitle =	 {2011 IEEE Global Engineering Education Conference
                  (EDUCON)},
  title =	 {Interdisciplinary approach in engineering education},
  year =	 2011,
  pages =	 {1096-1101},
  doi =		 {10.1109/EDUCON.2011.5773284}
}

@misc{claesen,
  title =	 {Hyperparameter search in machine learning},
  booktitle =	 {MIC 2015: The XI Metaheuristics International
                  Conference in Agadir, Morocco},
  author =	 {Claesen, Marc and De Moor, Bart},
  howpublished =	 {arXiv},
  url = {https://arxiv.org/abs/1502.02127},
  year =	 2015
}

@article{shapiro,
  title =	 {How machine learning impacts the undergraduate
                  computing curriculum},
  author =	 {Shapiro, R Benjamin and Fiebrink, Rebecca and
                  Norvig, Peter},
  journal =	 {Communications of the ACM},
  volume =	 61,
  number =	 11,
  pages =	 {27--29},
  year =	 2018,
  publisher =	 {ACM New York, NY, USA}
}

@inproceedings{zou,
  title =	 {EasyHPC: An online programming platform for learning
                  high performance computing},
  author =	 {Zou, Zhepeng and Zhang, Yuxiao and Li, Jiang and
                  Hei, Xiaojun and Du, Yunfei and Wu, Di},
  booktitle =	 {2017 IEEE 6th International Conference on Teaching,
                  Assessment, and Learning for Engineering (TALE)},
  pages =	 {432--435},
  year =	 2017,
  organization = {IEEE}
}

@article{partee2022using,
  title =	 {Using machine learning at scale in numerical
                  simulations with {SmartSim}: An application to ocean
                  climate modeling},
  author =	 {Partee, Sam and Ellis, Matthew and Rigazzi,
                  Alessandro and Shao, Andrew E and Bachman, Scott and
                  Marques, Gustavo and Robbins, Benjamin},
  journal =	 {Journal of Computational Science},
  volume =	 62,
  pages =	 101707,
  year =	 2022,
  publisher =	 {Elsevier}
}

@inproceedings{boyer2022scalable,
  title =	 {Scalable Integration of Computational Physics
                  Simulations with Machine Learning},
  author =	 {Boyer, Mathew and Brewer, Wesley and Jude, Dylan and
                  Dettwiller, Ian},
  booktitle =	 {2022 IEEE/ACM International Workshop on Artificial
                  Intelligence and Machine Learning for Scientific
                  Applications (AI4S)},
  pages =	 {44--49},
  year =	 2022,
  organization = {IEEE}
}

@article{bhushan2023assessment,
  title =	 {Assessment of neural network augmented {Reynolds
                  averaged Navier Stokes} turbulence model in
                  extrapolation modes},
  author =	 {Bhushan, Shanti and Burgreen, Greg W and Brewer,
                  Wesley and Dettwiller, Ian D},
  journal =	 {Physics of Fluids},
  volume =	 35,
  number =	 5,
  year =	 2023,
  publisher =	 {AIP Publishing}
}

@inproceedings{brewer2021production,
  title =	 {Production deployment of machine-learned rotorcraft
                  surrogate models on {HPC}},
  author =	 {Brewer, Wesley and Martinez, Daniel and Boyer,
                  Mathew and Jude, Dylan and Wissink, Andy and
                  Parsons, Ben and Yin, Junqi and Anantharaj,
                  Valentine},
  booktitle =	 {2021 IEEE/ACM Workshop on Machine Learning in High
                  Performance Computing Environments (MLHPC)},
  pages =	 {21--32},
  year =	 2021,
  organization = {IEEE}
}

@inproceedings{brewer2024digital,
  author =	 {Brewer, Wesley and Maiterth, Matthias and Kumar,
                  Vineet and Wojda, Rafal and Bouknight, Sedrick and
                  Hines, Jesse and Shin, Woong and Greenwood, Scott
                  and Grant, David and Williams, Wesley and Wang,
                  Feiyi},
  title =	 {A digital twin framework for liquid-cooled
                  supercomputers as demonstrated at exascale},
  booktitle =	 {Proceedings of the International Conference for High
                  Performance Computing, Networking, Storage and
                  Analysis ({SC})},
  year =	 2024
}

@article{athavale2024digital,
  title =	 {Digital Twins for Data Centers},
  author =	 {Athavale, Jyotika and Bash, Cullen and Brewer,
                  Wesley and Maiterth, Matthias and Milojicic, Dejan
                  and Petty, Harry and Sarkar, Soumyendu},
  journal =	 {Computer},
  volume =	 57,
  number =	 10,
  pages =	 {151--158},
  year =	 2024,
  publisher =	 {IEEE}
}

@book{nas2023foundational,
  title =	 {Foundational Research Gaps and Future Directions for
                  Digital Twins},
  author =	 {{National Academies of Sciences, Engineering, and
                  Medicine}},
  url =		 {https://doi.org/10.17226/26894},
  year =	 2023,
  publisher =	 {The National Academies Press},
  address =	 {Washington, DC},
  doi =		 {10.17226/26894}
}

@inproceedings{reddi2020mlperf,
  title =	 {{MLPerf} inference benchmark},
  author =	 {Reddi, Vijay Janapa and Cheng, Christine and Kanter,
                  David and Mattson, Peter and Schmuelling, Guenther
                  and Wu, Carole-Jean and Anderson, Brian and Breughe,
                  Maximilien and Charlebois, Mark and Chou, William
                  and others},
  booktitle =	 {2020 ACM/IEEE 47th Annual International Symposium on
                  Computer Architecture (ISCA)},
  pages =	 {446--459},
  year =	 2020,
  organization = {IEEE}
}

@inproceedings{brewer2020inference,
  title =	 {Inference benchmarking on {HPC} systems},
  author =	 {Brewer, Wesley and Behm, Greg and Scheinine, Alan
                  and Parsons, Ben and Emeneker, Wesley and Trevino,
                  Robert P},
  booktitle =	 {2020 IEEE High Performance Extreme Computing
                  Conference (HPEC)},
  pages =	 {1--9},
  year =	 2020,
  organization = {IEEE}
}

@inproceedings{martinez2022roam,
  title =	 {{ROAM-ML}: A reduced order aerodynamic module
                  augmented with neural network digital surrogates},
  author =	 {Martinez-Gonzalez, Daniel A and Jude, Dylan and
                  Sitaraman, Jayanarayanan and Brewer, Wesley and
                  Wissink, Andrew M},
  booktitle =	 {AIAA SCITECH 2022 Forum},
  pages =	 1248,
  year =	 2022
}

@misc{brewer2024ai,
  title =	 {{AI-coupled HPC} Workflow Applications, Middleware
                  and Performance},
  author =	 {Brewer, Wes and Gainaru, Ana and Suter,
                  Fr{\'e}d{\'e}ric and Wang, Feiyi and Emani, Murali
                  and Jha, Shantenu},
  howpublished =	 {arXiv},
  year =	 2024,
  url= {https://github.com/cloudmesh/cloudmesh-ee}
}

@article{wilkinson2016fair,
  title =	 {The FAIR Guiding Principles for scientific data
                  management and stewardship},
  author =	 {Wilkinson, Mark D and Dumontier, Michel and
                  Aalbersberg, IJsbrand Jan and Appleton, Gabrielle
                  and Axton, Myles and Baak, Arie and Blomberg, Niklas
                  and Boiten, Jan-Willem and da Silva Santos, Luiz
                  Bonino and Bourne, Philip E and others},
  journal =	 {Scientific data},
  volume =	 3,
  number =	 1,
  pages =	 {1--9},
  year =	 2016,
  publisher =	 {Nature Publishing Group}
}

@article{jacobsen2020fair,
  title={FAIR principles: interpretations and implementation considerations},
  author={Jacobsen, Annika and de Miranda Azevedo, Ricardo and Juty, Nick and Batista, Dominique and Coles, Simon and Cornet, Ronald and Courtot, M{\'e}lanie and Crosas, Merc{\`e} and Dumontier, Michel and Evelo, Chris T and others},
  journal={Data intelligence},
  volume={2},
  number={1-2},
  pages={10--29},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{kirkpatrick2024,
 title={Using Benchmark Data to Inform Decisions Related to Machine Learning Resource Efficiency},
 author={Kirkpatrick, Christine and Barrett, Gregg and Brewer, Wesley and Christopher, Julie and Dutra, Inês and Emani, Murali and  Luszczek, Piotr and Shankar, Mallikarjun (Arjun) and Laszewski, Gregor von  and Papay, Juri and Fox, Geoffrey},
 year={2024}
}

@article{Font2024,
  doi =		 {10.1088/1742-6596/2753/1/012022},
  url =		 {https://dx.doi.org/10.1088/1742-6596/2753/1/012022},
  year =	 2024,
  month =	 {apr},
  publisher =	 {IOP Publishing},
  volume =	 2753,
  number =	 1,
  pages =	 012022,
  author =	 {Bernat Font and Francisco Alcántara-Ávila and Jean
                  Rabault and Ricardo Vinuesa and Oriol Lehmkuhl},
  title =	 {Active flow control of a turbulent separation bubble
                  through deep reinforcement learning},
  journal =	 {Journal of Physics: Conference Series},
  abstract =	 {The control efficacy of classical periodic forcing
                  and deep reinforcement learning (DRL) is assessed
                  for a turbulent separation bubble (TSB) at Reτ = 180
                  on the upstream region before separation occurs. The
                  TSB can resemble a separation phenomenon naturally
                  arising in wings, and a successful reduction of the
                  TSB can have practical implications in the reduction
                  of the aviation carbon footprint. We find that the
                  classical zero-net-mas-flux (ZNMF) periodic control
                  is able to reduce the TSB by 15.7%. On the other
                  hand, the DRL-based control achieves 25.3% reduction
                  and provides a smoother control strategy while also
                  being ZNMF. To the best of our knowledge, the
                  current test case is the highest Reynolds-number
                  flow that has been successfully controlled using DRL
                  to this date. In future work, these results will be
                  scaled to well-resolved large-eddy simulation
                  grids. Furthermore, we provide details of our
                  open-source CFD–DRL framework suited for the next
                  generation of exascale computing machines.}
}

﻿

@article{Maric2024OpenFOAM,
  author =	 {Maric, Tomislav and Fadeli, Mohammed Elwardi and
                  Rigazzi, Alessandro and Shao, Andrew and Weiner,
                  Andre},
  title =	 {Combining machine learning with computational fluid
                  dynamics using OpenFOAM and SmartSim},
  journal =	 {Meccanica},
  year =	 2024,
  month =	 {Apr},
  day =		 20,
  abstract =	 {Combining machine learning (ML) with computational
                  fluid dynamics (CFD) opens many possibilities for
                  improving simulations of technical and natural
                  systems. However, CFD+ML algorithms require exchange
                  of data, synchronization, and calculation on
                  heterogeneous hardware, making their implementation
                  for large-scale problems exceptionally
                  challenging. We provide an effective and scalable
                  solution to developing CFD+ML algorithms using open
                  source software OpenFOAM and SmartSim. SmartSim
                  provides an Orchestrator that significantly
                  simplifies the programming of CFD+ML algorithms
                  enables scalable data exchange between ML and CFD
                  clients. We show how to leverage SmartSim to
                  effectively couple different segments of OpenFOAM
                  with ML, including pre/post-processing applications,
                  function objects, and mesh motion solvers. We
                  additionally provide an OpenFOAM sub-module with
                  examples that can be used as starting points for
                  real-world applications in CFD+ML.},
  issn =	 {1572-9648},
  doi =		 {10.1007/s11012-024-01797-z},
  url =		 {https://doi.org/10.1007/s11012-024-01797-z}
}

@article{hamman2020pangeo,
  title =	 {The Pangeo Platform: a community-driven open-source
                  big data environment},
  author =	 {Hamman, Joseph and Henderson, Scott and Arendt,
                  Anthony and Tan, Amanda and Fatland, Dennis and
                  Pawloski, Andrew and Pilone, Daniel and Hanson,
                  Matthew and Augspurger, Tom and Abernathey, Ryan and
                  others},
  journal =	 {Earth and Space Science Open Archive ESSOAr},
  year =	 2020,
  publisher =	 {American Geophysical Union}
}

@Article{Yadan2019Hydra,
  author =	 {Omry Yadan},
  title =	 {Hydra - A framework for elegantly configuring
                  complex applications},
  howpublished = {Github},
  year =	 2019,
  url =		 {https://github.com/facebookresearch/hydra}
}

@inproceedings{brewer2023entropy,
  title =	 {Entropy-driven Optimal Sub-sampling of Fluid
                  Dynamics for Developing Machine-learned Surrogates},
  author =	 {Brewer, Wesley and Martinez, Daniel and
                  Gopalakrishnan Meena, Muralikrishnan and Kashi,
                  Aditya and Borowiec, Katarzyna and Liu, Siyan and
                  Pilmaier, Christopher and Burgreen, Greg and
                  Bhushan, Shanti},
  booktitle =	 {Proceedings of the SC'23 Workshops of The
                  International Conference on High Performance
                  Computing, Network, Storage, and Analysis},
  pages =	 {73--80},
  year =	 2023
}

@misc{liu2021pi3nn,
  title =	 {PI3NN: Out-of-distribution-aware prediction
                  intervals from three neural networks},
  author =	 {Liu, Siyan and Zhang, Pei and Lu, Dan and Zhang,
                  Guannan},
  howpublished =	 {arXiv},
  url = {https://arxiv.org/abs/2108.02327},
  year =	 2021
}

@inproceedings{martinez2018deep,
  title =	 {Deep learning evolutionary optimization for
                  regression of rotorcraft vibrational spectra},
  author =	 {Martinez, Daniel and Brewer, Wesley and Behm,
                  Gregory and Strelzoff, Andrew and Wilson, Andrew and
                  Wade, Daniel},
  booktitle =	 {2018 IEEE/ACM Machine Learning in HPC Environments
                  (MLHPC)},
  pages =	 {57--66},
  year =	 2018,
  organization = {IEEE}
}

@inproceedings{balaprakash2018deephyper,
  title =	 {Deephyper: Asynchronous hyperparameter search for
                  deep neural networks},
  author =	 {Balaprakash, Prasanna and Salim, Michael and Uram,
                  Thomas D and Vishwanath, Venkat and Wild, Stefan M},
  booktitle =	 {2018 IEEE 25th international conference on high
                  performance computing (HiPC)},
  pages =	 {42--51},
  year =	 2018,
  organization = {IEEE}
}

@article{bhushan2021development,
  title =	 {Development and Validation of a Machine Learned
                  Turbulence Model. Energies 2021, 14, 1465},
  author =	 {Bhushan, S and Burgreen, GW and Brewer, W and
                  Dettwiller, ID},
  year =	 2021,
  publisher =	 {s Note: MDPI stays neutral with regard to
                  jurisdictional claims in published~…}
}

@misc{pathak2022fourcastnet,
  title =	 {{FourCastNet}: A global data-driven high-resolution
                  weather model using adaptive {Fourier} neural
                  operators},
  author =	 {Pathak, Jaideep and Subramanian, Shashank and
                  Harrington, Peter and Raja, Sanjeev and
                  Chattopadhyay, Ashesh and Mardani, Morteza and
                  Kurth, Thorsten and Hall, David and Li, Zongyi and
                  Azizzadenesheli, Kamyar and others},
  howpublished =	 {arXiv},
  year =	 2022,
  url = {https://arxiv.org/abs/2202.11214}
}

@article{badia2024integrating,
  title =	 {Integrating HPC, AI, and Workflows for Scientific
                  Data Analysis: report from Dagstuhl Seminar 23352},
  author =	 {Badia Sala, Rosa Maria and Berti-Equille, Laure and
                  Ferreira da Silva, Rafael and Leser, Ulf},
  year =	 2024
}

@article{kirkpatrick2023,
  author =	 {Christine Kirkpatrick},
  title =	 {FAIRIST of them all: Meeting researchers where they
                  are with just-in-time, FAIR implementation advice},
  howpublished = {Invited talk at the WORKS workshop at the
                  Supercomputing Conference 2023, Denver},
  year =	 2023,
}

@article{Enders2020,
  author =	 {Enders, Bjoern and Bard, Debbie and Snavely, Cory
                  and Gerhardt, Lisa and Lee, Jason and Totzke, Becci
                  and Antypas, Katie and Byna, Suren and Cheema, Ravi
                  and Cholia, Shreyas and Day, Mark and Gaur, Aditi
                  and Greiner, Annette and Groves, Taylor and Kiran,
                  Mariam and Koziol, Quincey and Rowland, Kelly and
                  Samuel, Chris and Selvarajan, Ashwin and Sim, Alex
                  and Skinner, David and Thomas, Rollin and Torok,
                  Gabor},
  booktitle =	 {2020 IEEE/ACM 2nd Annual Workshop on Extreme-scale
                  Experiment-in-the-Loop Computing (XLOOP)},
  title =	 {Cross-facility science with the Superfacility
                  Project at LBNL},
  year =	 2020,
  pages =	 {1-7},
  keywords =	 {Collaboration;Tools;Databases;Data
                  models;Authorization;Automation;Standards;hpc;workflows;api;data},
  doi =		 {10.1109/XLOOP51963.2020.00006}
}

@inproceedings{las-19-harc-comet,
  author =	 {von Laszewski, Gregor and Fugang Wang and Geoffrey
                  C. Fox and Shawn Strande and Christopher Irving and
                  Trevor Cooper and Dmitry Mishin and Michael
                  L. Norman},
  title =	 {Human in the Loop Virtual Machine Management on
                  Comet},
  booktitle =	 {Humans in the Loop: Enabling and Facilitating
                  Research on Cloud Computing},
  year =	 2019,
  month =	 jul,
  address =	 {Chicago, IL, USA},
  doi =		 {10.1145/3355738.3355751},
  isbn =	 {978-1-4503-7279-4/19/07},
  url =
                  {https://laszewski.github.io/papers/vonLaszewski-human-comet.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-human-comet.pdf}}
}

@techreport{las-19-nist,
  author =	 {Gregor von Laszewski, Wo. L Chang},
  title =	 {NIST Big Data Interoperability Framework: Volume 8,
                  Reference Architecture Interfaces},
  institution =	 {institution},
  year =	 2019,
  month =	 jun,
  url =		 {https://laszewski.github.io/papers/nistvol8-2.pdf},
}

@inproceedings{las-17-teaching,
  title =	 {Teaching Big Data and Open Source Software on
                  Chameleon Cloud},
  author =	 {von Laszewski, Gergor and Fox, Geoffrey C.},
  booktitle =
                  {https://laszewski.github.io/papers/vonLaszewski-i524-chameleon.pdf},
  number =	 {Chameleon Cloud User Meeting},
  year =	 2017
}

@inproceedings{las-17-comet,
  title =	 {Comet: Tales from the Long Tail: Two Years in and
                  10,000 users later},
  author =	 {Strande, Shawn M and Cai, Haisong and Cooper, Trevor
                  and Flammer, Karen and Irving, Christopher and von
                  Laszewski, Gregor and Majumdar, Amit and Mishin,
                  Dmistry and Papadopoulos, Philip and Pfeiffer, Wayne
                  and others},
  booktitle =	 {Proceedings of the Practice and Experience in
                  Advanced Research Computing 2017 on Sustainability,
                  Success and Impact},
  pages =	 38,
  year =	 2017,
  organization = {ACM}
}

@misc{las-18-handbook,
  title =	 {Handbook of Clouds and Big Data},
  author =	 {von Laszewski, Gregor and Fox, Geoffrey C.},
  year =	 2018,
  publisher =
                  {https://laszewski.github.io/papers/vonLaszewski-bigdata.pdf}
}

@inproceedings{las-18-impact,
  title =	 {Evaluating the Scientific Impact of XSEDE},
  author =	 {Wang, Fugang and Laszewski, Gregor von and Whitson,
                  Timothy and Fox, Geoffrey C and Furlani, Thomas R
                  and DeLeon, Robert L and Gallo, Steven M},
  booktitle =	 {Proceedings of the Practice and Experience on
                  Advanced Research Computing},
  pages =	 10,
  year =	 2018,
  organization = {ACM},
  url =		 {http://doi.acm.org/10.1145/3219104.3219124},
  doi =		 {10.1145/3219104.3219124},
}

@techreport{las-17-cloudmesh,
  title =	 {Cloudmesh in support of the NIST Big Data
                  Architecture Framework},
  author =	 {von Laszewski, Gregor and Abdul-Wahid, Badi and
                  Wang, Fugang and Lee, Hyungro and Fox, Geoffrey C
                  and Chang, Wo},
  year =	 2017,
  institution =	 {Technical report, Indiana University, Bloomingtion
                  IN 47408, USA}
}

@incollection{las-17-futuregrid,
  title =	 {Futuregrid: a Reconfigurable Testbed for Cloud, Hpc,
                  and Grid Computing},
  author =	 {Fox, Geoffrey C and von Laszewski, Gregor and Diaz,
                  Javier and Keahey, Kate and Fortes, Jose and
                  Figueiredo, Renato and Smallen, Shava and Smith,
                  Warren and Grimshaw, Andrew},
  booktitle =	 {Contemporary High Performance Computing},
  pages =	 {603--635},
  year =	 2017,
  publisher =	 {Chapman and Hall/CRC}
}

@techreport{las-18-beckstein-contributions,
  title =	 {Contributions to High-Performance Big Data
                  Computing},
  author =	 {Beckstein, Oliver and Fox, Geoffrey and Qiu, Judy
                  and Crandall, David and von Laszewski, Gregor and
                  Paden, John and Jha, Shantenu and Wang, Fusheng and
                  Marathe, Madhav and Vullikanti, Anil and others},
  year =	 2018,
  institution =	 {Technical report, Digital Science Center},
  url =		 {https://laszewski.github.io/papers/bigdatahpc.pdf}
}

@inproceedings{las-15-tas,
  author =	 {DeLeon, Robert L. and Furlani, Thomas R. and Gallo,
                  Steven M. and White, Joseph P. and Jones, Matthew
                  D. and Patra, Abani and Innus, Martins and Yearke,
                  Thomas and Palmer, Jeffrey T. and Sperhac, Jeanette
                  M. and Rathsam, Ryan and Simakov, Nikolay and von
                  Laszewski, Gregor and Wang, Fugang},
  title =	 {TAS View of XSEDE Users and Usage},
  booktitle =	 {Proceedings of the 2015 XSEDE Conference: Scientific
                  Advancements Enabled by Enhanced
                  Cyberinfrastructure},
  series =	 {XSEDE '15},
  year =	 2015,
  isbn =	 {978-1-4503-3720-5},
  location =	 {St. Louis, Missouri},
  pages =	 {21:1--21:8},
  articleno =	 21,
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/2792745.2792766},
  doi =		 {10.1145/2792745.2792766},
  acmid =	 2792766,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {HPC, SUPReMM, TAS, XDMoD, XSEDE usage, XSEDE users},
}

@Article{las-10-multicore,
  Title =	 {{Multicores in Cloud Computing: Research Challenges
                  for Applications}},
  Author =	 {Lizhe Wang and Jie Tao and Gregor von Laszewski and
                  Holger Marten},
  Journal =	 {JCP},
  Year =	 2010,
  Number =	 6,
  Pages =	 {958-964},
  Volume =	 5,
  Bibsource =	 {DBLP, http://dblp.uni-trier.de},
  Doi =		 {10.4304/jcp.5.6.958-964},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-09-jcp2.pdf}
}

@Article{las-09-virt,
  Title =	 {{Grid Virtualization Engine: Design, Implementation,
                  and Evaluation}},
  Author =	 {Lizhe Wang and Gregor von Laszewski and Jie Tao and
                  Marcel Kunze},
  Journal =	 {IEEE Systems Journal},
  Year =	 2009,
  Number =	 4,
  Pages =	 {477-488},
  Volume =	 3,
  Bibsource =	 {DBLP, http://dblp.uni-trier.de},
  Doi =		 {10.1109/JSYST.2009.2028589},
  Otherlabel =	 {Wang09-systems-journal},
  Url =		 {https://laszewski.github.io/papers/isj_148.pdf}
}

@Article{las-09-yang,
  Title =	 {{Recent Research Advances in e-Science}},
  Author =	 {Yang, Xiaoyu and Wang, Lizhe and Laszewski, Gregor},
  Journal =	 {Cluster Computing},
  Year =	 2009,
  Month =	 dec,
  Number =	 4,
  Pages =	 {353--356},
  Volume =	 12,
  Acmid =	 1666210,
  Address =	 {Hingham, MA, USA},
  Doi =		 {10.1007/s10586-009-0104-0},
  ISSN =	 {1386-7857},
  Issue_date =	 {December 2009},
  Keywords =	 {Cloud computing, Grid computing, e-Science},
  Numpages =	 4,
  Publisher =	 {Kluwer Academic Publishers},
  Url =		 {10.1007/s10586-009-0104-0}
}

@InProceedings{las-10-energy,
  Title =	 {{Enabling Energy-Efficient Analysis of Massive
                  Neural Signals Using GPGPU}},
  Author =	 {Chen, Dan and Wang, Lizhe and Wang, Shuaiting and
                  Xiong, Muzhou and Laszewski, Gregor von and Li,
                  Xiaoli},
  Booktitle =	 {Proceedings of the 2010 IEEE/ACM Int'L Conference on
                  Green Computing and Communications \& Int'L
                  Conference on Cyber, Physical and Social Computing},
  Year =	 2010,
  Address =	 {Washington, DC, USA},
  Pages =	 {147--154},
  Publisher =	 {IEEE Computer Society},
  Series =	 {GREENCOM-CPSCOM '10},
  Acmid =	 1953550,
  Doi =		 {10.1109/GreenCom-CPSCom.2010.24},
  ISBN =	 {978-0-7695-4331-4},
  Keywords =	 {High Performance Computing, General-purpose
                  Computing on the Graphics Processing Unit, Neural
                  Signals, EEG},
  Numpages =	 8,
  Url =		 {10.1109/GreenCom-CPSCom.2010.24}
}

@InProceedings{las-12-comparisoncloud,
  Title =	 {{Comparison of Multiple Cloud Frameworks}},
  Author =	 {Gregor von Laszewski and Javier Diaz and Fugang Wang
                  and Geoffrey C. Fox},
  Booktitle =	 {IEEE Cloud 2012},
  Year =	 2012,
  Address =	 {Honolulu, HI},
  Month =	 jun,
  Doi =		 {10.1109/CLOUD.2012.104},
  Url =
                  {https://laszewski.github.io/papers/laszewski-IEEECloud2012_id-4803.pdf}
}

@Techreport{las-12-fg-1471,
  Title =	 {{Supporting Experimental Computer Science}},
  Author =	 {Frederic Desprez and Fox, Geoffrey and Emmanuel
                  Jeannot and Kate Keahey and Michael Kozuch and David
                  Margery and Pierre Neyron and Lucas Nussbaum and
                  Christian Perez and Olivier Richard and Warren Smith
                  and Gregor von Laszewski and Jens Voeckler},
  Year =	 2012,
  Month =	 mar,
  Address =	 {Argonne},
  Institution =	 {Argonne National Laboratory},
  ISSN =	 {Technical Memo 326},
  Type =	 {Report},
  Url =
                  {https://laszewski.github.io/papers/Supporting_Experimental_Computer_Science_final_draft.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/Supporting_Experimental_Computer_Science_final_draft.pdf}}
}

@Misc{las-15-futuresystems,
  author =	 {{Digital Science Lab}},
  Title =	 {FutureSystems at Indiana University},
  year =	 2015,
  Url =		 {https://portal.futuresystems.org/}
}

@InProceedings{las-12-imagemanagement,
  Title =	 {{Abstract Image Management and Universal Image
                  Registration for Cloud and HPC Infrastructures}},
  Author =	 {Javier Diaz and Gregor von Laszewski and Fugang Wang
                  and Geoffrey C. Fox},
  Booktitle =	 {IEEE Cloud 2012},
  Year =	 2012,
  Address =	 {Honolulu},
  Month =	 jun,
  Doi =		 {10.1109/CLOUD.2012.94},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-12-IEEECloud2012.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-12-IEEECloud2012.pdf}}
}

@InProceedings{las-11-grapple,
  Title =	 {{Grappling cloud infrastructure services with a
                  generic image repository}},
  Author =	 {Javier Diaz and Andrew Younge and von Laszewski,
                  Gregor and FugangWang and Fox, Geoffrey C.},
  Booktitle =	 {CCA11: Cloud Computing and Its Applications},
  Year =	 2011,
  Address =	 {Argonne National Laboratory, USA.},
  Month =	 apr,
  day =		 {12-13},
  Url =
                  {https://laszewski.github.io/papers/11-imagerepo-cca.pdf}
}

@InProceedings{las-09-ogce-tg,
  Title =	 {{Open Grid Computing Environments}},
  Author =	 {Pierce, Marlon and Marru, S. and Wenjun Wu and Gopi
                  Kandaswami and von Laszewski, Gregor and Rion Dooley
                  and Maytal Dahan and Nancy Wilkins-Diehr and Thomas,
                  Mary},
  Booktitle =	 {TeraGrid 09 meeting},
  Year =	 2009,
  Address =	 {Arlington, VA},
  day =		 24,
  Month =	 jun,
  Url =		 {https://laszewski.github.io/papers/OGCETG09-1-1.pdf}
}

@InProceedings{las--7-swift,
  Title =	 {{Swift: Fast, Reliable, Loosely Coupled Parallel
                  Computation}},
  Author =	 {Yong Zhao and Hategan, M. and Clifford, B. and
                  Foster, I. and von Laszewski, G. and Nefedova,
                  V. and Raicu, I. and Stef-Praun, T. and Wilde, M.},
  Booktitle =	 {Services, 2007 IEEE Congress on},
  Year =	 2007,
  Pages =	 {199-206},
  Doi =		 {10.1109/SERVICES.2007.63},
  Keywords =	 {formal specification, grid computing, software
                  reliability, GriPhyN virtual data system, Swift
                  system, SwiftScript language, complex file system
                  structures, runtime system, scripting language,
                  Computer science, Concurrent computing, Data
                  systems, Distributed computing, File systems, High
                  performance computing, Laboratories, Magnetic
                  analysis, Mathematics, Power system reliability}
}

@InProceedings{las-00-grande,
  Title =	 {{CoG Kits: A Bridge between Commodity Distributed
                  Computing and High-Performance Grids}},
  Author =	 {von Laszewski, Gregor and Ian Foster and Jarek Gawor
                  and Warren Smith and Steve Tuecke},
  Booktitle =	 {Proceedings of the ACM 2000 conference on Java
                  Grande},
  Year =	 2000,
  Address =	 {San Francisco, CA},
  Month =	 jun,
  day =		 {3-4},
  Pages =	 {97-106},
  Publisher =	 {ACM, New York, NY, USA},
  Series =	 {JAVA'00},
  Acmid =	 337491,
  Doi =		 {10.1145/337449.337491},
  ISBN =	 {1-58113-288-3},
  Location =	 {San Francisco, California, United States},
  Numpages =	 10,
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-cog-final.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-cog-final.pdf}}
}

@InProceedings{las-00-moba,
  Title =	 {{Grid-based Asynchronous Migration of Execution
                  Context in Java Virtual Machines}},
  Author =	 {von Laszewski, Gregor and Kazuyuki Shudo and Yoichi
                  Muraoka},
  Booktitle =	 {{Proceedings of EuroPar 2000}},
  Year =	 2000,
  Address =	 {Munich, Germany},
  Editor =	 {Arndt Bode and Thomas Ludwig and Wolfgang Karl and
                  Roland Wism{\"u}ller},
  Month =	 aug,
  day =		 {29~aug ~-~1~ sep},
  Note =	 {{{\em (Invited Talk)}}},
  Pages =	 {22-34},
  Publisher =	 {Springer},
  Series =	 {Lecture Notes in Computer Science},
  Volume =	 1900,
  Doi =		 {10.1007/3-540-44520-X_3},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/s/vonLaszewski-mobag.pdf}
}

@Article{las-00-sbc,
  Title =	 {{Using Computational Grid Capabilities to Enhance
                  the Ability of an X-Ray Source for Structural
                  Biology}},
  Author =	 {von Laszewski, Gregor and Mary Westbrook and Ian
                  Foster and Edwin Westbrook and Craig Barnes},
  Journal =	 {Cluster Computing},
  Year =	 2000,
  Number =	 3,
  Pages =	 {187-199},
  Volume =	 3,
  Doi =		 {10.1023/A:1019036421819},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-dtrek.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-dtrek.pdf}}
}

@Article{las-01-acm,
  Title =	 {{Multi-Paradigm Communications in Java for Grid
                  Computing}},
  Author =	 {Vladimir Getov and von Laszewski, Gregor and Michael
                  Philippsen and Ian Foster},
  Journal =	 {Communications of ACM},
  Year =	 2001,
  Month =	 oct,
  Number =	 10,
  Pages =	 {118-125},
  Volume =	 44,
  Acmid =	 383872,
  Address =	 {New York, NY, USA},
  Doi =		 {10.1145/383845.383872},
  ISSN =	 {0001-0782},
  Publisher =	 {ACM},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-cacm.pdf}
}

@Article{las-01-cmt,
  Title =	 {{A High-Throughput X-Ray Microtomography System at
                  the Advanced Photon Source}},
  Author =	 {Yuxin Wang and Fransesco De Carlo and Derrick
                  Mancini and Ian McNulty and Brian Tieman and John
                  Bresnahan and Ian Foster and Joseph Insley and Peter
                  Lane and von Laszewski, Gregor and Carl Kesselman
                  and Mei-Hui Su and Marcus Thiebaux},
  Journal =	 {Review of Scientific Instruments},
  Year =	 2001,
  Month =	 apr,
  Number =	 4,
  Pages =	 {2062-2068},
  Volume =	 72,
  Annote =	 {Received 14 November 2000; accepted for publication
                  23 January 2001},
  Doi =		 {10.1063/1.1355270},
  Label =	 {YDeD01},
  Url =
                  {https://laszewski.github.io/papers/vonlaszewski-RSI01.pdf}
}

@Article{las-01-cog-concurency,
  Title =	 {{A Java Commodity Grid Kit}},
  Author =	 {von Laszewski, Gregor and Ian Foster and Jarek Gawor
                  and Peter Lane},
  Journal =	 {Concurrency and Computation: Practice and
                  Experience},
  Year =	 2001,
  Number =	 {8-9},
  Pages =	 {645--662},
  Volume =	 13,
  Doi =		 {10.1002/cpe.572},
  ISSN =	 {1532-0634},
  Keywords =	 {Commodity Grid Toolkits, Java CoG Kit, Computational
                  Grid},
  Publisher =	 {John Wiley and Sons, Ltd.},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-cog-cpe-final.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-cog-cpe-final.pdf}}
}

@InProceedings{las-01-corba,
  Title =	 {{Design and Implementation of a CORBA Commodity Grid
                  Kit}},
  Author =	 {Verma, Snigdha and Parashar, Manish and Gawor, Jarek
                  and von Laszewski, Gregor},
  Booktitle =	 {{Proceedings of the Second International Workshop on
                  Grid Computing (GRID'01)}},
  Year =	 2001,
  Address =	 {Denver},
  Editor =	 {Craig A. Lee},
  Month =	 nov,
  Note =	 {http://dl.acm.org/citation.cfm?id=645441.652851},
  Pages =	 {2-12},
  Publisher =	 {Springer-Verlag, London, UK, UK},
  Series =	 {Lecture Notes in Computer Science},
  Volume =	 2241,
  Acmid =	 652851,
  ISBN =	 {3-540-42949-2},
  Numpages =	 12,
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-corba.pdf}
}

@InProceedings{las-01-greed,
  Title =	 {{A Greedy Grid - The Grid Economic Engine
                  Directive}},
  Author =	 {Vazhkudai, Sudharshan and von Laszewski, Gregor},
  Booktitle =	 {Proceedings of the 15th International Parallel and
                  Distributed Processing Symposium, International
                  Workshop on Internet Computing and E-Commerce
                  (ICEC'01)},
  Year =	 2001,
  Address =	 {San Francisco, California, USA},
  Month =	 apr,
  day =		 {27~},
  Note =	 {http://dl.acm.org/citation.cfm?id=645609.662793},
  Pages =	 {173--},
  Publisher =	 {IEEE Computer Society, Washington, DC, USA},
  Series =	 {IPDPS '01},
  Acmid =	 662793,
  ISBN =	 {0-7695-0990-8},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-greed.pdf}
}

@InProceedings{las-01-hpdc-cactus,
  Title =	 {{The Astrophysics Simulation Collaboratory: A
                  Science Portal Enabling Community Software
                  Development}},
  Author =	 {Michael Russell and Gabrielle Allen and Ian Foster
                  and Ed Seidel and Jason Novotny and John Shalf and
                  von Laszewski, Gregor and Greg Daues},
  Booktitle =	 {{Proceedings of the 10th IEEE International
                  Symposium on High Performance Distributed
                  Computing}},
  Year =	 2001,
  Address =	 {San Francisco, CA},
  Month =	 aug,
  day =		 {7-9~},
  Pages =	 {207-215},
  Doi =		 {10.1109/HPDC.2001.945190},
  ISSN =	 {1082-8907},
  Url =		 {https://laszewski.github.io/papers/astro-hpdc10.pdf}
}

%Note =	 {\url{http://dl.acm.org/citation.cfm?id=820738.820812}},
  
@InProceedings{las-01-pse,
  Title =	 {{Designing Grid-based Problem Solving Environments
                  and Portals}},
  Author =	 {von Laszewski, Gregor and Ian Foster and Jarek Gawor
                  and Peter Lane and Nell Rehn and Mike Russell},
  Booktitle =	 {Proceedings of the 34th Annual Hawaii International
                  Conference on System Sciences (HICSS-34)},
  Year =	 2001,
  Address =	 {Maui, Hawaii},
  Month =	 jan,
  day =		 {3-6},
  Pages =	 {9028--},
  Publisher =	 {IEEE Computer Society, Washington, DC, USA},
  Series =	 {HICSS '01},
  Volume =	 9,
  Acmid =	 820812,
  ISBN =	 {0-7695-0981-9},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-cog-pse-final.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-cog-pse-final.pdf}}
}

@InProceedings{las-02-activetable,
  Title =	 {{A Grid Service Based Active Thermochemical Table
                  Framework}},
  Author =	 {Laszewski, Gregor von and Ruscic, Branko and
                  Wagstrom, Patrick and Krishnan, Sriram and Amin,
                  Kaizar and Nijsure, Sandeep and Bittner, Sandra and
                  Pinzon, Reinhardt and Hewson, John C. and Morton,
                  Melita L. and Minkoff, Mike and Wagner, Al},
  Booktitle =	 {Third International Workshop on Grid Computing (GRID
                  '02)},
  Year =	 2002,
  Address =	 {Baltimore, MD},
  Month =	 nov,
  day =		 18,
  Note =	 {http://dl.acm.org/citation.cfm?id=645442.652663},
  Pages =	 {25-38},
  Publisher =	 {Springer-Verlag, London, UK, UK},
  Series =	 {Lecture Notes in Computer Science},
  Volume =	 2536,
  Acmid =	 652663,
  ISBN =	 {3-540-00133-6},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-cmcs.pdf}
}

@Article{las-02-cactus,
  Title =	 {{Community Software Development with the
                  Astrophysics Simulation Collaboratory}},
  Author =	 {von Laszewski, Gregor and Michael Russell and Ian
                  Foster and John Shalf and Gabrielle Allen and Greg
                  Daues and Jason Novotny and Edward Seidel},
  Journal =	 {Concurrency and Computation: Practice and
                  Experience},
  Year =	 2002,
  Number =	 {13-15},
  Pages =	 {1289-1301},
  Volume =	 14,
  Doi =		 {10.1002/cpe.688},
  ISSN =	 {1532-0634},
  Otherlabel =	 {Laszewski01communitysoftware},
  Publisher =	 {John Wiley and Sons, Ltd.},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-cactus5.pdf}
}

@Article{las-02-cactus-j,
  Title =	 {{The Astrophysics Simulation Collaboratory: A
                  Science Portal Enabling Community Software
                  Development}},
  Author =	 {Michael Russell and Gabrielle Allen and Ian Foster
                  and Ed Seidel and Jason Novotny and John Shalf and
                  von Laszewski, Gregor and Greg Daues},
  Journal =	 {Journal on Cluster Computing},
  Year =	 2002,
  Month =	 jul,
  Number =	 3,
  Pages =	 {297-304},
  Volume =	 5,
  Acmid =	 593012,
  Address =	 {Hingham, MA, USA},
  Doi =		 {10.1023/A:1015629422149},
  ISSN =	 {1386-7857},
  Numpages =	 8,
  Oldlabel =	 {DBLP:journals/cluster/RussellADFSNSL02},
  Oldlabels =	 {cactusclster},
  Publisher =	 {Kluwer Academic Publishers},
  Url =		 {https://laszewski.github.io/papers/astro-jcc.pdf}
}

@Article{las-02-corbacog,
  Title =	 {{A CORBA Commodity Grid Kit}},
  Author =	 {Manish Parashar and von Laszewski, Gregor and
                  Snigdha Verma and Jarek Gawor and Kate Keahey},
  Journal =	 {Concurrency and Computation: Practice and
                  Experience},
  Year =	 2002,
  Pages =	 {1057-1074},
  Volume =	 14,
  Doi =		 {10.1002/cpe.682},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/corbacog-ccpe-gce01-final.pdf}
}

@InProceedings{las-02-deploy,
  Title =	 {{Software, Component, and Service Deployment in
                  Computational Grids}},
  Author =	 {von Laszewski, Gregor and Eric Blau and Michael
                  Bletzinger and Jarek Gawor and Peter Lane and Stuart
                  Martin and Michael Russell},
  Booktitle =	 {{IFIP/ACM Working Conference on Component
                  Deployment}},
  Year =	 2002,
  Address =	 {Berlin, Germany},
  Editor =	 {Judith Bishop},
  Month =	 jun,
  day =		 {20-21~},
  Note =	 {http://dl.acm.org/citation.cfm?id=647479.727944},
  Pages =	 {244-256},
  Publisher =	 {Springer-Verlag, London, UK},
  Series =	 {Lecture Notes in Computer Science},
  Volume =	 2370,
  Acmid =	 727944,
  ISBN =	 {3-540-43847-5},
  Numpages =	 13,
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-deploy-32.pdf}
}

@InProceedings{las-11-fg-1295,
  Title =	 {{FutureGrid Image Repository: A Generic Catalog and
                  Storage System for Heterogeneous Virtual Machine
                  Images}},
  Author =	 {Javier Diaz and Gregor von Laszewski and Fugang Wang
                  and Younge, Andrew J and Geoffrey C. Fox},
  Booktitle =	 {Third IEEE International Conference on Coud
                  Computing Technology and Science (CloudCom2011)},
  Year =	 2011,
  Address =	 {Athens, Greece},
  Month =	 dec,
  Pages =	 {560-564},
  Doi =		 {10.1109/CloudCom.2011.85},
  Keywords =	 {image repository},
  Type =	 {paper},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-draft-11-imagerepo.pdf}
}

@InProceedings{las-02-gcc,
  Title =	 {{A QoS Guided Scheduling Algorithm for the
                  Computational Grid}},
  Author =	 {X. He and X.-H. Sun and G. Laszewski},
  Booktitle =	 {{Proceedings of the International Workshop on Grid
                  and Cooperative Computing (GCC02)}},
  Year =	 2002,
  Address =	 {Hainan, Chian},
  Month =	 dec,
  Url =		 {https://laszewski.github.io/papers/GCC02_XHe.pdf}
}

@Article{las-02-grip,
  Title =	 {{A Unicore Globus Interoperability Layer}},
  Author =	 {David Snelling and Sven van den Berghe and von
                  Laszewski, Gregor and Philipp Wieder and D. Breuer
                  and Jon MacLaren and Denis Nicole and John Brooke
                  and Hans-Christian Hoppe.},
  Journal =	 {Computing and Informatics},
  Year =	 2002,
  Pages =	 {399-411},
  Volume =	 21,
  ISSN =	 {1335-9150},
  Url =		 {https://laszewski.github.io/papers/D4.1b_draft.pdf}
}

%  Note =	 {http://dl.acm.org/citation.cfm?id=822086.823347},
@InProceedings{las-02-infogram,
  Title =	 {{InfoGram: A Peer-to-Peer Information and Job
                  Submission Service}},
  Author =	 {von Laszewski, Gregor and Jarek Gawor and Carlos
                  J. Pe{\~n}a and Ian Foster},
  Booktitle =	 {{Proceedings of the 11th Symposium on High
                  Performance Distributed Computing}},
  Year =	 2002,
  Address =	 {Edinbrough, U.K.},
  Month =	 jul,
  day =		 {24-26~},
  Pages =	 {333-342},
  Publisher =	 {IEEE Computer Society, Washington, DC, USA},
  Series =	 {HPDC '02},
  Acmid =	 823347,
  ISBN =	 {0-7695-1686-6},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-infogram.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-infogram.pdf}}
}

@Article{las-02-javacog,
  Title =	 {{Features of the Java Commodity Grid Kit}},
  Author =	 {von Laszewski, Gregor and Jarek Gawor and Peter Lane
                  and Nell Rehn and Mike Russell and Keith Jackson},
  Journal =	 {Concurrency and Computation: Practice and
                  Experience},
  Year =	 2002,
  Number =	 {13-15},
  Pages =	 {1045-1055},
  Volume =	 14,
  Doi =		 {10.1002/cpe.674},
  ISSN =	 {1532-0634},
  Publisher =	 {John Wiley and Sons, Ltd.},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-cog-features.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-cog-features.pdf}}
}

@InProceedings{las-02-ocgsa,
  Title =	 {{Open Collaborative Grid Services Architecture
                  (OCGSA)}},
  Author =	 {Kaizar Amin and Sandeep Nijsure and von Laszewski,
                  Gregor},
  Booktitle =	 {Euroweb 2002 Conference, The Web and the GRID: from
                  e-Science to e-Business},
  Year =	 2002,
  Address =	 {St Anne's College Oxford, UK},
  Month =	 dec,
  day =		 {17-18~},
  Pages =	 {101-107},
  Publisher =	 {The British Computer Society},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-ocgsa.pdf}
}

@InProceedings{las-02-pdcs,
  Title =	 {{Key Concepts and Services of a Grid Information
                  Service}},
  Author =	 {Beth Plale and Peter Dinda and Mike Helm and von
                  Laszewski, Gregor and John McGee},
  Booktitle =	 {15th International Conference on Parallel and
                  Distributed Computing Systems (PDCS 2002)},
  Year =	 2002,
  Address =	 {Louisville, KY},
  Month =	 sep,
  day =		 {19~},
  Note =
                  {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.209},
  Pages =	 {437-442},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/plale--pdcs2002.pdf}
}

@Article{las-02-perlcog,
  Title =	 {{A Perl Commodity Grid Kit}},
  Author =	 {Mock, Stephen and Thomas, Mary and Dahan, Maytal and
                  Mueller, Kurt and Mills, Catherine and von
                  Laszewski, Gregor},
  Journal =	 {Concurrency and Computation: Practice and
                  Experience},
  Year =	 2002,
  Number =	 {13-15},
  Pages =	 {1085-1095},
  Volume =	 14,
  Doi =		 {10.1002/cpe.695},
  ISSN =	 {1532-0634},
  Keywords =	 {Grid, PERL, CoG, commodity, toolkit, Globus, storage
                  resource broker, SRB, module, portal, middleware},
  Publisher =	 {John Wiley and Sons, Ltd.},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-perl-cog.pdf}
}

@InProceedings{las-02-vision,
  Title =	 {{Grid Computing: Enabling a Vision for Collaborative
                  Research}},
  Author =	 {von Laszewski, Gregor},
  Booktitle =	 {{The Sixth International Conference on Applied
                  Parallel Computing}},
  Year =	 2002,
  Address =	 {Espoo, Finland},
  Editor =	 {Fagerholm, Juha and Haataja, Juha and J\"{a}rvinen,
                  Jari and Lyly, Mikko and R\o{a}back, Peter and
                  Savolainen, Ville},
  Month =	 jun,
  day =		 {15-18~},
  Note =	 {{\em (Invited Talk)}},
  Pages =	 {37-52},
  Publisher =	 {Springer Berlin / Heidelberg},
  Series =	 {Lecture Notes in Computer Science},
  Volume =	 2367,
  Doi =		 {10.1007/3-540-48051-X_4},
  ISBN =	 {978-3-540-43786-4},
  Oldlabel =	 {las02para},
  Pdfother =
                  {https://laszewski.github.io/papers/vonLaszewski-grid.pdf},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-para4.pdf}
}

@InProceedings{las-03-chem,
  Title =	 {{Further Refinements of the Bond Dissociation Energy
                  in Water and Hydroxyl Radical Using the Active
                  Thermochemical Tables Approach}},
  Author =	 {B. Ruscic and R. E. Pinzon and M. L. Morton and
                  B. Wang and A. F. Wagner and G. von Laszevski and
                  S. G. Nijsure and K. A. Amin and Sandra J. Bittner
                  and M. Minkoff},
  Booktitle =	 {Proceedings of the 58th International Symposium
                  Molecular Sectrosctroscopy},
  Year =	 2003,
  Address =	 {Columbus, OH},
  Month =	 jun,
  day =		 {16-20~},
  Pages =	 178,
  Status =	 {final},
  Url =		 {http://hdl.handle.net/1811/21100}
}

@InCollection{las-03-cmt-book,
  Title =	 {{Sourcebook of Parallel Computing}},
  Author =	 {von Laszewski, Gregor and Mei-Hui Su and Joseph
                  Insley and Ian Foster and Carl Kesselman},
  Booktitle =	 {{Quasi-Realtime Microtomography Experiments at
                  Photon Sources}},
  Publisher =	 {Morgan Kaufman Publishers},
  Year =	 2003,
  Address =	 {New York},
  Editor =	 {Jack Dongara and Ian Foster and Geoffrey Fox and
                  Wiliam Gropp and Kenn Kennedy and Linda Torczon and
                  Andy White},
  Pages =	 {258-265},
  ISBN =	 9781558608719,
  Oldlabels =	 {las00handbook},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-cmtscience.pdf}
}

@InProceedings{las-03-coalloc,
  Title =	 {{Flow-based Multistage Co-allocation Service}},
  Author =	 {Sudeepth Ananad and Srikanath Yoginath and von
                  Laszewski, Gregor and Beulah Alunkal},
  Booktitle =	 {Proceedings of the International Conference on
                  Communications in Computing},
  Year =	 2003,
  Address =	 {Las Vegas},
  Editor =	 {Braan J d'Auriol},
  Month =	 jun,
  day =		 {~23-26},
  Pages =	 {24-30},
  Publisher =	 {CSREA Press},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-coalloc.pdf}
}

@InProceedings{las-03-dc,
  Title =	 {{Metadata in the Collaboratory for Multi-Scale
                  Chemical Science}},
  Author =	 {Carmen Pancerella and James D. Myers and Thomas
                  C. Allison and Kaizar Amin and Sandra Bittner and
                  Brett Didier and Michael Frenklach and William
                  H. Green, Jr. and Yen-Ling Ho and John Hewson and
                  Wendy Koegler and Carina Lansing and David Leahy and
                  Michael Lee and Renata McCoy and Michael Minkoff and
                  Sandeep Nijsure and von Laszewski, Gregor and David
                  Montoya and Reinhardt Pinzon and William Pitz and
                  Larry Rahn and Branko Ruscic and Karen Schuchardt
                  and Eric Stephan and Al Wagner and Baoshan Wang and
                  Theresa Windus and Lili Xu and Christine Yang},
  Booktitle =	 {2003 Dublin Core Conference: Supporting Communities
                  of Discourse and Practice-Metadata Research and
                  Applications},
  Year =	 2003,
  Address =	 {Seatle, WA},
  day =		 {28~} # sep # {~--~2~} # oct,
  Month =	 sep,
  ISBN =	 0974530301,
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-dublin-core.pdf}
}

@InProceedings{las-03-ftp,
  Title =	 {{A File Transfer Component for Grids}},
  Author =	 {von Laszewski, Gregor and Beulah Alunkal and Jarek
                  Gawor and Ravi Madhuri and Pawel Plaszczak and
                  Xian-He Sun},
  Booktitle =	 {Proceedings of the International Conferenece on
                  Parallel and Distributed Processing Techniques and
                  Applications},
  Year =	 2003,
  Address =	 {Las Vegas},
  Editor =	 {H.R. Arabnia and Youngson Mun},
  Month =	 jun,
  day =		 {~23-26},
  Pages =	 {24-30},
  Publisher =	 {CSREA Press},
  Volume =	 1,
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-gridftp.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-gridftp.pdf}}
}

@InCollection{las-03-gridcomputing,
  Title =	 {{Commodity Grid Kits - Middleware for Building Grid
                  Computing Environments}},
  Author =	 {von Laszewski, Gregor and Jarek Gawor and Sriram
                  Krishnan and Keith Jackson},
  Booktitle =	 {{Grid Computing: Making the Global Infrastructure a
                  Reality}},
  Publisher =	 {Wiley},
  Year =	 2003,
  Editor =	 {Fran Berman and Geoffrey Fox and Toney Hey},
  Pages =	 {639-656},
  Series =	 {Communications Networking and Distributed Systems},
  ISBN =	 {0-470-85319-0},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-grid2002book.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-grid2002book.pdf}}
}

@Article{las-03-knowledge,
  Title =	 {{A Framework for Building Scientific Knowledge Grids
                  Applied to Thermochemical Tables}},
  Author =	 {von Laszewski, Gregor and Branko Ruscic and Kaizar
                  Amin and Patrick Wagstrom and Sriram Krishnan and
                  Sandeep Nijsure},
  Journal =	 {The International Journal of High Performance
                  Computing Applications},
  Year =	 2003,
  Month =	 dec,
  day =		 {Winter},
  Number =	 4,
  Pages =	 {431-447},
  Volume =	 17,
  Doi =		 {10.1177/10943420030174007},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-knowledge-grid.pdf}
}

@InProceedings{las-03-masses,
  Title =	 {{Grid Computing for the Masses: An Overview}},
  Author =	 {Kaizar Amin and von Laszewski, Gregor and Armin
                  R. Mikler},
  Booktitle =	 {Grid and Cooperative Computing (GCC2003)},
  Year =	 2003,
  Address =	 {Shanghai, China},
  Month =	 dec,
  Pages =	 {464-473},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-masses-gcc03.pdf}
}

@InProceedings{las-03-qos,
  Title =	 {{An OGSA-based Quality of Service Framework}},
  Author =	 {Rashid Al-Ali and Kaizar Amin and von Laszewski,
                  Gregor and Omer Rana and David Walker},
  Booktitle =	 {Proceedings of the Second International Workshop on
                  Grid and Cooperative Computing (GCC2003)},
  Year =	 2004,
  Address =	 {Shanghai, China},
  Editor =	 {Li, Minglu and Sun, Xian-He and Deng, Qianni and Ni,
                  Jun},
  Month =	 dec,
  day =		 {7-10~},
  Number =	 3003,
  Pages =	 {529-540},
  Publisher =	 {Springer Berlin / Heidelberg},
  Series =	 {Lecture Notes on Computer Science},
  Anote =	 {ISBN: 3-540-21993-5},
  Doi =		 {10.1007/978-3-540-24680-0_88},
  ISBN =	 {978-3-540-21993-4},
  Url =
                  {https://laszewski.github.io/papers//vonLaszewski-qos.pdf}
}

@InProceedings{las-03-reputation,
  Title =	 {{Reputation-based Grid Resource Selection}},
  Author =	 {Beulah Alunkal and Ivana Veljkovic and von
                  Laszewski, Gregor and Kaizar Amin},
  Booktitle =	 {Workshop on Adaptive Grid Middleware},
  Year =	 2003,
  Address =	 {New Orleans, Louisiana},
  Month =	 sep,
  day =		 {27~},
  Organization = {AGridM 2003},
  Institution =	 {Argonne National Laboratory},
  Type =	 {Argonne Preprint},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-reputation.pdf}
}

@Article{las-04-abstraction-j,
  Title =	 {{An Abstraction Model for a Grid Execution
                  Framework}},
  Author =	 {Kaizar Amin and von Laszewski, Gregor and Rashid Al
                  Ali and Omer Rana and David Walker},
  Journal =	 {Euromicro Journal of Systems Architecture},
  Year =	 2006,
  Number =	 2,
  Pages =	 {73-87},
  Volume =	 52,
  Acmid =	 1140809,
  Address =	 {New York, NY, USA},
  Doi =		 {10.1016/j.sysarc.2004.10.007},
  ISSN =	 {1383-7621},
  Numpages =	 15,
  Oldlabels =	 {las04-abstraction-journal},
  Publisher =	 {Elsevier North-Holland, Inc.},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-abstraction-jsa.pdf}
}

@Article{las-04-ftp-journal,
  Title =	 {{An Overview of Grid File Transfer Patterns and
                  their Implementation in the Java CoG Kit}},
  Author =	 {von Laszewski, Gregor and Jarek Gawor and Pawel
                  Plaszczak and Mike Hategan and Kaizar Amin and Ravi
                  Madduri and Scott Gose},
  Journal =	 {Journal of Neural Parallel and Scientific Computing},
  Year =	 2004,
  Month =	 sep,
  Note =	 {Special Issue on Grid Computing},
  Number =	 3,
  Pages =	 {329-352},
  Volume =	 12,
  Acmid =	 1093539,
  Address =	 {Atlanta, GA, USA},
  ISSN =	 {1061-5369},
  Numpages =	 24,
  Publisher =	 {Dynamic Publishers, Inc.},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-overview-gridftp.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-overview-gridftp.pdf}}
}

@InProceedings{las-04-qos-ccgrid,
  Title =	 {{QoS Support for High-performance Scientific Grid
                  Applications}},
  Author =	 {Rashid Al-Ali and von Laszewski, Gregor and Kaizar
                  Amin and Mihael Hategan and Omer Rana and David
                  Walker and Nester Zaluzec},
  Booktitle =	 {Proceedings of the IEEE/ACM 4th International
                  Symposium on Cluster Computing and the Grid (CCGrid
                  2004)},
  Year =	 2004,
  Address =	 {Chicago IL, USA},
  Month =	 apr,
  day =		 {19-22~},
  Pages =	 {134-143},
  Publisher =	 {IEEE Computer Society Press},
  Doi =		 {10.1109/CCGrid.2004.1336559},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-qos-ccgrid04.pdf}
}

@Article{las-04-qos-journal,
  Title =	 {{Analysis and Provision of QoS for Distributed Grid
                  Applications}},
  Author =	 {Al-Ali, Rashid J. and Amin, Kaizar and von
                  Laszewski, Gregor and Rana, Omer F. and Walker,
                  David W. and Hategan, Mihael and Zaluzec, Nestor},
  Journal =	 {Journal of Grid Computing},
  Year =	 2004,
  Month =	 jun,
  Note =	 {10.1007/s10723-004-6743-8},
  Number =	 2,
  Pages =	 {163-182},
  Volume =	 2,
  Doi =		 {10.1007/s10723-004-6743-8},
  ISSN =	 {1570-7873},
  Publisher =	 {Springer Netherlands},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-qos-final-jogc.pdf}
}

@InProceedings{las-04-abstracting,
  Title =	 {{Abstracting the Grid}},
  Author =	 {Kaizar Amin and Mihael Hategan and von Laszewski,
                  Gregor and Nestor J. Zaluzec},
  Booktitle =	 {Proceedings of the 12th Euromicro Conference on
                  Parallel, Distributed and Network-Based Processing
                  (PDP 2004)},
  Year =	 2004,
  Address =	 {La Coru\~{n}a, Spain},
  Month =	 feb,
  day =		 {11-13~},
  Pages =	 {250-257},
  Doi =		 {10.1109/EMPDP.2004.1271452},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-abstracting.pdf}
}

@InProceedings{las-04-adcom,
  Title =	 {{Toward an Architecture for Ad Hoc Grids}},
  Author =	 {Kaizar Amin and von Laszewski, Gregor and Armin
                  R. Mikler},
  Booktitle =	 {12th International Conference on Advanced Computing
                  and Communications (ADCOM 2004)},
  Year =	 2004,
  Address =	 {Ahmedabad Gujarat, India},
  Month =	 dec,
  day =		 {15-18~},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-adhoc-adcom2004.pdf}
}

@Article{las-04-atct-j,
  Title =	 {{Introduction to Active Thermochemical Tables:
                  Several Key Enthalpies of Formation Revisited}},
  Author =	 {Branko Ruscic and Reinhardt E. Pinzon and Melita
                  L. Morton and Gregor von Laszevski and Sandra
                  J. Bittner and Sandeep G. Nijsure and Kaizar A. Amin
                  and Michael Minkoff and Albert F. Wagner},
  Journal =	 {J. Phys. Chem. A},
  Year =	 2004,
  Number =	 45,
  Pages =	 {9979-9997},
  Volume =	 108,
  Doi =		 {10.1021/jp047912y}
}

@InProceedings{las-04-clade,
  Title =	 {{A Collaborative Informatics Infrastructure for
                  Multi-scale Science}},
  Author =	 {James D. Myers and Thomas C. Allison and Sandra
                  Bittner and Brett Didier and Michael Frenklach and
                  William H. Green and Jr. and Yen-Ling Ho and John
                  Hewson and Wendy Koegler and Carina Lansing and
                  David Leahy and Michael Lee and Renata McCoy and
                  Michael Minkoff and Sandeep Nijsure and von
                  Laszewski, Gregor and David Montoya and Carmen
                  Pancerella and Reinhardt Pinzon and William Pitz and
                  Larry A. Rahn and Branko Ruscic and Karen Schuchardt
                  and Eric Stephan and Al Wagner and Theresa Windus
                  and Christine Yang},
  Booktitle =	 {{Second International Workshop on Challenges of
                  Large Applications in Distributed Environments}},
  Year =	 2004,
  Address =	 {Honolulu, HI},
  Month =	 jun,
  day =		 7,
  Pages =	 {24-33},
  Doi =		 {10.1109/CLADE.2004.1309089},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-clade2004.pdf}
}

@InCollection{las-04-gestalt,
  Title =	 {{Gestalt of the Grid}},
  Author =	 {von Laszewski, Gregor and Patrick Wagstrom},
  Booktitle =	 {{Tools and Environments for Parallel and Distributed
                  Computing}},
  Publisher =	 {Wiley},
  Year =	 2004,
  Editor =	 {Salim Hariri and Manish Parashar},
  Pages =	 {149-187},
  Series =	 {Parallel and Distributed Computing},
  ISBN =	 {978-0-471-47484-5},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-gestalt.pdf}
}

@InProceedings{las-04-gridant,
  Title =	 {{GridAnt: A Client-Controllable Grid Workflow
                  System}},
  Author =	 {Kaizar Amin and Mihael Hategan and von Laszewski,
                  Gregor and Nestor J. Zaluzec and Shawn Hampton and
                  Albert Rossi},
  Booktitle =	 {37th Hawai'i International Conference on System
                  Science},
  Year =	 2004,
  Address =	 {Island of Hawaii, Big Island},
  Month =	 jan,
  day =		 {5-8~},
  Note =	 {{The original paper is: von Laszewski, Gregor,
                  Kaizar Amin, Shawn Hampton, and Sandeep
                  Nijsure. Technical report, Argonne National
                  Laboratory, 31 July
                  2002. https://laszewski.github.io/papers/vonLaszewski-gridant.pdf.}},
  Publisher =	 {IEEE Computer Society, Los Alamitos, CA, USA},
  Volume =	 7,
  Doi =		 {10.1109/HICSS.2004.1265491},
  Ee =
                  {http://csdl.computer.org/comp/proceedings/hicss/2004/2056/07/205670210cabs.htm},
  ISSN =	 {1530-1605},
  Otherlabel =	 {DBLP:conf/hicss/AminLHZHR04},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-gridant-hics.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-gridant-hics.pdf}}
}

@InCollection{las-04-middleware,
  Title =	 {{Middleware for Communications}},
  Author =	 {von Laszewski, Gregor and Kaizar Amin},
  Booktitle =	 {{Grid Middleware}},
  Publisher =	 {Wiley},
  Year =	 2004,
  Editor =	 {Qusay H. Mahmoud},
  Pages =	 {109-130},
  Doi =		 {10.1002/0470862084.ch5},
  ISBN =	 {0-470-86206-3},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-grid-middleware.pdf}
}

@InCollection{las-05--qos-book,
  Title =	 {{Quality-of-Service Based Grid Communities}},
  Author =	 {Omer Rana and Asif Akram and Rashid Al-Ali and David
                  Walker and Gregor von Laszewski and Kaizar Amin},
  Booktitle =	 {{Extending Web Services Technologies: The Use of
                  Multi-Agent Approaches}},
  Publisher =	 {Springer},
  Year =	 2005,
  Editor =	 {Lawrence Cavedon and Zakaria Maamar and David Martin
                  and Boualem Benatallah},
  Series =	 {Multiagent Systems, Artificial Societies, and
                  Simulated Organizations},
  Volume =	 13,
  Doi =		 {10.1007/0-387-23344-X_8},
  ISBN =	 {0-387-23343-1},
  Oldlabels =	 {las04-qos-book}
}

@InProceedings{las-05-adhoc-quality,
  Title =	 {{Quality Assured Ad Hoc Grids}},
  Author =	 {Kaizar Amin and von Laszewski, Gregor and Armin
                  R. Mikler},
  Booktitle =	 {{International Conference on Autonomic and
                  Autonomous Systems International Conference on
                  Networking and Services}},
  Year =	 2005,
  Address =	 {Papeete, Tahiti, French Polynesia},
  Month =	 oct,
  day =		 {23-28~},
  Publisher =	 {IEEE},
  Doi =		 {10.1109/ICAS-ICNS.2005.82},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-adhoc-quality.pdf}
}

@Article{las-05-atct,
  Title =	 {{Active Thermochemical Tables: Thermochemistry for
                  the 21st century}},
  Author =	 {Branko Ruscic and Reinhardt E. Pinzon and von
                  Laszewski, Gregor and Deepti Kodeboyina and
                  Alexander Burcat and David Leahy and David Montoya
                  and and Albert F. Wagner},
  Journal =	 {Journal of Physics},
  Year =	 2005,
  Pages =	 {561-570},
  Volume =	 16,
  Doi =		 {10.1088/1742-6596/16/1/078},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-scidac-atct.pdf}
}

@InProceedings{las-05-ca,
  Title =	 {{A Grid Certificate Authority for Community and
                  Ad-hoc Grids}},
  Author =	 {von Laszewski, Gregor and Mikhail Sosonkin},
  Booktitle =	 {7th International Workshop on Java for Parallel and
                  Distributed Computing, published in the Proceedings
                  of the 19th International Parallel and Distributed
                  Processing Symposium},
  Year =	 2005,
  Address =	 {Denver, CO},
  Month =	 apr,
  day =		 {4-8~},
  Publisher =	 {IEEE},
  Doi =		 {10.1109/IPDPS.2005.29},
  Oldlabels =	 {vonLaszewski-ca05},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-ca-workshop.pdf}
}

@TechReport{las-05-exp,
  Title =	 {{The Java CoG Kit Experiment Manager}},
  Author =	 {von Laszewski, Gregor},
  Institution =	 {Argonne National Laboratory},
  Year =	 2005,
  Month =	 jun,
  Number =	 {P1259},
  Status =	 {tmp},
  Url =
                  {http://scholarworks.rit.edu/cgi/viewcontent.cgi?article=1977&context=article},
  url =
                  {https://laszewski.github.io/papers/vonLaszewski-exp.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-exp.pdf}}
}

@Article{las-05-gridhistory,
  Title =	 {{The Grid-Idea and Its Evolution}},
  Author =	 {von Laszewski, Gregor},
  Journal =	 {Journal of Information Technology},
  Year =	 2005,
  Month =	 jun,
  Number =	 6,
  Pages =	 {319-329},
  Volume =	 47,
  Doi =		 {10.1524/itit.2005.47.6.319},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-grid-idea.pdf}
}

@Article{las-05-portalarch,
  Title =	 {{Grid Portal Architectures for scientific
                  applications}},
  Author =	 {M. Thomas and J. Burruss and L. Cinquini and G. Fox
                  and D. Gannon and L. Glilbert and von Laszewski,
                  Gregor and K. Jackson and D. Middleton and R. Moore
                  and M. Pierce and B. Plale and A. Rajasekar and
                  R. Regno and E. Roberts and D. Schissel and A. Seth
                  and W. Schroeder},
  Journal =	 {Journal of Physics},
  Year =	 2005,
  Pages =	 {596-600},
  Volume =	 16,
  Doi =		 {10.1088/1742-6596/16/1/083},
  Url =
                  {https://laszewski.github.io/papers/jpconf5_16_083.pdf}
}

@Article{las-05-reputation-j,
  Title =	 {{Toward Reputable Grids}},
  Author =	 {von Laszewski, Gregor and Beulah Alunkal and Ivana
                  Veljkovic},
  Journal =	 {Scalable Computing: Practice and Experience},
  Year =	 2005,
  Month =	 sep,
  Note =	 {submitted in 2003},
  Number =	 3,
  Pages =	 {95-106},
  Volume =	 6,
  Oldlabels =	 {las03reputation-journal},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-pdcp-reputation.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-pdcp-reputation.pdf}}
}

@Article{las-05-workflow-jgc,
  Title =	 {{Workflow Concepts of the Java CoG Kit}},
  Author =	 {von Laszewski, Gregor},
  Journal =	 {Journal of Grid Computing},
  Year =	 2005,
  Month =	 jan,
  Pages =	 {239-258},
  Volume =	 3,
  Doi =		 {10.1007/s10723-005-9013-5},
  ISSN =	 {1570-7873},
  Issue =	 {3-4},
  Publisher =	 {Springer Netherlands},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-workflow-taylor-anl.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-workflow-taylor-anl.pdf}}
}

%Note =	 {http://dl.acm.org/citation.cfm?id=1105923.1106017},
@InProceedings{las-05-workflowrepo,
  Title =	 {{A Repository Service for Grid Workflow Components}},
  Author =	 {von Laszewski, Gregor and Deepti Kodeboyina},
  Booktitle =	 {{Proceedings of the Joint International Conference
                  on Autonomic and Autonomous Systems and
                  International Conference on Networking and
                  Services}},
  Year =	 2005,
  Address =	 {Papeete, Tahiti, French Polynesia},
  Month =	 oct,
  day =		 {23-28~},
  Pages =	 {84--},
  Publisher =	 {IEEE Computer Society, Washington, DC, USA},
  Series =	 {ICAS-ICNS '05},
  Acmid =	 1106017,
  ISBN =	 {0-7695-2450-8},
  Oldlabels =	 {las05workflowrepository},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-workflow-repository.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-workflow-repository.pdf}}
}

@InProceedings{las-06-exp-a,
  Title =	 {{The Java CoG Kit Experiment Manager}},
  Author =	 {von Laszewski, Gregor and Christopher Grubbs and
                  Matthew Bone and David Angulo},
  Booktitle =	 {International Workshop on Grid Computing
                  Environments 2006 in Conjunction with SC06},
  Year =	 2006,
  Owner =	 {neu},
  Timestamp =	 {2013.12.18},
  Url =
                  {http://library.rit.edu/oajournals/index.php/gce/article/view/75/36},
  note =
                  {\url{http://library.rit.edu/oajournals/index.php/gce/article/view/75/36}}
}

@InCollection{las-06-workflow-book,
  Title =	 {Grid Workflow with the Java CoG Kit},
  Author =	 {von Laszewski, Gregor and Mihael Hategan and Depti
                  Kodeboyina},
  Booktitle =	 {{Workflows for E-science: Scientific Workflows for
                  Grids}},
  Publisher =	 {Springer-Verlag New York, Inc.},
  Year =	 2007,
  Address =	 {Secaucus, NJ, USA},
  Editor =	 {Ian J. Taylor and Ewa Deelman and Dennis B. Gannon
                  and Matthew Shields},
  ISBN =	 1846285194,
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-workflow-book.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-workflow-book.pdf}}
}

@InProceedings{las-06-cobalt,
  Title =	 {{Workflow Management Through Cobalt}},
  Author =	 {Gregor von Laszewski and Christopher Grubb and
                  Matthew Bone and David Angulo},
  Booktitle =	 {International Workshop on Grid Computing
                  Environments 2006 in Conjunction with SC06},
  Year =	 2006,
  Owner =	 {neu},
  Timestamp =	 {2013.12.18},
  Url =
                  {http://library.rit.edu/oajournals/index.php/gce/article/view/73/34}
}

@Article{las-06-guss-j,
  Title =	 {{A Portal for Visualizing Grid Usage}},
  Author =	 {von Laszewski, Gregor and Jonathan DiCarlo and Bill
                  Allcock},
  Journal =	 {Concurrency and Computation: Practice and
                  Experience},
  Year =	 2007,
  Month =	 aug,
  Number =	 12,
  Pages =	 {1683-1692},
  Volume =	 19,
  Acmid =	 1285349,
  Address =	 {Chichester, UK},
  Doi =		 {10.1002/cpe.v19:12},
  ISSN =	 {1532-0626},
  Numpages =	 10,
  Publisher =	 {John Wiley and Sons Ltd.},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-guss.pdf}
}

@InCollection{las-06-workcoordination,
  Title =	 {{Work coordination for Grid computing}},
  Author =	 {von Laszewski, Gregor and Mihael Hategan and Deepti
                  Kodeboyina},
  Booktitle =	 {{Grid Technologies}},
  Publisher =	 {Wit},
  Year =	 2006,
  Editor =	 {M.P. Bekakos and G.A. Gravvanis and H.R. Arabnia},
  Series =	 {State-of-the-art in Science and Engineering},
  Volume =	 5,
  ISBN =	 {1-84564-055-1},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-work-coordination.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-work-coordination.pdf}}
}

@InProceedings{las-07-gridtorrent,
  Title =	 {{GridTorrent Framework: A High-performance Data
                  Transfer and Data Sharing Framework for Scientific
                  Computing}},
  Author =	 {Kaplan, Ali and C. Fox, Geoffrey and von Laszewski,
                  Gregor},
  Booktitle =	 {International Workshop on Grid Computing
                  Environments 2007 (GCE07)},
  Year =	 2007,
  Ee =		 {https://ritdml.rit.edu/handle/1850/9682},
  Oldlabel =	 {kaplan2007gridtorrent},
  Timestamp =	 {2008.05.06},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-torrent.pdf}
}

@InProceedings{las-07-javascript,
  Title =	 {{JavaScript Grid Abstractions}},
  Author =	 {von Laszewski, Gregor and Fugang Wang and Andrew
                  Younge and Zhenhua Guo and Marlon Pierce},
  Booktitle =	 {Proceedings of the Grid Computing Environments 2007
                  at SC07},
  Year =	 2007,
  Address =	 {Reno, NV},
  Month =	 nov,
  Publisher =	 {IEEE},
  Timestamp =	 {2008.12.04},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-07-javascript.pdf}
}

@Article{las-07-ogce,
  Title =	 {{The Open Grid Computing Environments collaboration:
                  portlets and services for science gateways}},
  Author =	 {Alameda, Jay and Christie, Marcus and Fox, Geoffrey
                  and Futrelle, Joe and Gannon, Dennis and Hategan,
                  Mihael and Kandaswamy, Gopi and von Laszewski,
                  Gregor and Nacar, Mehmet A. and Pierce, Marlon and
                  Roberts, Eric and Severance, Charles and Thomas,
                  Mary},
  Journal =	 {Concurrency and Computation: Practice and
                  Experience},
  Year =	 2007,
  Number =	 6,
  Pages =	 {921--942},
  Volume =	 19,
  Doi =		 {10.1002/cpe.1078},
  ISSN =	 {1532-0634},
  Key =		 {alameda2007ogc},
  Keywords =	 {portlets, collaboration, Grid services},
  Oldlabel =	 {alameda2007ogc},
  Publisher =	 {John Wiley and Sons, Ltd.},
  Status =	 {final},
  Timestamp =	 {2008.11.05}
}

@InProceedings{las-07-torrent,
  Title =	 {{GridTorrent Framework: A High-performance Data
                  Transfer and Data Sharing Framework for Scientific
                  Computing}},
  Author =	 {Ali Kaplan and Geoffrey C. Fox and von Laszewski,
                  Gregor},
  Booktitle =	 {International Workshop on Grid Computing
                  Environments 2007 in Conjunction with SC07},
  Year =	 2007,
  Owner =	 {neu},
  Timestamp =	 {2013.12.18},
  Url =
                  {http://library.rit.edu/oajournals/index.php/gce/article/view/85/46}
}

@InProceedings{las-08-javascript,
  Title =	 {{Cyberaide JavaScript: A JavaScript Commodity Grid
                  Kit}},
  Author =	 {von Laszewski,Gregor and Fugang Wang and Andrew
                  Younge and Xi He and Zhenhua Guo and Marlon Pierce},
  Booktitle =	 {GCE08 at SC'08},
  Year =	 2008,
  Address =	 {Austin, TX},
  Month =	 nov,
  day =		 16,
  Publisher =	 {IEEE},
  Doi =		 {10.1109/GCE.2008.4738448},
  Otherlabel =	 {las08-javascript},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-08-javascript.pdf}
}

@InProceedings{las-08-project,
  Title =	 {{e-Science Project and Experiment Management with
                  Microsoft Project}},
  Author =	 {von Laszewski, Gregor and Leor E. Dilmanian},
  Booktitle =	 {Grid Computing Environments Workshop, GCE'08},
  Year =	 2008,
  Address =	 {Austin, TX},
  Month =	 nov,
  day =		 16,
  Publisher =	 {IEEE},
  Doi =		 {10.1109/GCE.2008.4738449},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-08-project-ieee.pdf}
}

@InProceedings{las-08-federated-cloud,
  Title =	 {{Design of an Accounting and Metric-based
                  Cloud-shifting and Cloud-seeding Framework for
                  Federated Clouds and Bare-metal Environments}},
  Author =	 {von Laszewski, Gregor and Lee, Hyungro and Diaz,
                  Javier and Wang, Fugang and Tanaka, Koji and
                  Karavinkoppa, Shubhada and Fox, Geoffrey C. and
                  Furlani, Tom},
  Booktitle =	 {Proceedings of the 2012 Workshop on Cloud Services,
                  Federation, and the 8th Open Cirrus Summit},
  Year =	 2012,
  Address =	 {New York, NY, USA},
  Pages =	 {25--32},
  Publisher =	 {ACM},
  Series =	 {FederatedClouds '12},
  Acmid =	 2378982,
  Doi =		 {10.1145/2378975.2378982},
  ISBN =	 {978-1-4503-1754-2},
  Keywords =	 {cloud metric, cloud seeding, cloud shifting, dynamic
                  provisioning, federated clouds, futuregrid, rain},
  Location =	 {San Jose, California, USA},
  Numpages =	 8
}

@Unpublished{las-08-gridshell,
  Title =	 {{Cyberaide Shell: Interactive Task Management for
                  Grids and Cyberinfrastructure}},
  Author =	 {Gregor von Laszewski and Andrew Younge and Fugang
                  Wang and Xi He},
  Year =	 2009,
  note =	 {Draft}
}

@InProceedings{las-08-project-position,
  Title =	 {{Accelerating Time to Scientific Discovery with a
                  Grid-Enhanced Microsoft Project}},
  Author =	 {von Laszewski, Gregor and Leor Dilmanian},
  Booktitle =	 {{2008 Microsoft eScience Workshop}},
  Year =	 2008,
  Address =	 {Indianapolis, IN, USA},
  Month =	 dec,
  day =		 {7-9},
  Url =
                  {https://laszewski.github.io/papers/las08msproject.pdf}
}

@InProceedings{las-09-ccgrid,
  Title =	 {{Experiment and Workflow Management Using Cyberaide
                  Shell}},
  Author =	 {von Laszewski, Gregor and Andrew Younge and Xi He
                  and Kumar Mahinthakumar and Lizhe Wang},
  Booktitle =	 {4th International Workshop on Workflow Systems in
                  e-Science (WSES 09) in conjunction with 9th IEEE
                  International Symposium on Cluster Computing and the
                  Grid},
  Year =	 2009,
  Address =	 {Shanghai, China},
  Month =	 may,
  Pages =	 {568-573},
  Publisher =	 {IEEE},
  Doi =		 {10.1109/CCGRID.2009.66},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-ccgrid09-final.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-ccgrid09-final.pdf}}
}

@Article{las-09-cloud,
  Title =	 {{Cloud Computing: a Perspective Study}},
  Author =	 {Lizhe Wang and Gregor von Laszewski and Andrew
                  J. Younge and Xi He and Marcel Kunze and Jie Tao and
                  Cheng Fu},
  Journal =	 {New Generation Computing},
  Year =	 2010,
  Note =	 {Springer and Ohmsha, Ltd.},
  Number =	 2,
  Pages =	 {137-146},
  Volume =	 28,
  Doi =		 {10.1007/s00354-008-0081-5},
  Oldlabel =	 {journals/ngc09/Wang09, Wang2010ngc},
  Url =		 {https://laszewski.github.io/papers/08-ngc.pdf}
}

@InCollection{las-09-cloudcomp,
  Title =	 {{Cyberaide Virtual Applicance: On-Demand Deploying
                  Middleware for Cyberinfrastructure}},
  Author =	 {Kurze, Tobias and Wang, Lizhe and Laszewski, Gregor
                  von and Tao, Jie and Kunze, Marcel and Wang, Fugang
                  and Kramer, David and Karl, Wolfgang and Ekanayake,
                  Jaliya},
  Booktitle =	 {International Conference on Cloud Computing
                  (CloudComp'09)},
  Publisher =	 {Springer Berlin Heidelberg},
  Year =	 2010,
  Address =	 {Munich, Germany},
  Editor =	 {Avresky, Dimiter R. and Diaz, Michel and Bode, Arndt
                  and Ciciani, Bruno and Dekel, Eliezer and Akan,
                  Ozgur and Bellavista, Paolo and Cao, Jiannong and
                  Dressler, Falko and Ferrari, Domenico and Gerla,
                  Mario and Kobayashi, Hisashi and Palazzo, Sergio and
                  Sahni, Sartaj and Shen, Xuemin (Sherman) and Stan,
                  Mircea and Xiaohua, Jia and Zomaya, Albert and
                  Coulson, Geoffrey},
  Month =	 oct,
  day =		 {19-21},
  Pages =	 {132-144},
  Series =	 {Lecture Notes of the Institute for Computer
                  Sciences, Social Informatics and Telecommunications
                  Engineering},
  Volume =	 34,
  Doi =		 {10.1007/978-3-642-12636-9_10},
  ISBN =	 {978-3-642-12636-9},
  Keyword =	 {Computer Science},
  Url =
                  {https://laszewski.github.io/papers/09-cloudcomp/paper.pdf}
}

@InProceedings{las-09-gridcat,
  Title =	 {{Cyberaide Creative: On-Demand Cyberinfrastructure
                  Provision in Clouds}},
  Author =	 {Casey Rathbone and Lizhe Wang and von Laszewski,
                  Gregor and Fugang Wang},
  Booktitle =	 {International Workshop on Grid Computing,
                  Applications, and Technologies (GridCAT 2009) in
                  conjunction with the 10th International Symposium on
                  Pervasive Systems, Algorithms and Networks (I-SPAN
                  2009)},
  Year =	 2009,
  Address =	 {Kaoshiung, Taiwan},
  Month =	 dec,
  day =		 {14-16~},
  Pages =	 {684-690},
  Publisher =	 {IEEE},
  Doi =		 {10.1109/I-SPAN.2009.23},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-ispan2.pdf}
}

@InProceedings{las-09-ipccc,
  Title =	 {{Thermal Aware Workload Scheduling with Backfilling
                  for Green Data Centers}},
  Author =	 {Lizhe Wang and von Laszewski, Gregor and Jai Dayal
                  and Xi He and Thomas R. Furlani},
  Booktitle =	 {{Proceedings of the 28th IEEE International
                  Performance Computing and Communications Conference
                  (IPCCC)}},
  Year =	 2009,
  Address =	 {Arizona, U.S.},
  Month =	 dec,
  Pages =	 {289 -296},
  Doi =		 {10.1109/PCCC.2009.5403821},
  ISSN =	 {1097-2641}
}

@InProceedings{las-09-ispa,
  Title =	 {{Accelerating Partitional Algorithms for Flow
                  Cytometry on GPUs}},
  Author =	 {Jeremy Espenshade and Andrew Pangborn and James
                  Cavenaugh and von Laszewski, Gregor and Doug
                  Roberts},
  Booktitle =	 {The 7th IEEE International Symposium on Parallel and
                  Distributed Processing with Applications (ISPA-09)},
  Year =	 2009,
  Address =	 {Chengdu and Jiuzhai Valley, China},
  Month =	 aug,
  Pages =	 {226-233},
  Publisher =	 {IEEE},
  Doi =		 {10.1109/ISPA.2009.29},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-09-cuda-biostat-ispa.pdf}
}

@InProceedings{las-09-ispan,
  Title =	 {{Towards Thermal Aware Workload Scheduling in a Data
                  Center}},
  Author =	 {Wang, Lizhe and von Laszewski, Gregor and Dayal, Jai
                  and He, Xi and Younge, Andrew J. and Furlani, Thomas
                  R.},
  Booktitle =	 {{Proceedings of the 10th International Symposium on
                  Pervasive Systems, Algorithms, and Networks
                  (ISPAN2009)}},
  Year =	 2009,
  Address =	 {Kao-Hsiung, Taiwan},
  Month =	 dec,
  day =		 {14-16},
  Pages =	 {116-122},
  Publisher =	 {IEEE Computer Society, Washington, DC, USA},
  Series =	 {ISPAN '09},
  Acmid =	 1728982,
  Doi =		 {10.1109/I-SPAN.2009.22},
  ISBN =	 {978-0-7695-3908-9},
  Numpages =	 7
}

@InProceedings{las-09-sla,
  Title =	 {{GreenIT Service Level Agreements}},
  Author =	 {von Laszewski, Gregor and Lizhe Wang},
  Booktitle =	 {{Service Level Agreements in Grids Workshop,
                  colocated with IEEE/ACM Grid 2009 Conference}},
  Year =	 2009,
  Address =	 {Banff, Canada},
  Month =	 oct,
  day =		 {13~},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-greenit-sla.pdf}
}

@InProceedings{las-10-ccgrid,
  Title =	 {{Towards Energy Aware Scheduling for Precedence
                  Constrained Parallel Tasks in a Cluster with DVFS}},
  Author =	 {Wang, Lizhe and von Laszewski, Gregor and Dayal, Jay
                  and Wang, Fugang},
  Booktitle =	 {{Proceedings of the 10th IEEE/ACM International
                  Conference on Cluster, Cloud and Grid Computing}},
  Year =	 2010,
  Address =	 {Melbourne, Victoria, Australia},
  Month =	 may,
  day =		 {17-20~},
  Pages =	 {368--377},
  Publisher =	 {IEEE Computer Society, Washington, DC, USA},
  Series =	 {CCGRID '10},
  Acmid =	 1845153,
  Doi =		 {10.1109/CCGRID.2010.19},
  ISBN =	 {978-0-7695-4039-9},
  Keywords =	 {Cluster Computing, Green Computing, Task Scheduling},
  Numpages =	 10,
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-10-ccgrid.pdf}
}

@Article{las-10-ijahuc,
  Title =	 {{Virtual Data System on Distributed Virtual Machines
                  in Computational Grids}},
  Author =	 {Wang, Lizhe and Laszewski, Gregor Von and Tao, Jie
                  and Kunze, Marcel},
  Journal =	 {International Journal of Ad Hoc and Ubiquitous
                  Compututing},
  Year =	 2010,
  Month =	 sep,
  Number =	 4,
  Pages =	 {194--204},
  Volume =	 6,
  Acmid =	 1866088,
  Doi =		 {10.1504/IJAHUC.2010.035532},
  ISSN =	 {1743-8225},
  Issue_date =	 {September 2010},
  Keywords =	 {compact muon solenoid, distributed virtual machines,
                  grid computing, grid workflow, high energy physics
                  applications, virtual data systems},
  Numpages =	 11,
  Publisher =	 {Inderscience Publishers, Geneva, Switzerland}
}

@InProceedings{las-10-onserve,
  Title =	 {{Cyberaide onServe: Software as a Service on
                  Production Grids}},
  Author =	 {Tobias Kurze and Lizhe Wang and von Laszewski,
                  Gregor and Jie Tao and Marcel Kunze},
  Booktitle =	 {{Proceedings of the 39th International Conference on
                  Parallel Processing (ICPP'10)}},
  Year =	 2010,
  Address =	 {San Diego, CA, USA},
  Month =	 sep,
  day =		 {13-16~},
  Pages =	 {395-403},
  Doi =		 {10.1109/ICPP.2010.47},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-icpp.pdf}
}

@InCollection{las-10-sla,
  Title =	 {{GreenIT Service Level Agreements}},
  Author =	 {von Laszewski, Gregor and Lizhe Wang},
  Booktitle =	 {{Grids and Service-Oriented Architectures for
                  Service Level Agreements}},
  Year =	 2010,
  Editor =	 {Wieder, Philipp and Yahyapour, Ramin and Ziegler,
                  Wolfgang},
  Pages =	 {77-88},
  ISBN =	 {978-1-4419-7320-7},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-greenit-sla.pdf}
}

@Article{las-10-ve-journal,
  Title =	 {{Provide Virtual Distributed Environments for Grid
                  computing on Demand}},
  Author =	 {Wang, Lizhe and von Laszewski, Gregor and Kunze,
                  Marcel and Tao, Jie and Dayal, Jai},
  Journal =	 {Advances in Engineering Software},
  Year =	 2010,
  Month =	 feb,
  Number =	 2,
  Pages =	 {213-219},
  Volume =	 41,
  Acmid =	 1663939,
  Address =	 {Oxford, UK},
  Doi =		 {10.1016/j.advengsoft.2009.09.002},
  ISSN =	 {0965-9978},
  Issue_date =	 {February, 2010},
  Keywords =	 {Grid computing, Virtual environment, Virtual
                  machine},
  Numpages =	 7,
  Publisher =	 {Elsevier Science Ltd.},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-vapl.pdf}
}

@InProceedings{las-10-vmschedule,
  Title =	 {{Schedule Distributed Virtual Machines in a Service
                  Oriented Environment}},
  Author =	 {Lizhe Wang and von Laszewski, Gregor and Jie Tao and
                  Marcel Kunze},
  Booktitle =	 {{Proceedings of the 24th IEEE International
                  Conference on Advanced Information Networking and
                  Applications (AINA'10)}},
  Year =	 2010,
  Address =	 {Perth, Australia},
  Month =	 apr,
  day =		 {20-23},
  Pages =	 {230--236},
  Doi =		 {10.1109/AINA.2010.47},
  ISSN =	 {1550-445X},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-09-aina.pdf}
}

@Article{las-11-ann,
  Title =	 {{Task scheduling with ANN-based temperature
                  prediction in a data center: a simulation-based
                  study}},
  Author =	 {Lizhe Wang and Gregor von Laszewski and Fang Huang
                  and Jai Dayal and Tom Frulani and Geoffrey Fox},
  Journal =	 {Eng. Comput. (Lond.)},
  Year =	 2011,
  Number =	 4,
  Pages =	 {381-391},
  Volume =	 27,
  Bibsource =	 {DBLP, http://dblp.uni-trier.de},
  Doi =		 {10.1007/s00366-011-0211-4},
  Url =
                  {https://laszewski.github.io/papers/las11ann-schedule.pdf}
}

@TechReport{las-08-cumulus,
  author =	 {Lizhe Wang and Gregor von Laszewski and Marcel Kunze
                  and Jie Tao},
  title =	 {A cumulus project: design and implementation},
  institution =	 {Rochester Institute of Technology},
  year =	 2008,
  type =	 {Report},
  url =
                  {http://scholarworks.rit.edu/cgi/viewcontent.cgi?article=1686&context=article}
}

@Article{las-11-emolst,
  Title =	 {{eMOLST: a documentation flow for distributed health
                  informatics}},
  Author =	 {Gregor von Laszewski and Jai Dayal and Lizhe Wang},
  Journal =	 {Concurrency and Computation: Practice and
                  Experience},
  Year =	 2011,
  Number =	 16,
  Pages =	 {1857-1867},
  Volume =	 23,
  Bibsource =	 {DBLP, http://dblp.uni-trier.de},
  Doi =		 {10.1002/cpe.1745},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-10-CCPE-emolst.pdf}
}

@InCollection{las-11-greenchapter,
  Title =	 {{Providing a Green Framework for Cloud Based Data
                  Centers}},
  Author =	 {Younge, A. J. and von Laszewski, Gregor and Wang,
                  L. and Fox, G. C.},
  Booktitle =	 {The Handbook of Energy-Aware Green Computing},
  Publisher =	 {Chapman and Hall/CRC Press},
  Year =	 2011,
  Chapter =	 17,
  Editor =	 {Ahmad, I. and Ranka, Sanjay},
  ISBN =	 {978-1-4665-0116-4},
  Otherkeys =	 {las11greenitcloud},
  Url =
                  {https://laszewski.github.io/papers/11-greenit-bookch.pdf}
}

@InCollection{las-11-ondemand,
  Title =	 {Towards on Demand IT Service Deployment},
  Author =	 {Jai Dayal and Casey Rathbone and Lizhe Wang and
                  Gregor von Laszewski},
  Booktitle =	 {{Internet Policies and Issues. Volume 7 - 2nd
                  quarter}},
  Publisher =	 {Nova},
  Year =	 2011,
  Pages =	 {pp.249-262},
  ISBN =	 {978-1-61668-745-8},
  Timestamp =	 {2013.12.23}
}

@Proceedings{las-12-fedcloud-proc,
  Title =	 {{FederatedClouds '12: Proceedings of the 2012
                  Workshop on Cloud Services, Federation, and the 8th
                  Open Cirrus Summit}},
  Year =	 2012,
  Address =	 {New York, NY, USA},
  Editor =	 {vonLaszewski, Gregor and Robert Grossman and Michael
                  Kozuchand Rick McGeerand Dejan Milojicic},
  Author =	 {vonLaszewski, Gregor and Robert Grossman and Michael
                  Kozuchand Rick McGeerand Dejan Milojicic},
  Publisher =	 {ACM},
  ISBN =	 {978-1-4503-1754-2},
  Location =	 {San Jose, California, USA},
  Url =
                  {http://dl.acm.org/citation.cfm?id=2378975&picked=prox&cfid=389635474&cftoken=32712991}
}

@InCollection{las-12-fg-bookchapter,
  Title =	 {{FutureGrid - a reconfigurable testbed for Cloud,
                  HPC and Grid Computing}},
  Author =	 {Geoffrey C. Fox and Gregor von Laszewski and Javier
                  Diaz and Kate Keahey and Jose Fortes and Renato
                  Figueiredo and Shava Smallen and Warren Smith and
                  Andrew Grimshaw},
  Booktitle =	 {{Contemporary HPC Architectures}},
  Year =	 2012,
  Edition =	 {draft},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-12-fg-bookchapter.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-12-fg-bookchapter.pdf}}
}

@Article{las-12-xdmod-kernel,
  Title =	 {{Performance Metrics and Auditing Framework using
                  Application Kernels for High-performance Computer
                  Systems}},
  Author =	 {Thomas R. Furlani and Matthew D. Jones and Steven
                  M. Gallo and Andrew E. Bruno and Charng-Da Lu and
                  Amin Ghadersohi and Ryan J. Gentner and Abani
                  K. Patra and Robert L. DeLeon and Gregor von
                  Laszewski and Fugang Wang and Ann Zimmerman},
  Journal =	 {Concurrency and Computation: Practice and
                  Experience},
  Year =	 2013,
  Number =	 7,
  Pages =	 {918-931},
  Volume =	 25,
  Doi =		 {10.1002/cpe.2871},
  Author =	 {Thomas R Furlani and Barry I Schneider and Matthew D
                  Jones and John, Towns and David L Hart and Abani K
                  Patra and Robert L Deleon and Steven M Gallo and
                  Charng-Da Lu and Amin Ghadersohi and Ryan J Gentner
                  and Andrew E Bruno and John R Boisseau and Fugang
                  Wang and Gregor Von Laszewski},
  Year =	 2012,
  Month =	 jul,
  institution =	 {University of Buffalo},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-draft-data-analytics-planing.pdf}
}

@Article{las-13-ondemand,
  Title =	 {{On-demand Service Hosting on Production Grid
                  Infrastructures}},
  Author =	 {Lizhe Wang and Tobias Kurze and Jie Tao and Marcel
                  Kunze and Gregor von Laszewski},
  Journal =	 {The Journal of Supercomputing},
  Year =	 2013,
  Number =	 3,
  Pages =	 {1178-1193},
  Volume =	 66,
  Doi =		 {10.1007/s11227-011-0666-5},
}

@InProceedings{las-13-xdmod,
  Title =	 {{Using XDMoD to Facilitate XSEDE Operations,
                  Planning and Analysis}},
  Author =	 {Furlani, Thomas R. and Schneider, Barry L. and
                  Jones, Matthew D. and Towns, John and Hart, David
                  L. and Gallo, Steven M. and DeLeon, Robert L. and
                  Lu, Charng-Da and Ghadersohi, Amin and Gentner, Ryan
                  J. and Patra, Abani K. and von Laszewski, Gregor and
                  Wang, Fugang and Palmer, Jeffrey T. and Simakov,
                  Nikolay},
  Booktitle =	 {{Proceedings of the Conference on Extreme Science
                  and Engineering Discovery Environment: Gateway to
                  Discovery}},
  Year =	 2013,
  Address =	 {New York, NY, USA},
  Pages =	 {46:1--46:8},
  Publisher =	 {ACM},
  Series =	 {XSEDE '13},
  Acmid =	 2484763,
  Articleno =	 46,
  Doi =		 {10.1145/2484762.2484763},
  ISBN =	 {978-1-4503-2170-9},
  Keywords =	 {Scientific IMpact, XSEDE, XDMoD},
  Location =	 {San Diego, California},
  Numpages =	 8
}

@InProceedings{las-14-Impact,
  Title =	 {{Towards a Scientific Impact Measuring Framework for
                  Large Computing Facilities - a Case Study on XSEDE}},
  Author =	 {Wang, Fugang and von Laszewski, Gregor and Fox,
                  Geoffrey C. and Furlani, Thomas R. and DeLeon,
                  Robert L. and Gallo, Steven M.},
  Booktitle =	 {Proceedings of the 2014 Annual Conference on Extreme
                  Science and Engineering Discovery Environment},
  Year =	 2014,
  Address =	 {New York, NY, USA},
  Pages =	 {25:1--25:8},
  Publisher =	 {ACM},
  Series =	 {XSEDE '14},
  Acmid =	 2616507,
  Articleno =	 25,
  Doi =		 {10.1145/2616498.2616507},
  ISBN =	 {978-1-4503-2893-7},
  Keywords =	 {Scientific impact, Technology Audit Service, XDMoD,
                  XSEDE, bibliometric, h-index},
  Location =	 {Atlanta, GA, USA},
  Numpages =	 8,
  Url =		 {http://doi.acm.org/10.1145/2616498.2616507}
}

@InCollection{las-14-bigdata,
  Title =	 {{The FutureGrid Testbed for Big Data}},
  Author =	 {von Laszewski, Gregor and Geoffrey Fox},
  Booktitle =	 {Cloud Computing for Data-Intensive Applications},
  Publisher =	 {Springer},
  Year =	 2014,
  Address =	 {Indiana University},
  Editor =	 {Xiaolin Li and Judy Qiu},
  Pages =	 {TBD},
  Author =	 {von Laszewski, Gregor and Wang, Fugang and Lee,
                  Hyungro and Chen, Heng and Fox, Geoffrey C.},
  Booktitle =	 {Proceedings of the 2014 ACM International Workshop
                  on Software-defined Ecosystems},
  Year =	 2014,
  Address =	 {New York, NY, USA},
  Pages =	 {21--28},
  Publisher =	 {ACM},
  Series =	 {BigSystem '14},
  Acmid =	 2609638,
  Doi =		 {10.1145/2609441.2609638},
  ISBN =	 {978-1-4503-2909-5},
  Keywords =	 {cloud computing},
  Location =	 {Vancouver, BC, Canada},
  Numpages =	 8,
  Url =		 {http://doi.acm.org/10.1145/2609441.2609638},
  note =	 {\url{http://doi.acm.org/10.1145/2609441.2609638}}
}

@TechReport{las-15-cluster-long,
  author =	 {von Laszewski, Gregor and Fugang Wang and Geoffrey
                  C. Fox and David L. Hart and Thomas R. Furlani and
                  Robert L. DeLeon and Steven M. Gallo},
  title =	 {Peer comparison of XSEDE and NCAR publication data},
  institution =	 {Indiana University},
  year =	 2015,
  url =
                  {https://laszewski.github.io/papers//vonLaszewski-tas-cluster.pdf}
}

@InProceedings{las-16-virtcluster,
  author =	 {Wagner, Rick and Papadopoulos, Philip and Mishin,
                  Dmitry and Cooper, Trevor and Tatineti, Mahidhar and
                  von Laszewski, Gregor and Wang, Fugang and Fox,
                  Geoffrey C.},
  title =	 {User Managed Virtual Clusters in Comet},
  booktitle =	 {Proceedings of the XSEDE16 Conference on Diversity,
                  Big Data, and Science at Scale},
  year =	 2016,
  pages =	 {24:1--24:8},
  month =	 jul,
  address =	 {Miami, USA},
  publisher =	 {ACM, New York, NY},
  doi =		 {10.1145/2949550.2949555},
  isbn =	 {978-1-4503-4755-6}
}

@InProceedings{las-20-10gce,
  Title =	 {{Design of the FutureGrid Experiment Management
                  Framework}},
  Author =	 {Gregor von Laszewski and Geoffrey C. Fox and Fugang
                  Wang and Younge, Andrew J and Kulshrestha and
                  Gregory G. Pike and Warren Smith and Jens Voeckler
                  and Renato J. Figueiredo and Jose Fortes and Kate
                  Keahey and Ewa Deelman},
  Booktitle =	 {Proceedings of Gateway Computing Environments 2010
                  (GCE2010) at SC10},
  Year =	 2010,
  Address =	 {New Orleans, LA},
  Month =	 nov,
  Publisher =	 {IEEE},
  Doi =		 {10.1109/GCE.2010.5676126},
}

@InProceedings{las-20-11virt,
  Title =	 {{Analysis of Virtualization Technologies for High
                  Performance Computing Environments}},
  Author =	 {Andrew J. Younge and Robert Henschel and James
                  T. Brown and Gregor von Laszewski and Judy Qiu and
                  Geoffrey C. Fox},
  Booktitle =	 {Proceedings of the 4th International Conference on
                  Cloud Computing (CLOUD 2011)},
  Year =	 2011,
  Address =	 {Washington, DC},
  Month =	 jul,
  Pages =	 {9-16},
  Publisher =	 {IEEE},
  Doi =		 {10.1109/CLOUD.2011.29},
  Otherlabel =	 {Younge2011cloud},
  Url =
                  {https://laszewski.github.io/papers/10-fg-hypervisor.pdf}
}

@InProceedings{las-20-15cluster,
  Title =	 {{Peer Comparison of Cluster Resource Provider
                  Publication Data}},
  Author =	 {von Laszewski, Gregor and Fugang Wang and Geoffrey
                  C. Fox and David L. Hart and Thomas R. Furlani and
                  Robert L. DeLeon and Steven M. Gallo},
  Booktitle =	 {Cluster Computing 2015},
  Year =	 2015,
  Publisher =	 {submitted to Cluster 2015 as Poster},
  Owner =	 {big},
  Timestamp =	 {2015.05.06},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-tas-cluster.pdf}
}

@InProceedings{las-90-natug,
  Title =	 {{A Parallel Genetic Algorithm for the Graph
                  Partitioning Problem}},
  Author =	 {von Laszewski, Gregor},
  Booktitle =	 {{Transputer Research and Applications 4, Proceedings
                  of the 4th Conference of the North-American
                  Transputers Users Group}},
  Year =	 1990,
  Address =	 {Ithaca, NY},
  Editor =	 {David Fielding},
  Month =	 oct,
  day =		 {11-12},
  Pages =	 {164-172},
  Publisher =	 {IOS Press, Amsterdam},
  Url =		 {http://tinyurl.com/laszewski-natug}
}

@InProceedings{las-90-ppsn,
  author =	 "von Laszewski, Gregor and M{\"u}hlenbein, Heinz",
  editor =	 "Schwefel, Hans-Paul and M{\"a}nner, Reinhard",
  title =	 {{Partitioning a Graph with a Parallel Genetic
                  Algorithm}},
  booktitle =	 {{Parallel Problem Solving from Nature}},
  year =	 1991,
  publisher =	 "Springer Berlin Heidelberg",
  address =	 {Dortmund, Germany},
  pages =	 "165--169",
  month =	 oct,
  volume =	 496,
  series =	 {Lecture Notes in Computer Science},
  abstract =	 "We present a parallel genetic algorithm for the k
                  way graph partitioning problem. The algorithm uses
                  selection in local neighborhood and sophisticated
                  genetic operators. For a sample problem the
                  algorithm has found better solutions than those
                  found by recent GPP algorithms. The success of the
                  parallel genetic algorithm depends on the
                  representation, a suitable crossover operator and an
                  efficient local hill climbing method which is used
                  to restrict the solution space.",
  isbn =	 "978-3-540-70652-6",
  doi =		 "https://doi.org/10.1007/BFb0029748",
  note =	 {1-3 Oct 1990},
  doi =		 {10.1007/BFb0029748},
  isbn =	 {978-3-540-54148-6},
  url =
                  {https://laszewski.github.io/papers/vonLaszewski-ppsn.pdf},
  comment =	 {ok}
}

@InProceedings{las-91-icga,
  Title =	 {{Intelligent Structural Operators for the k-way
                  Graph Partitioning Problem}},
  Author =	 {von Laszewski, Gregor},
  Booktitle =	 {{Proceedings of the 4th International Conference on
                  Genetic Algorithms}},
  Year =	 1991,
  Address =	 {San Diego, CA},
  Month =	 jul,
  day =		 {14-17~},
  Note =	 {(Plenary presentation)},
  Pages =	 {45-52},
  Publisher =	 {Morgan Kaufman},
  ISBN =	 {1-55860-208-9},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-icga.pdf}
}

@InProceedings{las-94-ecwmf,
  Title =	 {{Design Issues for the Parallelization of an Optimal
                  Interpolation Algorithm}},
  Author =	 {von Laszewski, Gregor and Mike Seablom and Milo
                  Makivic and Peter Lyster and Sanya Ranka},
  Booktitle =	 {{Coming of Age, Proceedings of the 4th Workshop on
                  the Use of Parallel Processing in Atmospheric
                  Science}},
  Year =	 1994,
  Address =	 {Reading, UK},
  Editor =	 {G.-R. Hoffman and N. Kreitz},
  day =		 {21-25~},
  Month =	 nov,
  Organization = {European Centre for Medium Weather Forecast},
  Pages =	 {290-302},
  Publisher =	 {World Scientific},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski94-4dda-design.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski94-4dda-design.pdf}}
}

@InProceedings{las-96-ecwmf,
  Title =	 {{An Interactive Parallel Programming Environment
                  Applied in Atmospheric Science}},
  Author =	 {von Laszewski, Gregor},
  Booktitle =	 {{Making Its Mark, Proceedings of the 6th Workshop on
                  the Use of Parallel Processors in Meteorology}},
  Year =	 1996,
  Address =	 {Reading, UK},
  Editor =	 {G.-R. Hoffman and N. Kreitz},
  day =		 {2-6~},
  Month =	 dec,
  Organization = {European Centre for Medium Weather Forecast},
  Pages =	 {311-325},
  Publisher =	 {World Scientific},
  ISBN =	 {978-9810233501},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-ecwmf-interactive.pdf},
  note =
                  {\url{https://laszewski.github.io/papers/vonLaszewski-ecwmf-interactive.pdf}}
}

@InProceedings{las-97-hpdc,
  Title =	 {{A Directory Service for Configuring
                  High-Performance Distributed Computations}},
  Author =	 {Steve Fitzgerald and Ian Foster and Carl Kesselman
                  and von Laszewski, Gregor and Warren Smith and Steve
                  Tuecke},
  Booktitle =	 {Proceedings of the 6th IEEE Symposium on
                  High-Performance Distributed Computing},
  Year =	 1997,
  Address =	 {Portland, OR},
  Month =	 aug,
  day =		 {5-8~},
  Pages =	 {365-375},
  Doi =		 {10.1109/HPDC.1997.626445},
  Oldlabel =	 {DBLP:conf/hpdc/FitzgeraldFKLST97},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/fitzgerald-hpdc97-mds.pdf}
}

@InProceedings{las-97-nobugs,
  Title =	 {{Supercomputing Data Analysis with an Example on the
                  APS CATs}},
  Author =	 {von Laszewski, Gregor and Mary L. Westbrook and
                  Craig Barnes and Ian Foster},
  Booktitle =	 {International Workshop on New Opportunities for
                  Better User Group Software (NOBUGS)},
  Year =	 1997,
  Month =	 dec,
  Organization = {Argonne, IL},
  Status =	 {tmp},
  Url =
                  {http://www.aps.anl.gov/News/Conferences/1997/nobugs/vonL.html}
}

@InProceedings{las-98-hpdc,
  Title =	 {{A Fault Detection Service for Wide Area Distributed
                  Computations}},
  Author =	 {Paul Stelling and Ian Foster and Carl Kesselman and
                  Craig Lee and von Laszewski, Gregor},
  Booktitle =	 {Proceedings of the 7th IEEE International Symposium
                  on High Performance Distributed Computing},
  Year =	 1998,
  Address =	 {Chicago, IL},
  Month =	 jul,
  day =		 {28-31},
  Pages =	 {268-278},
  Doi =		 {10.1109/HPDC.1998.709981},
  ISSN =	 {1082-8907},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-hbm-hpdc.pdf}
}

@Article{las-99-hbm-journal,
  Title =	 {{A Fault Detection Service for Wide Area Distributed
                  Computations}},
  Author =	 {P. Stelling and C. DeMatteis and I. Foster and
                  C. Kesselman and C. Lee and von Laszewski, Gregor},
  Journal =	 {Cluster Computing},
  Year =	 1999,
  Number =	 2,
  Pages =	 {117-128},
  Volume =	 2,
  Doi =		 {10.1023/A:1019070407281},
  ISSN =	 {1386-7857},
  Oldlabel =	 {Las99HBM},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-hbm-journal.pdf}
}

@Article{las-99-ieee,
  Title =	 {{Distance Visualization: Data Exploration on the
                  Grid}},
  Author =	 {Ian Foster and Joeseph Insley and von Laszewski,
                  Gregor and Carl Kesselman and Marcus Thiebaux},
  Journal =	 {IEEE Computer},
  Year =	 1999,
  Month =	 dec,
  Number =	 12,
  Pages =	 {36-43},
  Volume =	 32,
  Doi =		 {10.1109/2.809249},
  ISSN =	 {0018-9162},
  Url =
                  {https://laszewski.github.io/papers/Foster_IEEEComputer.pdf}
}

@Article{las-99-loosely,
  Title =	 {{A Loosely Coupled Metacomputer: Cooperating Job
                  Submissions Across Multiple Supercomputing Sites}},
  Author =	 {von Laszewski, Gregor},
  Journal =	 {Concurrency: Practice and Experience},
  Year =	 1999,
  Month =	 dec,
  Note =	 {The initial version of this paper was available in
                  1996},
  Number =	 15,
  Pages =	 {933-948},
  Volume =	 11,
  Doi =
                  {10.1002/(SICI)1096-9128(19991225)11:15<933::AID-CPE461>3.0.CO;2-J},
  ISSN =	 {1096-9128},
  Publisher =	 {John Wiley and Sons, Ltd.},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-CooperatingJobs.pdf}
}

@InProceedings{las-99-rostock,
  Title =	 {{Grid Infrastructure to Support Science Portals for
                  Large Scale Instruments}},
  Author =	 {von Laszewski, Gregor and Ian Foster},
  Booktitle =	 {{Proceedings of the Workshop Distributed Computing
                  on the Web (DCW)}},
  Year =	 1999,
  Month =	 jun,
  day =		 {21-23~},
  Note =	 {{\em (Invited Talk)}},
  Pages =	 {1-16},
  Publisher =	 {University of Rostock, Germany},
  Status =	 {final}
}

@InProceedings{las-99-siam,
  Title =	 {{Real-Time Analysis, Visualization, and Steering of
                  Microtomography Experiments at Photon Sources}},
  Author =	 {von Laszewski, Gregor and Mei-Hui Su and Joseph
                  A. Insley and Ian Foster and John Bresnahan and Carl
                  Kesselman and Marcus Thiebaux and Mark L. Rivers and
                  Steve Wang and Brian Tieman and Ian McNulty},
  Booktitle =	 {Ninth SIAM Conference on Parallel Processing for
                  Scientific Computing},
  Year =	 1999,
  Address =	 {San Antonio, TX},
  Month =	 mar,
  day =		 {22-24~},
  Otherlabel =	 {paper1/inproceedings/cmt},
  Status =	 {final},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-siamCmt99.pdf}
}

@InProceedings{las-99-spie,
  Title =	 {{A Quasi-Realtime X-Ray Microtomography System at
                  the Advanced Photon Source}},
  Author =	 {Wang, Yuxin and De Carlo, Francesco and Foster, Ian
                  and Insley, Joseph and Kesselman, Carl and Lane,
                  Peter and von Laszewski, Gregor and Mancini, Derrick
                  C. and McNulty, Ian and Su, Mei-Hui and Tieman,
                  Brian},
  Booktitle =	 {Proceedings of SPIE99},
  Year =	 1999,
  Address =	 {Orlando, FL},
  Month =	 apr,
  day =		 {4-6},
  Pages =	 {318-327},
  Volume =	 3772,
  Doi =		 {10.1117/12.363735},
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-spie99.pdf}
}

@Misc{las-10-dynamic,
  Title =	 {{Dynamic Provisioned Experiments in FutureGrid}},
  Author =	 {von Laszewski, Gregor and Geoffrey C. Fox and von
                  Laszewski, Gregor and Geoffrey C. Fox and FutureGrid
                  Team},
  HowPublished = {2nd IEEE International Conference on Cloud Computing
                  Technology and Science (CloudCom2010), Indianapolis,
                  IN},
  Month =	 dec,
  day =		 1,
  Year =	 2010,
  Url =
                  {https://laszewski.github.io/papers/vonLaszewski-10-FG-proj-management.pdf}
}

@Misc{las-10-scPoster-rain,
  Title =	 {{Rain: Dynamically Provisioning Clouds within
                  FutureGrid}},
  Author =	 {Fox, G. C. and A. J. Younge and G. von Laszewski and
                  A. Kulshrestha and F. Wang},
  HowPublished = {SC10 International Conference for High Performance
                  Computing},
  Month =	 nov,
  Year =	 2010,
  Owner =	 {neu},
  Timestamp =	 {2013.12.23},
  Url =		 {http://sc10.supercomputing.org/?pg=posters.html}
}

@Misc{las-04-scidacPoster-chem,
  Title =	 {{Collaboratory for Multi-scale Chemical Science}},
  Author =	 {Thomas C. Allison and Sandra Bittner and Brett
                  Didier and Michael Frenklach and William H. Green,
                  Jr. and Darrian Hale and Mihael F. Hategan-Marandiuc
                  and Carina Lansing and Gregor von Laszewski and
                  David Leahy and James D. Myers and Michael Minkoff
                  and David Montoya and Luwi Oluwole and Carmen
                  Pancerella and Reinhardt Pinzon and William Pitz and
                  Larry Rahn and Jane Riese and Branko Ruscic and
                  Karen Schuchardt and Albert F. Wagner and Theresa
                  Windus and Christine Yang and Ginger Young},
  HowPublished = {DOI SciDAC PI Meeting (Poster), Charleston, SC},
  Month =	 mar,
  day =		 {22-24},
  Year =	 2004,
  Owner =	 {neu},
  Timestamp =	 {2013.12.23},
  Url =
                  {http://www.csm.ornl.gov/workshops/DOE_SciDAC/posters.html}
}

@Misc{las-04-scidacPoster-cogkit,
  Title =	 {{Commodity Grid Kits}},
  Author =	 {Gregor von Laszewski and Keith Jackson},
  HowPublished = {DOI SciDAC PI Meeting (Poster), Charleston, SC},
  Month =	 mar,
  day =		 {22-24},
  Year =	 2004,
  Owner =	 {neu},
  Timestamp =	 {2013.12.23},
  Url =
                  {http://www.csm.ornl.gov/workshops/DOE_SciDAC/posters.html}
}

@Misc{las-05-scidacPoster-portal,
  Title =	 {{Grid Portal Architectures for Scientific
                  Applications}},
  Author =	 {Thomas, M. P. and J. Burruss, L. Cinquini and
                  G. C. Fox and D. Gannon and L. Gilbert and G. von
                  Laszewski and K. Jackson and D. Middleton and
                  R. Moore and et al.},
  HowPublished = {DOI SciDAC Meeting 2005 (Poster), San Francisco},
  Month =	 jun,
  day =		 26,
  Year =	 2005,
  Owner =	 {neu},
  Timestamp =	 {2013.12.23},
  Url =		 {http://www.csm.ornl.gov/workshops/SciDAC2005/}
}

@Article{las-10-wang-transactions,
  Title =	 {{Provide Virtual Machine Information for Grid
                  Computing}},
  Author =	 {Lizhe Wang and von Laszewski, Gregor and Dan Chen
                  and Jie Tao and Kunze, M.},
  Journal =	 {IEEE Transactions on Systems, Man and Cybernetics,
                  Part A: Systems and Humans},
  Year =	 2010,
  Month =	 nov,
  Number =	 6,
  Pages =	 {1362-1374},
  Volume =	 40,
  Doi =		 {10.1109/TSMCA.2010.2052598},
}

@TechReport{las-95-Mopac,
  author =	 {Gregor von Laszewski},
  title =	 {Draft: Parallelization of MOPAC},
  institution =	 {Syracuse University},
  year =	 1995,
  url =		 {https://laszewski.github.io/papers/sccs-0362.pdf}
}

@article{WECEnergy,
  author =	 {{World Economic Forum}},
  title =	 {AI and energy: Will AI help reduce emissions or increase power demand? Here's what to know},
  url={https://www.weforum.org/stories/2024/07/generative-ai-energy-emissions/},
  month =	 Jul,
  year =	 2024,
  journal =	 {NA},
  note =	 {(Accessed on 09/07/2025)}
}

@Article{HPCpricing:online,
  author       = {{AWS}},
  journal      = {NA},
  title        = {HPC Workload Service – AWS Parallel Computing Service Pricing – AWS},
  year         = {2024},
  month        = oct,
  note         = {\url{https://aws.amazon.com/pcs/pricing/}},
  howpublished = {Web Page},
  url          = {https://aws.amazon.com/pcs/pricing/},
}

@Article{spot-instance:online,
  author = {{AWS}},
  title  = {Savings from purchasing Spot Instances - Amazon Elastic Compute Cloud},
  year   = {2024},
  month  = oct,
  note   = {\url {https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-savings.html}},
}

@Article{las-frontiers-edu,
  author  = {von Laszewski, Gregor and Fleischer, J. P. and Knuuti, Robert and Fox, Geoffrey C. and Kolessar, Jake and Butler, Thomas S. and Fox, Judy},
  journal = {Frontiers in High Performance Computing},
  title   = {Opportunities for enhancing MLCommons efforts while leveraging insights from educational MLCommons earthquake benchmarks efforts},
  year    = {2023},
  issn    = {2813-7337},
  month   = {October},
  number  = {1233877},
  pages   = {31},
  volume  = {1},
  doi     = {10.3389/fhpcp.2023.1233877},
  url     = {https://www.frontiersin.org/journals/high-performance-computing/articles/10.3389/fhpcp.2023.1233877},
}

@Article{www-top500,
  journal = {Web page},
  title   = {Homepage},
  year    = {2023},
  month   = apr,
  note    = {\url{https://www.top500.org/} [Accessed April 13, 2023]},
  key     = {Top500},
}

@Article{software-carpentry,
  author    = {Greg Wilson and D. A. Aruliah and C. Titus Brown and Neil P. Chue Hong and Matt Davis and Richard T. Guy and Steven H. D. Haddock and Kathryn D. Huff and Ian M. Mitchell and Mark D. Plumbley and Ben Waugh and Ethan P. White and Paul Wilson},
  journal   = {{PLoS} Biology},
  title     = {Best Practices for Scientific Computing},
  year      = {2014},
  month     = {jan},
  number    = {1},
  pages     = {e1001745},
  volume    = {12},
  abstract  = {We describe a set of best practices for scientific
                  software development, based on research and
                  experience, that will improve scientists'
                  productivity and the reliability of their software.},
  doi       = {10.1371/journal.pbio.1001745},
  editor    = {Jonathan A. Eisen},
  publisher = {Public Library of Science ({PLoS})},
  url       = {https://doi.org/10.1371%2Fjournal.pbio.1001745},
}

@InProceedings{las-15-impact-ncar,
  author       = {G. von Laszewski and F. Wang and G. C. Fox and D. L. Hart and T. R. Furlani and R. L. DeLeon and S. M. Gallo},
  booktitle    = {2015 IEEE International Conference on Cluster Computing},
  title        = {Peer Comparison of XSEDE and NCAR Publication Data},
  year         = {2015},
  address      = {Chicago IL},
  month        = sep,
  note         = {Poster, Technical Report},
  organization = {Indiana University},
  pages        = {531-532},
  publisher    = {IEEE},
  doi          = {10.1109/CLUSTER.2015.98},
  issn         = {1552-5244},
  keywords     = {citation analysis, NCAR, scientific impact},
  url          = {https://laszewski.github.io/papers//vonLaszewski-tas-cluster.pdf},
}

@Proceedings{las-06-gce,
  title        = {{Grid Computing Environments 2006 Confernce Proceeedings}},
  year         = {2006},
  address      = {Tampa, FL},
  editor       = {von Laszewski, Gregor},
  month        = nov,
  organization = {in conjunction with IEEE/ACM SC06},
  publisher    = {Published Aug. 2008, Rochester Institute of Technology, Rochester NY},
  author       = {von Laszewski, Gregor},
  oldlabel     = {gce06},
  url          = {http://library.rit.edu/oajournals/index.php/gce/issue/view/10/showToc},
}

@InProceedings{las-06-water,
  author    = {Mahinthakumar, Kumar and von Laszewski, Gregor and Ranjithan, Ranji and Brill, Downey and Uber, Jim and Harrison, Ken and Sreepathi, Sarat and Zechman, Emily},
  booktitle = {{The Second International Conference on Parallel, Distributed, Grid and Cloud Computing for Engineering}},
  title     = {{An Adaptive Cyberinfrastructure for Threat Management in Urban Water Distribution Systems}},
  year      = {2006},
  address   = {Berlin, Heidelberg},
  month     = apr,
  note      = {Extended paper available},
  pages     = {401-408},
  publisher = {Springer-Verlag},
  series    = {ICCS'06},
  volume    = {3993},
  acmid     = {2107159},
  day       = {12-15},
  doi       = {10.1007/11758532_54},
  isbn      = {3-540-34383-0, 978-3-540-34383-7},
  location  = {Reading, UK},
  numpages  = {8},
  url       = {https://laszewski.github.io/papers/vonLaszewski-water-iccs.pdf},
  vol       = {3},
}

@InProceedings{las-09-cluster,
  author     = {von Laszewski, Gregor and Lizhe Wang and Andrew J. Younge and Xi He},
  booktitle  = {Proceedings of the 2009 IEEE International Conference on Cluster Computing (Cluster 2009)},
  title      = {{Power-Aware Scheduling of Virtual Machines in DVFS-enabled Clusters}},
  year       = {2009},
  address    = {New Orleans},
  month      = aug,
  pages      = {357-364},
  publisher  = {IEEE},
  series     = {GREENCOMP '10},
  acmid      = {1909753},
  day        = {31 Aug. -- Sep. 4},
  doi        = {10.1109/GREENCOMP.2010.5598294},
  isbn       = {978-1-4244-7612-1},
  numpages   = {8},
  otherlabel = {DBLP:conf/cluster/Wang09},
  status     = {accepted},
  timestamp  = {2009.06.21},
  url        = {https://laszewski.github.io/papers/vonLaszewski-cluster09.pdf},
}

@InProceedings{las-15-xsede,
  author       = {von Laszewski, Gregor and Fugang Wang and Geoffrey C. Fox and David L. Hart and Thomas R. Furlani and Robert L. DeLeon and Steven M. Gallo},
  booktitle    = {XSEDE2015},
  title        = {{Peer comparison of XSEDE publication data}},
  year         = {2015},
  address      = {St. Louis},
  month        = jul,
  note         = {Poster, Technical Report},
  organization = {Indiana University},
  publisher    = {IEEE},
  owner        = {big},
  timestamp    = {2015.05.06},
  url          = {https://laszewski.github.io/papers/vonLaszewski-tas-xsede.pdf},
}

@Comment{jabref-meta: databaseType:bibtex;}


@inproceedings{maiterth2025hpc,
  title={{HPC} Digital Twins for Evaluating Scheduling Policies, Incentive Structures and their Impact on Power and Cooling},
  author={Maiterth, Matthias and Brewer, Wesley H. and Kuruvella, Jaya S. and Dey, Arunavo and Islam, Tanzima Z. and Menear, Kevin and Duplyakin, Dmitry and Kabir, Rashadul and Patki, Tapasya and Jones, Terry and others},
  booktitle={SC25-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  year={2025},
  organization={IEEE}
}

@inproceedings{brewer2025trace,
  title={Trace Replay Simulation of {MIT SuperCloud} for Studying Optimal Sustainability Policies},
  author={Brewer, Wesley and Maiterth, Matthias and Fay, Damien},
  booktitle={2025 IEEE High Performance Extreme Computing Conference (HPEC)},
  year={2025},
  organization={IEEE}
}

@inproceedings{kalepu2025virtual,
  title={Virtual Benchmarking for {HPC} Systems Using {ExaDigiT} and {Calculon}},
  author={Kalepu, Srishti and Brewer, Wesley H. and Maiterth, Matthias and Vuduc, Richard},
  booktitle={2025 IEEE High Performance Extreme Computing Conference (HPEC)},
  year={2025},
  organization={IEEE}
}
